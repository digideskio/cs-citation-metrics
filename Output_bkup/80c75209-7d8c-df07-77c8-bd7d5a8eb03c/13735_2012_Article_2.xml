<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE Publisher PUBLIC "-//Springer-Verlag//DTD A++ V2.4//EN" "http://devel.springer.de/A++/V2.4/DTD/A++V2.4.dtd">
<Publisher>
  <PublisherInfo>
    <PublisherName>Springer-Verlag</PublisherName>
    <PublisherLocation>London</PublisherLocation>
  </PublisherInfo>
  <Journal OutputMedium="All">
    <JournalInfo JournalProductType="ArchiveJournal" NumberingStyle="ContentOnly">
      <JournalID>13735</JournalID>
      <JournalPrintISSN>2192-6611</JournalPrintISSN>
      <JournalElectronicISSN>2192-662X</JournalElectronicISSN>
      <JournalTitle>International Journal of Multimedia Information Retrieval</JournalTitle>
      <JournalAbbreviatedTitle>Int J Multimed Info Retr</JournalAbbreviatedTitle>
      <JournalSubjectGroup>
        <JournalSubject Type="Primary">Computer Science</JournalSubject>
        <JournalSubject Type="Secondary">Data Mining and Knowledge Discovery</JournalSubject>
        <JournalSubject Type="Secondary">Image Processing and Computer Vision</JournalSubject>
        <JournalSubject Type="Secondary">Information Systems Applications (incl. Internet)</JournalSubject>
        <JournalSubject Type="Secondary">Information Storage and Retrieval</JournalSubject>
        <JournalSubject Type="Secondary">Multimedia Information Systems</JournalSubject>
        <JournalSubject Type="Secondary">Computer Science, general</JournalSubject>
      </JournalSubjectGroup>
    </JournalInfo>
    <Volume OutputMedium="All">
      <VolumeInfo TocLevels="0" VolumeType="Regular">
        <VolumeIDStart>1</VolumeIDStart>
        <VolumeIDEnd>1</VolumeIDEnd>
        <VolumeIssueCount>4</VolumeIssueCount>
      </VolumeInfo>
      <Issue IssueType="Regular" OutputMedium="All">
        <IssueInfo IssueType="Regular" TocLevels="0">
          <IssueIDStart>2</IssueIDStart>
          <IssueIDEnd>2</IssueIDEnd>
          <IssueArticleCount>5</IssueArticleCount>
          <IssueHistory>
            <OnlineDate>
              <Year>2012</Year>
              <Month>6</Month>
              <Day>19</Day>
            </OnlineDate>
            <PrintDate>
              <Year>2012</Year>
              <Month>6</Month>
              <Day>18</Day>
            </PrintDate>
            <CoverDate>
              <Year>2012</Year>
              <Month>7</Month>
            </CoverDate>
            <PricelistYear>2012</PricelistYear>
          </IssueHistory>
          <IssueCopyright>
            <CopyrightHolderName>Springer-Verlag London Limited</CopyrightHolderName>
            <CopyrightYear>2012</CopyrightYear>
          </IssueCopyright>
        </IssueInfo>
        <Article ID="s13735-012-0002-8" OutputMedium="All">
          <ArticleInfo ArticleType="OriginalPaper" ContainsESM="No" Language="En" NumberingStyle="ContentOnly" TocLevels="0">
            <ArticleID>2</ArticleID>
            <ArticleDOI>10.1007/s13735-012-0002-8</ArticleDOI>
            <ArticleSequenceNumber>4</ArticleSequenceNumber>
            <ArticleTitle Language="En" OutputMedium="All">Exploiting contextual information for image re-ranking and rank aggregation</ArticleTitle>
            <ArticleCategory>Regular Paper</ArticleCategory>
            <ArticleFirstPage>115</ArticleFirstPage>
            <ArticleLastPage>128</ArticleLastPage>
            <ArticleHistory>
              <RegistrationDate>
                <Year>2012</Year>
                <Month>1</Month>
                <Day>28</Day>
              </RegistrationDate>
              <Received>
                <Year>2011</Year>
                <Month>11</Month>
                <Day>23</Day>
              </Received>
              <Accepted>
                <Year>2012</Year>
                <Month>1</Month>
                <Day>23</Day>
              </Accepted>
              <OnlineDate>
                <Year>2012</Year>
                <Month>3</Month>
                <Day>13</Day>
              </OnlineDate>
            </ArticleHistory>
            <ArticleCopyright>
              <CopyrightHolderName>Springer-Verlag London Limited</CopyrightHolderName>
              <CopyrightYear>2012</CopyrightYear>
            </ArticleCopyright>
            <ArticleGrants Type="Regular">
              <MetadataGrant Grant="OpenAccess"/>
              <AbstractGrant Grant="OpenAccess"/>
              <BodyPDFGrant Grant="OpenAccess"/>
              <BodyHTMLGrant Grant="OpenAccess"/>
              <BibliographyGrant Grant="OpenAccess"/>
              <ESMGrant Grant="OpenAccess"/>
            </ArticleGrants>
          </ArticleInfo>
          <ArticleHeader>
            <AuthorGroup>
              <Author AffiliationIDS="Aff1" CorrespondingAffiliationID="Aff1">
                <AuthorName DisplayOrder="Western">
                  <GivenName>Daniel</GivenName>
                  <GivenName>Carlos</GivenName>
                  <GivenName>Guimarães</GivenName>
                  <FamilyName>Pedronette</FamilyName>
                </AuthorName>
                <Contact>
                  <Email>pedronette@gmail.com</Email>
                  <Email>dcarlos@ic.unicamp.br</Email>
                </Contact>
              </Author>
              <Author AffiliationIDS="Aff1">
                <AuthorName DisplayOrder="Western">
                  <GivenName>Ricardo</GivenName>
                  <GivenName>da</GivenName>
                  <GivenName>S.</GivenName>
                  <FamilyName>Torres</FamilyName>
                </AuthorName>
                <Contact>
                  <Email>rtorres@ic.unicamp.br</Email>
                </Contact>
              </Author>
              <Affiliation ID="Aff1">
                <OrgDivision>RECOD Lab, Institute of Computing (IC)</OrgDivision>
                <OrgName>University of Campinas (UNICAMP)</OrgName>
                <OrgAddress>
                  <City>Campinas</City>
                  <Country Code="BR">Brazil</Country>
                </OrgAddress>
              </Affiliation>
            </AuthorGroup>
            <Abstract ID="Abs1" Language="En" OutputMedium="All">
              <Heading>Abstract</Heading>
              <Para>Content-based image retrieval (CBIR) systems aim to retrieve the most similar images in a collection, given a query image. Since users are interested in the returned images placed at the first positions of ranked lists (which usually are the most relevant ones), the effectiveness of these systems is very dependent on the accuracy of ranking approaches. This paper presents a novel re-ranking algorithm aiming to exploit <Emphasis Type="Italic">contextual information</Emphasis> for improving the effectiveness of rankings computed by CBIR systems. In our approach, ranked lists and distance scores are used to create <Emphasis Type="Italic">context images</Emphasis>, later used for retrieving contextual information. We also show that our re-ranking method can be applied to other tasks, such as (a) combining ranked lists obtained using different image descriptors (rank aggregation) and (b) combining post-processing methods. Conducted experiments involving shape, color, and texture descriptors and comparisons with other post-processing methods demonstrate the effectiveness of our method.</Para>
            </Abstract>
            <KeywordGroup Language="En" OutputMedium="All">
              <Heading>Keywords</Heading>
              <Keyword>Content-based image retrieval</Keyword>
              <Keyword>Re-ranking</Keyword>
              <Keyword>Rank aggregation</Keyword>
              <Keyword>Image processing</Keyword>
              <Keyword>Contextual information</Keyword>
            </KeywordGroup>
          </ArticleHeader>
          <Body>
            <Section1 ID="Sec1">
              <Heading>Introduction</Heading>
              <Para>The continuous decrease of storage devices costs and the technological improvements in image acquisition and sharing facilities have enabled the dissemination of very large digital image collections, accessible through various technologies. In this scenario, effective and efficient systems for searching and organizing these contents are of great interest.</Para>
              <Para>Content-based image retrieval (CBIR) can be seen as any technology that helps to search and organize digital picture archives by means of their visual content [<CitationRef CitationID="CR11">11</CitationRef>]. In general, given a query image, a CBIR system aims to retrieve the most similar images in a collection by taking into account image visual properties (such as shape, color, and texture). Collection images are <Emphasis Type="Italic">ranked</Emphasis> in decreasing order of similarity, according to a given <Emphasis Type="Italic">image descriptor</Emphasis>. An image content descriptor is characterized by [<CitationRef CitationID="CR8">8</CitationRef>]: (a) an extraction algorithm that encodes image features into feature vectors and (b) a similarity measure used to compare two images. The similarity between two images is computed as a function of the distance of their feature vectors.</Para>
              <Para>A direct way to improve the effectiveness of CBIR systems consists in using more accurate features for describing images. Another possibility is related to the definition of similarity (or distance) functions that would be able to measure the distance between feature vectors in a more effective way.</Para>
              <Para>Commonly, CBIR systems compute similarity considering only pairs of images. On the other hand, the user perception usually considers the query specification and the query responses in a given context. In interactive applications, the use of context can play an important role [<CitationRef CitationID="CR1">1</CitationRef>]. Context can be broadly defined as all information about the whole situation relevant to an application and its set of users. Information retrieval and recommendation systems, that include geographic information, user profiles, and relationships among users and objects, can be used for improving the effectiveness of obtained results. In a CBIR scenario, relationships among images, encoded in ranked lists, can be used for extracting contextual information.</Para>
              <Para>In this paper, we present a new post-processing method that re-ranks images by taking into account <Emphasis Type="Italic">contextual information</Emphasis> encoded in ranked lists and distance among images. We propose a novel approach for retrieving contextual information, by creating a <Emphasis Type="Italic">gray scale image</Emphasis> representation of distance matrices computed by CBIR descriptors (referenced in this paper as <Emphasis Type="Italic">context image</Emphasis>). The context image is constructed for the <InlineEquation ID="IEq1"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq1.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$k$$]]></EquationSource></InlineEquation>-nearest neighbors of a query image and analyzed using image processing techniques. The use of image processing techniques for <Emphasis Type="Italic">contextual information</Emphasis> representation and processing is an important novelty of our work. Our method uses distance matrices computed by CBIR descriptors that are later processed considering their image representation. The median filter, for instance, which is a well-known non-linear filter often used for removing noise, is exploited in our approach to improve the quality of distance scores. Basically, we consider that “<Emphasis Type="Italic">wrong</Emphasis>” distances can be considered and represented as “<Emphasis Type="Italic">noise</Emphasis>” in the context image, and the median filter is used for filtering this noise out. In fact, a very large number of image processing techniques can be used for extracting useful information from context images. We believe that our strategy opens a new area of investigation related to the use of image processing approaches for analyzing distances computed by CBIR descriptor, in tasks such as image re-ranking, rank aggregation, and clustering.</Para>
              <Para>We evaluated the proposed method on shape, color, and texture descriptors. Experimental results demonstrate that the proposed method can be used in several CBIR tasks, since it yields better results in terms of effectiveness performance than various post-processing algorithms recently proposed in the literature.</Para>
              <Para>This paper differs from previous works [<CitationRef CitationID="CR29">29</CitationRef>, <CitationRef CitationID="CR32">32</CitationRef>] with regard to the following aspects: (a) it presents and discusses in more details the main concepts of the proposed methods, (b) it extends both re-ranking and rank aggregation algorithms by considering more contextual information, and (c) it presents new experimental results that overcome the original methods.</Para>
              <Para>The paper is organized as follows. Section <InternalRef RefID="Sec2">2</InternalRef> discusses related work and Sect.  <InternalRef RefID="Sec5">3</InternalRef> presents the problem definition. Section <InternalRef RefID="Sec9">4.1</InternalRef> describes the contextual information representation, while Sects. <InternalRef RefID="Sec10">4.2</InternalRef> and <InternalRef RefID="Sec11">4.3</InternalRef> describe the re-ranking and rank aggregation methods, respectively. Section <InternalRef RefID="Sec12">4.4</InternalRef> discusses how to use our approach for combining post-processing methods. Experimental design and results are reported in Sect. <InternalRef RefID="Sec13">5</InternalRef>. Finally, Sect. <InternalRef RefID="Sec25">6</InternalRef> presents conclusions and future work.</Para>
            </Section1>
            <Section1 ID="Sec2">
              <Heading>Related work</Heading>
              <Para>This section discusses related work. Section <InternalRef RefID="Sec3">2.1</InternalRef> discusses the re-ranking approaches and Sect. <InternalRef RefID="Sec4">2.2</InternalRef> describes the rank aggregation methods.</Para>
              <Section2 ID="Sec3">
                <Heading>Re-ranking</Heading>
                <Para>Recently, several approaches have been proposed for performing re-ranking tasks on various information retrieval systems [<CitationRef CitationID="CR3">3</CitationRef>, <CitationRef CitationID="CR12">12</CitationRef>, <CitationRef CitationID="CR20">20</CitationRef>, <CitationRef CitationID="CR29">29</CitationRef>, <CitationRef CitationID="CR33">33</CitationRef>, <CitationRef CitationID="CR34">34</CitationRef>, <CitationRef CitationID="CR36">36</CitationRef>, <CitationRef CitationID="CR41">41</CitationRef>]. In general, these methods perform a <Emphasis Type="Italic">post-processing analysis</Emphasis> that uses an initial ranking and exploits additional information (e.g., relationships among items, user profiles) for improving the effectiveness of ranked lists.</Para>
                <Para>In the Information Retrieval scenario, the term “<Emphasis Type="Italic">global ranking</Emphasis>” was proposed in [<CitationRef CitationID="CR34">34</CitationRef>] for designating a ranking model that takes all the documents together as its input, instead of only individual objects. In other words, a global ranking uses not only the information of documents but also the relation information among them.</Para>
                <Para>The continuous conditional random fields (CRF) has been proposed in [<CitationRef CitationID="CR34">34</CitationRef>] for conducting the learning task in global ranking tasks. This model is defined as a conditional probability distribution over ranking scores of objects. It represents the content information of objects as well as the relation information between objects, necessary for global ranking. A global ranking framework that solves the problem via data fusion was proposed in [<CitationRef CitationID="CR10">10</CitationRef>]. The main idea of the approach is to take each retrieved document as a pseudo-information retrieval system. Each document generates a pseudo-ranked list by a global function. A data fusion algorithm is then adapted to generate the final ranked list.</Para>
                <Para>Inter-documents similarity is considered in [<CitationRef CitationID="CR12">12</CitationRef>] and a clustering approach is applied for regularizing retrieval scores. In [<CitationRef CitationID="CR45">45</CitationRef>], a semi-supervised label propagation algorithm [<CitationRef CitationID="CR50">50</CitationRef>] was applied for re-ranking documents in information retrieval applications.</Para>
                <Para>In the CBIR scenario, several methods have also been proposed for post-processing retrieval tasks, considering relationships among images. A graph transduction learning approach is introduced in [<CitationRef CitationID="CR48">48</CitationRef>]. The algorithm computes the shape similarity of a pair of shapes in the context of other shapes as opposed to considering only pairwise relations. The influence among shape similarities in an image collection is analyzed in [<CitationRef CitationID="CR46">46</CitationRef>]. Markov chains are used to perform a diffusion process on a graph formed by a set of shapes, where the influences of other shapes are propagated. The approach introduces a locally constrained diffusion process and a method for densifying the shape space by adding synthetic points. A shortest path propagation algorithm was proposed in [<CitationRef CitationID="CR44">44</CitationRef>], which is a graph-based algorithm for shape/object retrieval. Given a query object and a target database object, it explicitly finds the shortest path between them in the distance manifold of the database objects. Then a new distance measure is learned based on the shortest path and is used to replace the original distance measure. Another approach based on propagating the similarity information in a weighted graph is proposed in [<CitationRef CitationID="CR47">47</CitationRef>] and called by <Emphasis Type="Italic">affinity learning</Emphasis>. Instead of propagating the similarity information on the original graph, it uses a tensor product graph (TPG) obtained by the tensor product of the original graph with itself.</Para>
                <Para>A method that exploits the shape similarity scores is proposed in [<CitationRef CitationID="CR21">21</CitationRef>]. This method uses an unsupervised clustering algorithm, aiming to capture the manifold structure of the image relations by defining a neighborhood for each data point in terms of a mutual <InlineEquation ID="IEq2"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq2.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$k$$]]></EquationSource></InlineEquation>-nearest neighbor graph. The Distance Optimization Algorithm (DOA) is presented in [<CitationRef CitationID="CR31">31</CitationRef>]. DOA considers an iterative clustering approach based on distances correlation and on the similarity of ranked lists. The algorithm explores the fact that if two images are similar, their distances to other images and therefore their ranked lists should be similar as well.</Para>
                <Para>Recently, <Emphasis Type="Italic">contextual information</Emphasis> has also been considered for improving the effectiveness of image retrieval  [<CitationRef CitationID="CR19">19</CitationRef>, <CitationRef CitationID="CR33">33</CitationRef>, <CitationRef CitationID="CR36">36</CitationRef>, <CitationRef CitationID="CR49">49</CitationRef>]. The objective of these methods is somehow mimic the human behavior on judging the similarity among objects by considering specific <Emphasis Type="Italic">contexts</Emphasis>. More specifically, the notion of <Emphasis Type="Italic">context</Emphasis> can refer to updating image similarity measures by taking into account information encoded on the ranked lists defined by a CBIR system [<CitationRef CitationID="CR36">36</CitationRef>]. Similar to approaches based on global ranking, these methods take information about relationships among images for re-ranking. In [<CitationRef CitationID="CR33">33</CitationRef>], the notion of context refers to the nearest neighbors of a query image. A similarity measure is proposed for assessing how similar two ranked lists are. An extension of this approach was proposed in [<CitationRef CitationID="CR36">36</CitationRef>]. A clustering method is used for representing the contextual information. In [<CitationRef CitationID="CR33">33</CitationRef>], a family of contextual measures of similarity between distributions is introduced. These contextual measures are then used in the image retrieval problem as a re-ranking method.</Para>
                <Para>The <Emphasis Type="Italic">contextual re-ranking algorithm</Emphasis> proposed in this paper aims to exploit contextual information for image re-ranking tasks. An important novelty of the contextual re-ranking algorithm consists in the use of image processing techniques for contextual information representation and processing. The proposed method is flexible in the sense that it can be easily tailored to different CBIR tasks, considering shape, color and texture descriptors. Furthermore, it can also be used for rank aggregation and for combining post-processing methods.</Para>
              </Section2>
              <Section2 ID="Sec4">
                <Heading>Rank aggregation</Heading>
                <Para>Different CBIR descriptors produce different rankings. Further, it is intuitive that different descriptors may provide different but complementary information about images, and therefore their combination may improve ranking performance. An approach for improving CBIR systems consists in using <Emphasis Type="Italic">rank aggregation</Emphasis> techniques. Basically, rank aggregation approaches aim to combine different rankings in order to obtain a more accurate one.</Para>
                <Para>Although rank aggregation problem has a long and interesting history that goes back at least two centuries [<CitationRef CitationID="CR14">14</CitationRef>, <CitationRef CitationID="CR26">26</CitationRef>], it has been receiving great attention by the computer community in the last few decades. Rank aggregation is being employed in many new applications [<CitationRef CitationID="CR14">14</CitationRef>, <CitationRef CitationID="CR26">26</CitationRef>], such as document filtering, spam webpage detection, meta-search, word association finding, multiple search, biological databases, and similarity search. Commonly, different rank aggregation approaches consider that objects highly ranked in many ranked lists are likely to be relevant [<CitationRef CitationID="CR7">7</CitationRef>]. For estimating the relevance of an object, given a ranked list, both <Emphasis Type="Italic">rank positions</Emphasis> [<CitationRef CitationID="CR6">6</CitationRef>] and <Emphasis Type="Italic">retrieval scores</Emphasis> [<CitationRef CitationID="CR16">16</CitationRef>] are considered.</Para>
                <Para>Recently, learning to rank approaches are being considered [<CitationRef CitationID="CR15">15</CitationRef>]. Their objective is to use machine learning techniques to combine different CBIR descriptors. Rank aggregation can also be thought as an unsupervised regression, in which the goal is to find an aggregate ranking that minimizes the distance to each of the given ranked lists [<CitationRef CitationID="CR37">37</CitationRef>]. It can also be seen as the problem of finding a ranking of a set of elements that is “closest to” a given set of input rankings of the elements [<CitationRef CitationID="CR13">13</CitationRef>, <CitationRef CitationID="CR14">14</CitationRef>, <CitationRef CitationID="CR35">35</CitationRef>].</Para>
                <Para>In general, using supervised or unsupervised techniques, rank aggregation methods consider only scores or positions for producing new rankings. The rich contextual information encoded in relationships among images is ignored. In this paper, we exploit these relationships for rank aggregation.</Para>
                <Para>Different from the aforementioned methods, in our work, the similarity (in terms of effectiveness measures) between descriptors to be combined is considered for rank aggregation tasks. It is expected that uncorrelated systems would produce different rankings of the relevant objects, even when the overlap in the provided ranked lists is high. This observation is consistent with the statement that the combination with the lowest error occurs when the classifiers are independent and non-correlated [<CitationRef CitationID="CR7">7</CitationRef>].</Para>
              </Section2>
            </Section1>
            <Section1 ID="Sec5">
              <Heading>Problem definition</Heading>
              <Para>This section presents a formal definition for problems discussed in this paper. Section <InternalRef RefID="Sec6">3.1</InternalRef> presents a definition of the re-ranking problem considering contextual information. Section <InternalRef RefID="Sec7">3.2</InternalRef> presents a definition of the rank aggregation problem.</Para>
              <Section2 ID="Sec6">
                <Heading>Re-ranking method</Heading>
                <Para>Let <InlineEquation ID="IEq3"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq3.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ C} =\{\text{img}_{1}, {\text{img}}_{2},\dots , {\text{img}}_{N}\}$$]]></EquationSource></InlineEquation> be an <Emphasis Type="Italic">image collection</Emphasis>.</Para>
                <Para>Let <InlineEquation ID="IEq4"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq4.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ D} $$]]></EquationSource></InlineEquation> be an <Emphasis Type="Italic">image descriptor</Emphasis> which can be defined [<CitationRef CitationID="CR8">8</CitationRef>] as a tuple <InlineEquation ID="IEq5"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq5.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(\epsilon ,\rho )$$]]></EquationSource></InlineEquation>, where<UnorderedList Mark="Dash"><ItemContent><Para><InlineEquation ID="IEq6"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq6.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\epsilon : \hat{I}\rightarrow \mathbb{ R} ^{n}$$]]></EquationSource></InlineEquation><Emphasis Type="Italic"> is a function, which extracts a feature vector</Emphasis><InlineEquation ID="IEq7"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq7.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$v_{\hat{I}}$$]]></EquationSource></InlineEquation><Emphasis Type="Italic">from an image</Emphasis><InlineEquation ID="IEq8"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq8.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\hat{I}$$]]></EquationSource></InlineEquation>. </Para></ItemContent><ItemContent><Para><InlineEquation ID="IEq9"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq9.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\rho : \mathbb{ R} ^{n} \times \mathbb{ R} ^{n} \rightarrow \mathbb{ R} $$]]></EquationSource></InlineEquation><Emphasis Type="Italic">is a distance function that computes the distance between two images as a function of the distance between their corresponding feature vectors.</Emphasis></Para></ItemContent></UnorderedList> In order to obtain the distance between two images <InlineEquation ID="IEq10"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq10.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i}$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq11"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq11.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{j}$$]]></EquationSource></InlineEquation> it is necessary to compute the value of <InlineEquation ID="IEq12"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq12.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\rho (\epsilon ({\text{img}}_{i}), \epsilon ({\text{img}}_{j}))$$]]></EquationSource></InlineEquation>. For simplicity and readability purposes we use the notation <InlineEquation ID="IEq13"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq13.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\rho ({\text{img}}_{i}, {\text{img}}_{j})$$]]></EquationSource></InlineEquation> along the paper.</Para>
                <Para>The distance <InlineEquation ID="IEq14"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq14.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\rho ({\text{img}}_{i}, {\text{img}}_{j})$$]]></EquationSource></InlineEquation> among all images <InlineEquation ID="IEq15"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq15.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i}, {\text{img}}_{j} \in \mathcal{ C} $$]]></EquationSource></InlineEquation> can be computed to obtain an <InlineEquation ID="IEq16"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq16.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$N \times N$$]]></EquationSource></InlineEquation> distance matrix <InlineEquation ID="IEq17"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq17.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation>. Given a query image <InlineEquation ID="IEq18"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq18.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{q}$$]]></EquationSource></InlineEquation>, we can compute a ranked list <InlineEquation ID="IEq19"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq19.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_{{\text{img}}_{q}}$$]]></EquationSource></InlineEquation> in response to the posed query by taking into account the distance matrix <InlineEquation ID="IEq20"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq20.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation>. The ranked list <InlineEquation ID="IEq21"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq21.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_{{\text{img}}_{q}}=\{{\text{img}}_{i}, {\text{img}}_{j}, \dots , {\text{img}}_{N}\}$$]]></EquationSource></InlineEquation> can be defined as a permutation of the collection <InlineEquation ID="IEq22"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq22.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ C} $$]]></EquationSource></InlineEquation>, such that, if <InlineEquation ID="IEq23"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq23.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i}$$]]></EquationSource></InlineEquation> is ranked higher than <InlineEquation ID="IEq24"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq24.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{j}$$]]></EquationSource></InlineEquation>, then <InlineEquation ID="IEq25"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq25.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\rho ({\text{img}}_{q}, {\text{img}}_{i}) < \rho ({\text{img}}_{q}, {\text{img}}_{j})$$]]></EquationSource></InlineEquation>. We can also take each image <InlineEquation ID="IEq26"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq26.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i} \in \mathcal{ C} $$]]></EquationSource></InlineEquation> as a query image <InlineEquation ID="IEq27"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq27.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{q}$$]]></EquationSource></InlineEquation>, in order to obtain a set <InlineEquation ID="IEq28"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq28.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ R} = \{R_{{\text{img}}_{1}},R_{{\text{img}}_{2}},\dots ,R_{{\text{img}}_{N}}\}$$]]></EquationSource></InlineEquation> of ranked lists for each image <InlineEquation ID="IEq29"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq29.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i} (1 \le i \le N)$$]]></EquationSource></InlineEquation> of collection <InlineEquation ID="IEq30"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq30.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ C} $$]]></EquationSource></InlineEquation>. A re-ranking method that considers relations among all images in a collection can be represented by function <InlineEquation ID="IEq31"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq31.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f_{r}$$]]></EquationSource></InlineEquation>, such that <InlineEquation ID="IEq32"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq32.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f_{r}$$]]></EquationSource></InlineEquation> takes as input the distance matrix <InlineEquation ID="IEq33"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq33.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation> and the set of ranked lists <InlineEquation ID="IEq34"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq34.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ R} $$]]></EquationSource></InlineEquation> for computing a new distance matrix <InlineEquation ID="IEq35"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq35.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\hat{A}$$]]></EquationSource></InlineEquation>:<Equation ID="Equ1"><EquationNumber>1</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ1.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \hat{A} = f_{r}(A,\mathcal{ R} ). \end{aligned}$$]]></EquationSource></Equation>Based on the distance matrix <InlineEquation ID="IEq36"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq36.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\hat{A}$$]]></EquationSource></InlineEquation>, collection images can be re-ranked, i.e., a new set of ranked lists can be obtained. The contextual re-ranking algorithm, detailed in Sect. <InternalRef RefID="Sec10">4.2</InternalRef>, consists in an implementation of function <InlineEquation ID="IEq37"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq37.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f_{r}$$]]></EquationSource></InlineEquation>.</Para>
              </Section2>
              <Section2 ID="Sec7">
                <Heading>Rank aggregation method</Heading>
                <Para>Let <InlineEquation ID="IEq38"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq38.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ C} $$]]></EquationSource></InlineEquation> be an image collection and let <InlineEquation ID="IEq39"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq39.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ D} = \{D_1, D_2, \dots , D_m\}$$]]></EquationSource></InlineEquation> be a set of <InlineEquation ID="IEq40"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq40.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$m$$]]></EquationSource></InlineEquation> image descriptors. The set of descriptors <InlineEquation ID="IEq41"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq41.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ D} $$]]></EquationSource></InlineEquation> can be used for computing a set of distances matrices <InlineEquation ID="IEq42"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq42.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ A} = \{A_1, A_2, \dots , A_m\}$$]]></EquationSource></InlineEquation>. As discussed in previous subsection, for each distance matrix <InlineEquation ID="IEq43"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq43.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{i} \in \mathcal{ A} $$]]></EquationSource></InlineEquation>, a set of ranked lists <InlineEquation ID="IEq44"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq44.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ R} _{i} = \{R_{1},R_{2},\dots ,R_{N}\}$$]]></EquationSource></InlineEquation> can be computed. Let <InlineEquation ID="IEq45"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq45.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ R} _\mathcal{ A} = \{\mathcal{ R} _{1}, \mathcal{ R} _{2}, \dots , \mathcal{ R} _{m}\}$$]]></EquationSource></InlineEquation> be a set of sets of ranked lists (one set <InlineEquation ID="IEq46"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq46.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ R} _{i}$$]]></EquationSource></InlineEquation> for each matrix <InlineEquation ID="IEq47"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq47.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ A} _{i}$$]]></EquationSource></InlineEquation>), the objective of rank aggregation methods that consider relationships among images is to use the sets <InlineEquation ID="IEq48"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq48.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ A} $$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq49"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq49.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ R} _\mathcal{ A} $$]]></EquationSource></InlineEquation> as input for computing a new distance matrix <InlineEquation ID="IEq50"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq50.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\hat{A}_{c} $$]]></EquationSource></InlineEquation>:<Equation ID="Equ2"><EquationNumber>2</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ2.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \hat{A}_{c} = f_{a} (\mathcal{ A} ,\mathcal{ R} _\mathcal{ A} ). \end{aligned}$$]]></EquationSource></Equation>Based on the combined distance matrix <InlineEquation ID="IEq51"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq51.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\hat{A}_{c}$$]]></EquationSource></InlineEquation>, a new set of ranked lists can be computed. The Contextual Rank Aggregation Algorithm, detailed in Sect. <InternalRef RefID="Sec11">4.3</InternalRef>, consists in an implementation of function <InlineEquation ID="IEq52"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq52.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f_{a}$$]]></EquationSource></InlineEquation>.</Para>
              </Section2>
            </Section1>
            <Section1 ID="Sec8">
              <Heading>Contextual methods</Heading>
              <Para>This section presents our methods for image re-ranking and rank aggregation considering contextual information. Section <InternalRef RefID="Sec9">4.1</InternalRef> discusses the contextual information representation used by our methods. Section <InternalRef RefID="Sec10">4.2</InternalRef> presents the re-ranking algorithm while Sect. <InternalRef RefID="Sec11">4.3</InternalRef> presents the rank aggregation algorithm. Finally, Sect. <InternalRef RefID="Sec12">4.4</InternalRef> discusses the use of our approach for combining re-ranking methods.</Para>
              <Section2 ID="Sec9">
                <Heading>Contextual information representation</Heading>
                <Para>Let <InlineEquation ID="IEq53"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq53.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ C} $$]]></EquationSource></InlineEquation> be an image collection and let <InlineEquation ID="IEq54"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq54.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ D} $$]]></EquationSource></InlineEquation> be an image descriptor. The distance function <InlineEquation ID="IEq55"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq55.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\rho $$]]></EquationSource></InlineEquation> defined by <InlineEquation ID="IEq56"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq56.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ D} $$]]></EquationSource></InlineEquation> can be used for computing the distance <InlineEquation ID="IEq57"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq57.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\rho ({\text{img}}_{i}, {\text{img}}_{j})$$]]></EquationSource></InlineEquation> among all images <InlineEquation ID="IEq58"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq58.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i}, {\text{img}}_{j} \in \mathcal{ C} $$]]></EquationSource></InlineEquation> in order to obtain an <InlineEquation ID="IEq59"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq59.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$N \times N$$]]></EquationSource></InlineEquation> distance matrix <InlineEquation ID="IEq60"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq60.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation>.</Para>
                <Para>Our goal is to represent the distance matrix <InlineEquation ID="IEq61"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq61.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation> as a gray scale image and to analyze this image for extracting <Emphasis Type="Italic">contextual information</Emphasis> using image processing techniques. For the gray scale image representation, referenced in this paper as <Emphasis Type="Italic">context image</Emphasis>
                  <InlineEquation ID="IEq62"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq62.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\hat{I}$$]]></EquationSource></InlineEquation>, we consider two reference images <InlineEquation ID="IEq63"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq63.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i}, {\text{img}}_{j} \in \mathcal{ C} $$]]></EquationSource></InlineEquation>.</Para>
                <Para>Let the <Emphasis Type="Italic">context image</Emphasis>
                  <InlineEquation ID="IEq64"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq64.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\hat{I}$$]]></EquationSource></InlineEquation> be a gray scale image defined by the pair <InlineEquation ID="IEq65"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq65.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(D_{I},f)$$]]></EquationSource></InlineEquation>, where <InlineEquation ID="IEq66"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq66.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$D_{I}$$]]></EquationSource></InlineEquation> is a finite set of pixels (points in <InlineEquation ID="IEq67"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq67.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathbb{ N} ^{2}$$]]></EquationSource></InlineEquation>, defined by a pair <InlineEquation ID="IEq68"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq68.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(x,y)$$]]></EquationSource></InlineEquation>) and <InlineEquation ID="IEq69"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq69.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f: D_{I} \rightarrow \mathbb{ R} $$]]></EquationSource></InlineEquation> is a function that assigns to each pixel <InlineEquation ID="IEq70"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq70.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$p \in D_{I}$$]]></EquationSource></InlineEquation> a real number. We define the values of <InlineEquation ID="IEq71"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq71.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f$$]]></EquationSource></InlineEquation> function in terms of the distance function <InlineEquation ID="IEq72"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq72.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\rho $$]]></EquationSource></InlineEquation> (encoded into matrix <InlineEquation ID="IEq73"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq73.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation>) and reference images <InlineEquation ID="IEq74"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq74.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i}, {\text{img}}_{j} \in \mathcal{ C} $$]]></EquationSource></InlineEquation>.</Para>
                <Para>Let <InlineEquation ID="IEq75"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq75.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_{i}=\{{\text{img}}_{i_1}, {\text{img}}_{i_2}, \dots , {\text{img}}_{i_N}\}$$]]></EquationSource></InlineEquation> be the ranked list defined by matrix <InlineEquation ID="IEq76"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq76.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation> considering the reference image <InlineEquation ID="IEq77"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq77.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i}$$]]></EquationSource></InlineEquation> as query image; and <InlineEquation ID="IEq78"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq78.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_{j}=\{{\text{img}}_{j_1}, {\text{img}}_{j_2}, \dots , {\text{img}}_{j_N}\}$$]]></EquationSource></InlineEquation> the ranked list of reference image <InlineEquation ID="IEq79"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq79.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{j}$$]]></EquationSource></InlineEquation>. In this way, the axis of <Emphasis Type="Italic">context image</Emphasis>
                  <InlineEquation ID="IEq80"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq80.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\hat{I}$$]]></EquationSource></InlineEquation> is ordered according to the order defined by ranked lists <InlineEquation ID="IEq81"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq81.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_{i}$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq82"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq82.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_{j}$$]]></EquationSource></InlineEquation>. Let <InlineEquation ID="IEq83"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq83.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i_x} \in R_{i}$$]]></EquationSource></InlineEquation> be an image at <InlineEquation ID="IEq84"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq84.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$x$$]]></EquationSource></InlineEquation> position of ranked list <InlineEquation ID="IEq85"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq85.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_{i}$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq86"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq86.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{j_y} \in R_{j}$$]]></EquationSource></InlineEquation> an image at <InlineEquation ID="IEq87"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq87.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$y$$]]></EquationSource></InlineEquation> position of the ranked list <InlineEquation ID="IEq88"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq88.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_{j}$$]]></EquationSource></InlineEquation>, the value of <InlineEquation ID="IEq89"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq89.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f(x,y)$$]]></EquationSource></InlineEquation> (function that defines the gray scale of pixel <InlineEquation ID="IEq90"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq90.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$p (x,y)$$]]></EquationSource></InlineEquation>) is defined as follows: <InlineEquation ID="IEq91"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq91.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f(x,y) = \bar{\rho }({\text{img}}_{i_x}, {\text{img}}_{j_y})$$]]></EquationSource></InlineEquation>, where <InlineEquation ID="IEq92"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq92.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\bar{\rho }$$]]></EquationSource></InlineEquation> is defined by the distance function <InlineEquation ID="IEq93"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq93.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\rho $$]]></EquationSource></InlineEquation> normalized in the interval [0, 255].</Para>
                <Para>An example, considering two similar reference images (from MPEG-7 dataset [<CitationRef CitationID="CR23">23</CitationRef>]), is illustrated in Fig. <InternalRef RefID="Fig1">1</InternalRef>. The respective gray scale image representing matrix <InlineEquation ID="IEq94"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq94.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation> is illustrated in Fig. <InternalRef RefID="Fig2">2</InternalRef>. An analogous example for non-similar images is shown in Figs. <InternalRef RefID="Fig3">3</InternalRef> and  <InternalRef RefID="Fig4">4</InternalRef>.</Para>
                <Para>The <Emphasis Type="Italic">context images</Emphasis> can represent a great source of information about an image collection and distance among images. A single context image contains information about all distances among images and their spatial relationship defined by the ranked lists of the reference images. In other words, a single pixel can relate four collection images: the two reference images (that define the position of the pixel, according to their ranked lists) and the two images whose distance define the grayscale value of the pixel. Another important advantage of this image representation relies on the possibility of using a large number of image processing techniques.</Para>
                <Para>In this paper, our goal is to exploit useful <Emphasis Type="Italic">contextual information</Emphasis> provided by context images. Low distance values (similar images) are associated with dark pixels in the image, while high values (non-similar images) refers to non-black pixels. Considering two similar images as reference images, the beginning of two ranked lists should have similar images as well. This behavior creates a <Emphasis Type="Italic">dark region</Emphasis> at the top left corner of a context image (as we can observe in Fig. <InternalRef RefID="Fig2">2</InternalRef>). This region represents a neighborhood of similar images with low distances.</Para>
                <Para>The top left corner represents images at the first position of the ranked lists of the two reference images, whose accuracy is higher than any other region in context image. We aim to characterize <Emphasis Type="Italic">contextual information</Emphasis> by analyzing this region using image processing techniques. These information will be used by the re-ranking method presented in next section.</Para>
                <Para>
                  <Figure Category="Standard" Float="Yes" ID="Fig1">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 1</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Similar reference images</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO3">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Fig1_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>
                  <Figure Category="Standard" Float="Yes" ID="Fig2">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 2</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Context image for similar reference images</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO4">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Fig2_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>
                  <Figure Category="Standard" Float="Yes" ID="Fig3">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 3</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Non-similar reference images</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO5">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Fig3_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>Other regions of context images could also be of interest. Considering similar reference images, the region close to the main diagonal, for example, contains more dark pixels (low distances) than the remaining of the image. Once the ranked lists of reference images are similar, pixels close to the main diagonal represent distances between similar images. The use of other regions of context images in image re-ranking tasks is left as future work.</Para>
              </Section2>
              <Section2 ID="Sec10">
                <Heading>The contextual re-ranking algorithm</Heading>
                <Para>Given an image <InlineEquation ID="IEq95"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq95.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i} \in \mathcal{ C} $$]]></EquationSource></InlineEquation>, we aim to process <Emphasis Type="Italic">contextual information</Emphasis> of <InlineEquation ID="IEq96"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq96.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i}$$]]></EquationSource></InlineEquation> by constructing <Emphasis Type="Italic">context images</Emphasis> for each one of its <Emphasis Type="Italic">k-nearest neighbors</Emphasis> (based on distance matrix <InlineEquation ID="IEq97"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq97.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation>). We use an affinity matrix <InlineEquation ID="IEq98"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq98.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> to store the results of processing <Emphasis Type="Italic">contextual information</Emphasis>. Let <InlineEquation ID="IEq99"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq99.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$N$$]]></EquationSource></InlineEquation> be the size of collection <InlineEquation ID="IEq100"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq100.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ C} $$]]></EquationSource></InlineEquation>, the affinity matrix <InlineEquation ID="IEq101"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq101.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> is an <InlineEquation ID="IEq102"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq102.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$N \times N$$]]></EquationSource></InlineEquation> matrix where <InlineEquation ID="IEq103"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq103.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W[k,l]$$]]></EquationSource></InlineEquation> represents the similarity between images <InlineEquation ID="IEq104"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq104.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_k$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq105"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq105.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_l$$]]></EquationSource></InlineEquation>.</Para>
                <Para>We use image processing techniques to process the <Emphasis Type="Italic">context images</Emphasis> that consider <InlineEquation ID="IEq106"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq106.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_i$$]]></EquationSource></InlineEquation> and each one of its <Emphasis Type="Italic">k-nearest neighbor</Emphasis> and then update the affinity matrix <InlineEquation ID="IEq107"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq107.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation>. The same process is performed for all <InlineEquation ID="IEq108"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq108.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i} \in \mathcal{ C} $$]]></EquationSource></InlineEquation>. Since all images of <InlineEquation ID="IEq109"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq109.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ C} $$]]></EquationSource></InlineEquation> are processed, the affinity matrix <InlineEquation ID="IEq110"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq110.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> is used as input for computing a new distance matrix <InlineEquation ID="IEq111"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq111.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t+1}$$]]></EquationSource></InlineEquation> (where <InlineEquation ID="IEq112"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq112.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$t$$]]></EquationSource></InlineEquation> indicates the current iteration).</Para>
                <Para>Based on the new distance matrix <InlineEquation ID="IEq113"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq113.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t+1}$$]]></EquationSource></InlineEquation>, a new set of ranked lists is computed. These steps are repeated along several iterations. Finally, after a number <InlineEquation ID="IEq114"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq114.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$T$$]]></EquationSource></InlineEquation> of iterations, a re-ranking is performed based on the final distance matrix <InlineEquation ID="IEq115"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq115.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{T}$$]]></EquationSource></InlineEquation> in order to obtain the final set of ranked lists. The main steps of contextual re-ranking algorithm are illustrated in Fig. <InternalRef RefID="Fig5">5</InternalRef>. Algorithm <InternalRef RefID="Figa">1</InternalRef> outlines the complete re-ranking method, that is detailed in the following.</Para>
                <Para>
                  <Figure Category="Standard" Float="Yes" ID="Fig4">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 4</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Context image for non-similar reference images</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO6">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Fig4_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>
                  <Figure Category="Standard" Float="Yes" ID="Fig5">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 5</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>The contextual re-ranking algorithm</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO7">
                      <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_2_Fig5_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>
                  <Figure Category="Standard" Float="No" ID="Figa">
                    <MediaObject ID="MO8">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Figa_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>The affinity matrix <InlineEquation ID="IEq132"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq132.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> is initialized with value 1 for all positions in Line 4. <Emphasis Type="Italic">Context images</Emphasis> are created in Line 7, as explained in Sect. <InternalRef RefID="Sec9">4.1</InternalRef>, considering <InlineEquation ID="IEq133"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq133.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_i$$]]></EquationSource></InlineEquation> (image being processed) and <InlineEquation ID="IEq134"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq134.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_j$$]]></EquationSource></InlineEquation> (current neighbor of <InlineEquation ID="IEq135"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq135.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_i$$]]></EquationSource></InlineEquation>) as reference images. The parameter <InlineEquation ID="IEq136"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq136.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$L$$]]></EquationSource></InlineEquation> refers to the size of the square in the top left corner of <Emphasis Type="Italic">context image</Emphasis> that will be analyzed.</Para>
                <Para>Image processing techniques are applied to <Emphasis Type="Italic">context images</Emphasis> in Line 8. Our goal is to identify dense regions of dark pixels. Dark pixels indicate low distance values and, therefore, similar images. These regions represent the set of similar images at first positions of both ranked lists whose distances to each other are low. We use a threshold for obtaining a binary image and then identify dark pixels. The threshold <InlineEquation ID="IEq137"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq137.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$l$$]]></EquationSource></InlineEquation> used is computed based on normalization given by average and maximum distance values contained in <InlineEquation ID="IEq138"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq138.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$L \times L$$]]></EquationSource></InlineEquation> square in top left corner of <Emphasis Type="Italic">context image</Emphasis>:<Equation ID="Equ3"><EquationNumber>3</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ3.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned} l = \frac{\text{avg}(\rho ({\text{img}}_{p}, {\text{img}}_{q}))}{\text{max}(\rho ({\text{img}}_{p}, {\text{img}}_{q}))} \end{aligned}$$]]></EquationSource></Equation>with <InlineEquation ID="IEq139"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq139.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$p,q < L$$]]></EquationSource></InlineEquation>.</Para>
                <Para>Next, we use a median filter for determining regions of dense black pixels. The non-linear median filter, often used for removing noise, is used in our approach aiming to correct distances among images. Basically, we consider that “<Emphasis Type="Italic">wrong</Emphasis>” distances can be considered and represented as “<Emphasis Type="Italic">noise</Emphasis>” and the median filter is used to filter this noise out. More specifically, consider a dense region of black pixels at the top left corner of a context image. It represents a set of similar images (low distances) at the top positions of ranked lists of reference images. Consider a white pixel in this region, indicating a high distance between two images. By taking into account the contextual information given by the region of the pixel (position and other close pixels), it is very likely that the distance represented by this pixel is incorrect. In this scenario, the median filter replaces the white pixel by a black pixel. Similar reasoning can be applied to isolated black pixels in white regions. We should note that, in extreme situations, in which the CBIR descriptors completely confuse similar and non-similar images, there is less contextual information available in the context images.</Para>
                <Para>Figure <InternalRef RefID="Fig6">6</InternalRef> illustrates an example of a binary image and Fig. <InternalRef RefID="Fig7">7</InternalRef> shows the same image after applying the median filter (with a <InlineEquation ID="IEq140"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq140.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$3 \times 3$$]]></EquationSource></InlineEquation> mask).</Para>
                <Para>
                  <Figure Category="Standard" Float="Yes" ID="Fig6">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 6</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Example of binary image</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO10">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Fig6_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>
                  <Figure Category="Standard" Float="Yes" ID="Fig7">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 7</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Example of filtered image</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO11">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Fig7_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>
                  <Figure Category="Standard" Float="Yes" ID="Fig8">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 8</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Updates of matrix <InlineEquation ID="IEq141"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq141.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation>
                        </SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO12">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Fig8_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>Line 9 updates the affinity matrix <InlineEquation ID="IEq142"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq142.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> based on the <Emphasis Type="Italic">context images</Emphasis>. For updating, only black pixels (and their positions) are considered. The objective is to give more relevance to pixels next to the origin <InlineEquation ID="IEq143"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq143.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(0,0)$$]]></EquationSource></InlineEquation>, i.e., pixels that represent the beginning of ranked lists. The importance of neighbors should also be considered: neighbors at first positions should be considered more relevant when updating <InlineEquation ID="IEq144"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq144.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation>.</Para>
                <Para>Let <InlineEquation ID="IEq145"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq145.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_i \in \mathcal{ C} $$]]></EquationSource></InlineEquation> be the current image being processed. Let <InlineEquation ID="IEq146"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq146.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_j$$]]></EquationSource></InlineEquation> be the <InlineEquation ID="IEq147"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq147.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$k$$]]></EquationSource></InlineEquation> (such that <InlineEquation ID="IEq148"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq148.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$k < K$$]]></EquationSource></InlineEquation>) neighbor of <InlineEquation ID="IEq149"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq149.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_i$$]]></EquationSource></InlineEquation>. Let <InlineEquation ID="IEq150"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq150.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_i$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq151"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq151.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_j$$]]></EquationSource></InlineEquation> be reference images and let <InlineEquation ID="IEq152"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq152.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\hat{I}(D_{I},f)$$]]></EquationSource></InlineEquation> be the <Emphasis Type="Italic">context image</Emphasis> after thresholding and applying the median filter. Let <InlineEquation ID="IEq153"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq153.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$L$$]]></EquationSource></InlineEquation> be the size of the top left corner square that should be processed and let <InlineEquation ID="IEq154"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq154.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$p(x,y) \!\in \! D_{I}$$]]></EquationSource></InlineEquation> be a black pixel <InlineEquation ID="IEq155"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq155.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(f(x,y)\!=\!0)$$]]></EquationSource></InlineEquation>, such that <InlineEquation ID="IEq156"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq156.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$x,y < L$$]]></EquationSource></InlineEquation>. The pixel <InlineEquation ID="IEq157"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq157.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$p(x,y)$$]]></EquationSource></InlineEquation> represents the distance between images <InlineEquation ID="IEq158"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq158.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_x$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq159"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq159.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_y$$]]></EquationSource></InlineEquation> such that the image <InlineEquation ID="IEq160"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq160.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_x$$]]></EquationSource></InlineEquation> is the image at the position <InlineEquation ID="IEq161"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq161.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$x$$]]></EquationSource></InlineEquation> of the ranked list <InlineEquation ID="IEq162"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq162.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_i$$]]></EquationSource></InlineEquation> and the image <InlineEquation ID="IEq163"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq163.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_y$$]]></EquationSource></InlineEquation> is the image at position <InlineEquation ID="IEq164"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq164.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$y$$]]></EquationSource></InlineEquation> of ranked list <InlineEquation ID="IEq165"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq165.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$R_j$$]]></EquationSource></InlineEquation>.</Para>
                <Para>Let <InlineEquation ID="IEq166"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq166.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$H = \sqrt{2 \times L^2}$$]]></EquationSource></InlineEquation> be the maximum distance of a pixel <InlineEquation ID="IEq167"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq167.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$p(x,y)$$]]></EquationSource></InlineEquation> to origin <InlineEquation ID="IEq168"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq168.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(0,0)$$]]></EquationSource></InlineEquation>, as illustrated in Fig. <InternalRef RefID="Fig8">8</InternalRef>. Let <InlineEquation ID="IEq169"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq169.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W[x,y]$$]]></EquationSource></InlineEquation> represent the similarity between images <InlineEquation ID="IEq170"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq170.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i_x}$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq171"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq171.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_{i_y}$$]]></EquationSource></InlineEquation>. Then, for each black pixel <InlineEquation ID="IEq172"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq172.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$p(x,y)$$]]></EquationSource></InlineEquation>, the matrix <InlineEquation ID="IEq173"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq173.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> receives five updates: the most relevant one refers to the similarity between images <InlineEquation ID="IEq174"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq174.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_x$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq175"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq175.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_y$$]]></EquationSource></InlineEquation>; two updates refer to the relationship between the reference image <InlineEquation ID="IEq176"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq176.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_i$$]]></EquationSource></InlineEquation> with images <InlineEquation ID="IEq177"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq177.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_x$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq178"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq178.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_y$$]]></EquationSource></InlineEquation>; and two updates refer to the relationships between reference image <InlineEquation ID="IEq179"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq179.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_j$$]]></EquationSource></InlineEquation> and images <InlineEquation ID="IEq180"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq180.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_x$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq181"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq181.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_y$$]]></EquationSource></InlineEquation>. Figure <InternalRef RefID="Fig9">9</InternalRef> illustrates the relationship among these images provided by each black pixel in the context image. The update of the similarity score between <InlineEquation ID="IEq182"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq182.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_x$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq183"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq183.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_y$$]]></EquationSource></InlineEquation> (the most relevant one) is computed as follows:<Equation ID="Equ4"><EquationNumber>4</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ4.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned} W[x,y] \leftarrow W[x,y] + [(K-k) \times (H / \sqrt{x^2 + y^2})]. \end{aligned}$$]]></EquationSource></Equation>
                  <Figure Category="Standard" Float="Yes" ID="Fig9"><Caption Language="En"><CaptionNumber>Fig. 9</CaptionNumber><CaptionContent><SimplePara>Relationship among images provided by a single pixel of a context image</SimplePara></CaptionContent></Caption><MediaObject ID="MO14"><ImageObject Color="Color" FileRef="MediaObjects/13735_2012_2_Fig9_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/></MediaObject></Figure>
                </Para>
                <Para>Note that low values of <InlineEquation ID="IEq184"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq184.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$k, x, y$$]]></EquationSource></InlineEquation> (the beginning of ranked lists) lead to high increments of <InlineEquation ID="IEq185"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq185.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation>. Smaller increments occur when <InlineEquation ID="IEq186"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq186.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$k$$]]></EquationSource></InlineEquation> has high values and <InlineEquation ID="IEq187"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq187.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$x,y = L$$]]></EquationSource></InlineEquation>. In this case, the term <InlineEquation ID="IEq188"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq188.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$H/\sqrt{x^2 + y^2}$$]]></EquationSource></InlineEquation> is equal to 1. The remaining four updates (relationship among reference images and images <InlineEquation ID="IEq189"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq189.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_x, {\text{img}}_y$$]]></EquationSource></InlineEquation>) are computed as follows:<Equation ID="Equ5"><EquationNumber>5</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ5.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned}&\hspace{-6pt}W[i,x] \leftarrow W[i,x] + \frac{[(K-k) \times (H / \sqrt{x^2 + y^2})]}{4} \end{aligned}$$]]></EquationSource></Equation>
                  <Equation ID="Equ6"><EquationNumber>6</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ6.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned}&\hspace{-6pt}W[i,y] \leftarrow W[i,y] + \frac{[(K-k) \times (H / \sqrt{x^2 + y^2})]}{4}\end{aligned}$$]]></EquationSource></Equation>
                  <Equation ID="Equ7"><EquationNumber>7</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ7.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned}&\hspace{-6pt}W[j,x] \leftarrow W[j,x] + \frac{[(K-k) \times (H / \sqrt{x^2 + y^2})]}{4}\end{aligned}$$]]></EquationSource></Equation>
                  <Equation ID="Equ8"><EquationNumber>8</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ8.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned}&\hspace{-6pt}W[j,y] \leftarrow W[j,y] + \frac{[(K-k) \times (H / \sqrt{x^2 + y^2})]}{4} \end{aligned}$$]]></EquationSource></Equation>Observe that these four updates have together the same weight of the first update. They are computed based on the position of <InlineEquation ID="IEq190"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq190.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_x$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq191"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq191.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_y$$]]></EquationSource></InlineEquation> (<InlineEquation ID="IEq192"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq192.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$x,y$$]]></EquationSource></InlineEquation>) in the ranked the lists of other images (reference images <InlineEquation ID="IEq193"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq193.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_i, {\text{img}}_j$$]]></EquationSource></InlineEquation>), while the first update is given by a pixel that represents the distance between images <InlineEquation ID="IEq194"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq194.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_x$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq195"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq195.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$${\text{img}}_y$$]]></EquationSource></InlineEquation>.</Para>
                <Para>When all images have been processed, and therefore an iteration has finished, the affinity matrix <InlineEquation ID="IEq196"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq196.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> presents high values for similar images. But there may be positions of <InlineEquation ID="IEq197"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq197.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> that was not updated (e.g., in the case of non-similar reference images), and have the initial value 1. The new distance matrix <InlineEquation ID="IEq198"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq198.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t+1}$$]]></EquationSource></InlineEquation> (Line 12 of Algorithm <InternalRef RefID="Figa">1</InternalRef>) is computed as follows:<Equation ID="Equ9"><EquationNumber>9</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ9.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned} A_{t+1}[x,y] = \left\{ \begin{array}{l@{\quad }l} 1 + \bar{A}_{t}[x,y],&\text{ if}\; W[x,y] = 1\\ 2 \times (1 / W[x,y]),&\text{ if}\; W[x,y] > 1 \\ \end{array} \right., \end{aligned}$$]]></EquationSource></Equation>where <InlineEquation ID="IEq199"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq199.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\bar{A}_{t}$$]]></EquationSource></InlineEquation> is the distance matrix <InlineEquation ID="IEq200"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq200.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t}$$]]></EquationSource></InlineEquation> normalized in the interval [0, 1]. When <InlineEquation ID="IEq201"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq201.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W[x,y] = 1$$]]></EquationSource></InlineEquation>, i.e., <InlineEquation ID="IEq202"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq202.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W[x,y]$$]]></EquationSource></InlineEquation> was not updated by Eq. <InternalRef RefID="Equ4">4</InternalRef>, we use the old distance matrix <InlineEquation ID="IEq203"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq203.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t}$$]]></EquationSource></InlineEquation> for determining values of <InlineEquation ID="IEq204"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq204.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t+1}$$]]></EquationSource></InlineEquation>. Otherwise (when <InlineEquation ID="IEq205"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq205.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W[x,y] > 1$$]]></EquationSource></InlineEquation>), values of new distance matrix <InlineEquation ID="IEq206"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq206.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t+1}$$]]></EquationSource></InlineEquation> are equal to the inverse of the values found in the affinity matrix <InlineEquation ID="IEq207"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq207.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation>. Since the smallest increment for <InlineEquation ID="IEq208"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq208.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> is 1 (and therefore <InlineEquation ID="IEq209"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq209.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W[x,y] = 2$$]]></EquationSource></InlineEquation>), the largest value of a new distance in <InlineEquation ID="IEq210"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq210.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t+1}$$]]></EquationSource></InlineEquation> is <InlineEquation ID="IEq211"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq211.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$0.5$$]]></EquationSource></InlineEquation>. Therefore, we normalize the new distance values in the interval [0, 1] by multiplying distances by 2. <InlineEquation ID="IEq212"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq212.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t+1}$$]]></EquationSource></InlineEquation> will have values in the interval [0, 2]: (a) in the interval [0, 1], if <InlineEquation ID="IEq213"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq213.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W[x,y] > 1$$]]></EquationSource></InlineEquation>, and (b) in the interval [1, 2], if <InlineEquation ID="IEq214"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq214.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W[x,y] = 1$$]]></EquationSource></InlineEquation>. A last operation is performed on the new distance matrix <InlineEquation ID="IEq215"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq215.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t+1}$$]]></EquationSource></InlineEquation> for ensuring the symmetry of distances between images <InlineEquation ID="IEq216"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq216.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(\rho (x,y) = \rho (y,x))$$]]></EquationSource></InlineEquation>:<Equation ID="Equ10"><EquationNumber>10</EquationNumber><MediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_Equ10.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></MediaObject><EquationSource Format="TEX"><![CDATA[$$\begin{aligned} A_{t+1}[x,y]\! \leftarrow \!A_{t+1}[y,x] \leftarrow min (A_{t+1}[x,y],A_{t+1}[y,x]). \nonumber \\ \end{aligned}$$]]></EquationSource></Equation>Finally, a re-ranking is performed based on values of <InlineEquation ID="IEq217"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq217.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{t+1}$$]]></EquationSource></InlineEquation> (Line 15 of Algorithm <InternalRef RefID="Figa">1</InternalRef>). At the end of <InlineEquation ID="IEq218"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq218.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$T$$]]></EquationSource></InlineEquation> iterations, a new computed distance matrix <InlineEquation ID="IEq219"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq219.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{T}$$]]></EquationSource></InlineEquation> and a set of new ranked list are obtained.</Para>
              </Section2>
              <Section2 ID="Sec11">
                <Heading>The contextual rank aggregation algorithm</Heading>
                <Para>The presented re-ranking algorithm can be easily tailored to rank aggregation tasks. In this section, we present the <Emphasis Type="Italic">contextual rank aggregation algorithm</Emphasis>, aiming to combine the results of different descriptors. The main idea consists in using the same iterative approach based on context images, but using the affinity matrix <InlineEquation ID="IEq220"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq220.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> for accumulating updates of different descriptors at the first iteration.</Para>
                <Para>Algorithm <InternalRef RefID="Figb">2</InternalRef> outlines the rank aggregation algorithm. We can observe that the algorithm is very similar to the re-ranking algorithm (Algorithm <InternalRef RefID="Figa">1</InternalRef>). It also considers an iterative approach and the context images for the contextual information processing. Note that the main difference relies on lines 8–13 of Algorithm <InternalRef RefID="Figb">2</InternalRef>, that are executed only at the first iteration, when different matrices <InlineEquation ID="IEq221"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq221.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A_{d} \in \mathcal{ A} $$]]></EquationSource></InlineEquation> of different descriptors are being combined.</Para>
                <Para>
                  <Figure Category="Standard" Float="No" ID="Figb">
                    <MediaObject ID="MO21">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Figb_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                </Para>
              </Section2>
              <Section2 ID="Sec12">
                <Heading>Combining post-processing methods</Heading>
                <Para>We defined a generic re-ranking algorithm as a implementation of a function <InlineEquation ID="IEq241"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq241.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f_{r} (A,\mathcal{ R} )$$]]></EquationSource></InlineEquation> in Sect. <InternalRef RefID="Sec6">3.1</InternalRef>. Both the input and output of the function <InlineEquation ID="IEq242"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq242.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f_{r}$$]]></EquationSource></InlineEquation> are given by a distance matrix (since the set of ranked lists <InlineEquation ID="IEq243"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq243.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ R} $$]]></EquationSource></InlineEquation> can be computed based on a distance matrix).</Para>
                <Para>In this way, a matrix obtained from another post- processing method (other implementation of <InlineEquation ID="IEq244"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq244.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$f_{r}$$]]></EquationSource></InlineEquation>) can be submitted to our re-ranking algorithm. Different approaches may exploit different relationships among images and further improve the effectiveness of CBIR systems. Contextual information can be exploited by our re-ranking algorithm even after other methods have already been processed. We present experiments for validating this conjecture in Sect. <InternalRef RefID="Sec23">5.4</InternalRef>.</Para>
              </Section2>
            </Section1>
            <Section1 ID="Sec13">
              <Heading>Experimental evaluation</Heading>
              <Para>In this section, we present the set of conducted experiments for demonstrating the effectiveness of our method. We analyzed and evaluated our method under several aspects. In Sect. <InternalRef RefID="Sec15">5.1</InternalRef>, we present an analysis of the Contextual Algorithm considering: the impact of parameters and image processing techniques on the re-ranking algorithm; and a brief discussion about complexity and efficiency.</Para>
              <Para>In Sect. <InternalRef RefID="Sec18">5.2</InternalRef>, we discuss the experimental results for our re-ranking method. Section <InternalRef RefID="Sec19">5.2.1</InternalRef> presents results of the use of our method for several shape descriptors, considering the well-known MPEG-7 dataset [<CitationRef CitationID="CR23">23</CitationRef>]. Sections <InternalRef RefID="Sec20">5.2.2</InternalRef> and <InternalRef RefID="Sec21">5.2.3</InternalRef> aim to validate the hypothesis that our method can be used in general image retrieval tasks. In addition to shape descriptors, we conducted experiments with color and texture descriptors.</Para>
              <Para>Section <InternalRef RefID="Sec22">5.3</InternalRef> presents experimental results of our method on rank aggregation tasks. Section <InternalRef RefID="Sec23">5.4</InternalRef> presents experimental results of our re-ranking method combined with other post-processing methods. Finally, we also conducted experiments aiming to compare our results with state-of-the-art-related post-processing and rank aggregation methods in Sect. <InternalRef RefID="Sec24">5.5</InternalRef>.</Para>
              <Para>All experiments were conducted considering all images in the collections as query images. Results presented in the paper (MAP and Recall@40 scores) represent an average score.</Para>
              <Section2 ID="Sec14">
                <Heading>Experiment 1: analysis of contextual re-ranking algorithm</Heading>
                <Para>In this section, we evaluated the contextual re-ranking algorithm with regard to different aspects. Section <InternalRef RefID="Sec15">5.1.1</InternalRef> analyzes the impact of parameters in effectiveness results. Section <InternalRef RefID="Sec16">5.1.2</InternalRef> evaluates the relevance of image processing techniques for the algorithm. Section <InternalRef RefID="Sec17">5.1.3</InternalRef> discusses aspects of efficiency and computational complexity.</Para>
                <Section3 ID="Sec15">
                  <Heading>Impact of parameters</Heading>
                  <Para>The execution of Algorithms <InternalRef RefID="Figa">1</InternalRef> and <InternalRef RefID="Figb">2</InternalRef> considers three parameters: (a) <InlineEquation ID="IEq245"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq245.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource></InlineEquation>: number of neighbors used as reference images, (b) <InlineEquation ID="IEq246"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq246.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$L$$]]></EquationSource></InlineEquation>: size of top left square of context image to be analyzed, and (c) <InlineEquation ID="IEq247"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq247.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$T$$]]></EquationSource></InlineEquation>: number of iterations that the algorithm is executed.</Para>
                  <Para>To evaluate the influence of different parameter settings on the retrieval scores and for determining the best parameters values we conducted a set of experiments. We use the MPEG-7 dataset [<CitationRef CitationID="CR23">23</CitationRef>] with the so-called bullseye score (<Emphasis Type="Italic">Recall@40</Emphasis>), which counts all matching objects within the 40 most similar candidates. The MPEG-7 data set consists of 1,400 silhouette images grouped into 70 classes. Each class has 20 different shapes. Since each class consists of 20 objects, the retrieved score is normalized with the highest possible number of hits. For distance computation, we used the CFD [<CitationRef CitationID="CR30">30</CitationRef>] shape descriptor.</Para>
                  <Para>Retrieval scores are computed ranging parameters <InlineEquation ID="IEq248"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq248.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource></InlineEquation> in the interval [1, 10] and <InlineEquation ID="IEq249"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq249.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$L$$]]></EquationSource></InlineEquation> in the interval [1, 60] (with increments of 5) for each iteration. Figures <InternalRef RefID="Fig10">10</InternalRef>, <InternalRef RefID="Fig11">11</InternalRef>, <InternalRef RefID="Fig12">12</InternalRef>, and <InternalRef RefID="Fig13">13</InternalRef> show surfaces that represent retrieval scores for iterations 1, 2, 3, and 4, respectively. For each iteration, the best retrieval score was determined.</Para>
                  <Para>We observed that the best retrieval scores increased along iterations and parameters converged for values <InlineEquation ID="IEq250"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq250.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K=7$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq251"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq251.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$L=25$$]]></EquationSource></InlineEquation>. Figure <InternalRef RefID="Fig14">14</InternalRef> illustrates the evolution of precision according to the iterations of re-ranking algorithm. The best retrieval score was reached at iteration <InlineEquation ID="IEq252"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq252.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$T=5$$]]></EquationSource></InlineEquation>: <Emphasis Type="Bold">95.71%</Emphasis>. Note that these parameters may change for datasets with very different sizes. The parameter values <InlineEquation ID="IEq253"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq253.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K=7, L=25$$]]></EquationSource></InlineEquation>, and <InlineEquation ID="IEq254"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq254.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$T=5$$]]></EquationSource></InlineEquation> were used for all experiments, except for Soccer color dataset (described in Scet. <InternalRef RefID="Sec21">5.2.3</InternalRef>). Since this dataset is very smaller than others, we used <InlineEquation ID="IEq255"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq255.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K=3$$]]></EquationSource></InlineEquation>.</Para>
                  <Para>
                    <Figure Category="Standard" Float="Yes" ID="Fig10">
                      <Caption Language="En">
                        <CaptionNumber>Fig. 10</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Iteration 1: 91.84%, <InlineEquation ID="IEq256"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq256.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K=5, L=50$$]]></EquationSource></InlineEquation>
                          </SimplePara>
                        </CaptionContent>
                      </Caption>
                      <MediaObject ID="MO22">
                        <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_2_Fig10_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                      </MediaObject>
                    </Figure>
                  </Para>
                  <Para>
                    <Figure Category="Standard" Float="Yes" ID="Fig11">
                      <Caption Language="En">
                        <CaptionNumber>Fig. 11</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Iteration 2: 94.41%, <InlineEquation ID="IEq257"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq257.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K=7, L=25$$]]></EquationSource></InlineEquation>
                          </SimplePara>
                        </CaptionContent>
                      </Caption>
                      <MediaObject ID="MO23">
                        <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_2_Fig11_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                      </MediaObject>
                    </Figure>
                  </Para>
                  <Para>
                    <Figure Category="Standard" Float="Yes" ID="Fig12">
                      <Caption Language="En">
                        <CaptionNumber>Fig. 12</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Iteration 3: 95.29%, <InlineEquation ID="IEq258"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq258.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K=7, L=25$$]]></EquationSource></InlineEquation>
                          </SimplePara>
                        </CaptionContent>
                      </Caption>
                      <MediaObject ID="MO24">
                        <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_2_Fig12_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                      </MediaObject>
                    </Figure>
                  </Para>
                  <Para>
                    <Figure Category="Standard" Float="Yes" ID="Fig13">
                      <Caption Language="En">
                        <CaptionNumber>Fig. 13</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Iteration 4: 95.66%, <InlineEquation ID="IEq259"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq259.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K=7, L=25$$]]></EquationSource></InlineEquation>
                          </SimplePara>
                        </CaptionContent>
                      </Caption>
                      <MediaObject ID="MO25">
                        <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_2_Fig13_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                      </MediaObject>
                    </Figure>
                  </Para>
                  <Para>
                    <Figure Category="Standard" Float="Yes" ID="Fig14">
                      <Caption Language="En">
                        <CaptionNumber>Fig. 14</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Impact of iterations on precision</SimplePara>
                        </CaptionContent>
                      </Caption>
                      <MediaObject ID="MO26">
                        <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_2_Fig14_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                      </MediaObject>
                    </Figure>
                  </Para>
                </Section3>
                <Section3 ID="Sec16">
                  <Heading>Impact of image processing techniques</Heading>
                  <Para>In this section, we aim to evaluate the impact of the image processing techniques in effectiveness results. For the experiments, we consider the MPEG-7 [<CitationRef CitationID="CR23">23</CitationRef>] dataset (with Recall@40 score), the CFD [<CitationRef CitationID="CR30">30</CitationRef>] shape descriptor and the parameters values defined in Sect. <InternalRef RefID="Sec15">5.1.1</InternalRef>. We evaluated the method with regard to the follows aspects:<UnorderedList Mark="Dash"><ItemContent><Para><Emphasis Type="Bold">Median filter:</Emphasis> we have disabled the median filter (considering only the thresholding). The retrieval score obtained was 93.94%. </Para></ItemContent><ItemContent><Para><Emphasis Type="Bold">Thresholding:</Emphasis> we have disabled the thresholding and filter steps (considering updating for all pixels in context images). The effectiveness result obtained was 92.89%. </Para></ItemContent><ItemContent><Para><Emphasis Type="Bold">Masks of median filter:</Emphasis> we evaluated the effectiveness of the method for different sizes of masks (3, 5, and 7). We have obtained for masks 3, 5, and 7, respectively, <Emphasis Type="Bold">95.71</Emphasis>, 95.36, and 95.18%. </Para></ItemContent></UnorderedList>
                  </Para>
                  <Table Float="Yes" ID="Tab1">
                    <Caption Language="En">
                      <CaptionNumber>Table 1</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Contextual re-ranking evaluation in content-based image retrieval tasks</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <tgroup cols="6">
                      <colspec align="left" colname="c1" colnum="1"/>
                      <colspec align="left" colname="c2" colnum="2"/>
                      <colspec align="left" colname="c3" colnum="3"/>
                      <colspec align="left" colname="c4" colnum="4"/>
                      <colspec align="left" colname="c5" colnum="5"/>
                      <colspec align="left" colname="c6" colnum="6"/>
                      <thead>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>Descriptor</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Type</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Dataset</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>Score (MAP) (%)</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>Contextual re-ranking (%)</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>Gain (%)</SimplePara>
                          </entry>
                        </row>
                      </thead>
                      <tbody>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>SS [<CitationRef CitationID="CR9">9</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>MPEG-7</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>37.67</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>44.79</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+18.90</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>BAS [<CitationRef CitationID="CR2">2</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>MPEG-7</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>71.52</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>76.60</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+7.10</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>MPEG-7</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>81.70</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>87.39</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+6.96</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>ASC [<CitationRef CitationID="CR25">25</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>MPEG-7</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>85.28</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>89.82</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+5.32</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>CFD [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>MPEG-7</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>80.71</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>92.76</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+14.93</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>AIR [<CitationRef CitationID="CR17">17</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>MPEG-7</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>89.39</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>94.49</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+5.71</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>GCH [<CitationRef CitationID="CR39">39</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Color</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Soccer</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>32.24</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>33.02</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+2.42</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>ACC [<CitationRef CitationID="CR18">18</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Color</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Soccer</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>37.23</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>39.86</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+7.06</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>BIC [<CitationRef CitationID="CR38">38</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Color</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Soccer</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>39.26</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>43.04</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+9.63</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>LBP [<CitationRef CitationID="CR27">27</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Texture</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Brodatz</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>48.40</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>49.06</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+1.37</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>CCOM [<CitationRef CitationID="CR22">22</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Texture</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Brodatz</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>57.57</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>63.67</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+10.60</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>LAS [<CitationRef CitationID="CR40">40</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Texture</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Brodatz</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>75.15</SimplePara>
                          </entry>
                          <entry align="left" colname="c5">
                            <SimplePara>78.48</SimplePara>
                          </entry>
                          <entry align="left" colname="c6">
                            <SimplePara>+4.43</SimplePara>
                          </entry>
                        </row>
                      </tbody>
                    </tgroup>
                  </Table>
                  <Para>The experimental results demonstrate the positive impact of image processing techniques in effectiveness results of contextual re-ranking algorithm. The best retrieval score was obtained when a thresholding and a median filter of mask <InlineEquation ID="IEq272"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq272.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$3 \times 3$$]]></EquationSource></InlineEquation> are used.</Para>
                </Section3>
                <Section3 ID="Sec17">
                  <Heading>Aspects of efficiency</Heading>
                  <Para>This paper focuses on the presentation of Contextual re-ranking Algorithm and its effectiveness evaluation. The focus on effectiveness is justified by the fact that the execution of the algorithm is expected to be off-line, as in other post-processing methods [<CitationRef CitationID="CR44">44</CitationRef>]. This subsection aims to briefly discuss some aspects of efficiency and computational complexity.</Para>
                  <Para>Let <InlineEquation ID="IEq273"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq273.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\mathcal{ C} $$]]></EquationSource></InlineEquation> be an image collection with <InlineEquation ID="IEq274"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq274.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$N$$]]></EquationSource></InlineEquation> images. The number of context images that should be processed is equal to <InlineEquation ID="IEq275"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq275.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(N \times K \times T)$$]]></EquationSource></InlineEquation>. The size of context images that impacts the number of updates in matrix <InlineEquation ID="IEq276"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq276.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> is given by <InlineEquation ID="IEq277"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq277.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$L^2$$]]></EquationSource></InlineEquation> pixels. Since the parameters <InlineEquation ID="IEq278"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq278.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K, T$$]]></EquationSource></InlineEquation>, and <InlineEquation ID="IEq279"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq279.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$L$$]]></EquationSource></InlineEquation> have fixed values independent of <InlineEquation ID="IEq280"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq280.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$N$$]]></EquationSource></InlineEquation>, the asymptotic computional complexity of main steps of the algorithm (image processing and <InlineEquation ID="IEq281"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq281.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> matrix updating steps) is <InlineEquation ID="IEq282"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq282.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$O(N)$$]]></EquationSource></InlineEquation>. Other steps of the algorithm have different complexities. The matrices <InlineEquation ID="IEq283"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq283.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$A$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq284"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq284.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> are recomputed <InlineEquation ID="IEq285"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq285.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(O(N^{2}))$$]]></EquationSource></InlineEquation> at each iteration. The re-ranking step computes a sort operation <InlineEquation ID="IEq286"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq286.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(O (N {\text{ log}}\,N))$$]]></EquationSource></InlineEquation> for all images <InlineEquation ID="IEq287"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq287.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(O(N^{2} {\text{ log}}\,N))$$]]></EquationSource></InlineEquation>. However, these steps admit optimizations: once the updatings for matrix <InlineEquation ID="IEq288"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq288.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$W$$]]></EquationSource></InlineEquation> impact a small subset of positions (depending on the size <InlineEquation ID="IEq289"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq289.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$L^2$$]]></EquationSource></InlineEquation> of context image), the matrices do not require to be totally recomputed and the ranked lists do not require to be totally sorted again. The contextual re-ranking algorithm can also be massively parallelized, since there is no dependence between processing of different context images at a same iteration. Optimizations and parallelization issues will be investigated in future work.</Para>
                  <Para>Also note that other post-processing methods use matrices multiplication approaches [<CitationRef CitationID="CR48">48</CitationRef>, <CitationRef CitationID="CR46">46</CitationRef>] and graph algorithms [<CitationRef CitationID="CR44">44</CitationRef>], both with complexity of <InlineEquation ID="IEq290"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq290.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$O(N^3)$$]]></EquationSource></InlineEquation>.</Para>
                  <Para>We evaluated the computation time of contextual re-ranking algorithm for MPEG-7 dataset <InlineEquation ID="IEq291"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq291.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$(N=1{,}400)$$]]></EquationSource></InlineEquation>, using the parameters defined in Sect. <InternalRef RefID="Sec15">5.1.1</InternalRef> (<InlineEquation ID="IEq292"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq292.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$K=7, L=25$$]]></EquationSource></InlineEquation> and <InlineEquation ID="IEq293"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq293.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$T=5$$]]></EquationSource></InlineEquation>), executing in a Linux PC Core 2 Quad and using a C implementation. This execution took approximately 6 s.</Para>
                </Section3>
              </Section2>
              <Section2 ID="Sec18">
                <Heading>Experiment 2: re-ranking</Heading>
                <Para>In this section, we present a set of conducted experiments for demonstrating the effectiveness of our method. Various post-processing methods [<CitationRef CitationID="CR21">21</CitationRef>, <CitationRef CitationID="CR28">28</CitationRef>, <CitationRef CitationID="CR46">46</CitationRef>, <CitationRef CitationID="CR48">48</CitationRef>] have been evaluated considering only one type of visual property (usually, either color or shape). We aim to evaluate the use of our method in a general way for several CBIR tasks. We compared results for several descriptors (shape, color, and texture) in differents datasets. The measure adopted is <Emphasis Type="Italic">mean average precision</Emphasis> (MAP), geometrically referred as the average area below precision <InlineEquation ID="IEq294"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq294.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\times $$]]></EquationSource></InlineEquation>  recall curves considering different queries. Table <InternalRef RefID="Tab1">1</InternalRef> presents results for 11 image descriptors in three different datasets. As we can be observed in Table <InternalRef RefID="Tab1">1</InternalRef>, the contextual re-ranking method presents positive effectiveness gains for all descriptors (including shape, color, and texture). The gains ranged from +1.37 to +18.90%, with 8.57% on the average. We conducted a paired <InlineEquation ID="IEq295"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq295.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$t$$]]></EquationSource></InlineEquation> test and conclude that there is a 99.9% chance of difference between the mean values (before and after the re-ranking) being statistical significantly. Next subsections present the descriptors and datasets used for shape, color, and texture experiments.</Para>
                <Section3 ID="Sec19">
                  <Heading>Shape descriptors</Heading>
                  <Para>We evaluate the use of our method with six shape descriptors considering the MPEG-7 dataset [<CitationRef CitationID="CR23">23</CitationRef>]: beam angle statistics (BAS) [<CitationRef CitationID="CR2">2</CitationRef>], segment saliences (SS) [<CitationRef CitationID="CR9">9</CitationRef>], inner distance shape context (IDSC) [<CitationRef CitationID="CR24">24</CitationRef>], contour features descriptor (CFD) [<CitationRef CitationID="CR30">30</CitationRef>] articulation-invariant representation (AIR) [<CitationRef CitationID="CR17">17</CitationRef>], and aspect shape context (ASC) [<CitationRef CitationID="CR25">25</CitationRef>]. Results of bullseye score for all descriptors are presented in Table <InternalRef RefID="Tab2">2</InternalRef>. Note that the effectiveness gains are always positive and represent very significant improvement of effectiveness, ranging from +5.29 to +16.80%, with 10.56% on average. Figure <InternalRef RefID="Fig15">15</InternalRef> presents the percentage gain obtained by contextual re-ranking algorithm for CFD [<CitationRef CitationID="CR30">30</CitationRef>] descriptor considering each of 70 shape classes in MPEG-7 dataset. Note that bullseye score was improved over 30% for several classes.</Para>
                  <Table Float="Yes" ID="Tab2">
                    <Caption Language="En">
                      <CaptionNumber>Table 2</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Contextual re-ranking for shape descriptors on the MPEG-7 dataset <Emphasis Type="Italic">(Recall@40)</Emphasis>
                        </SimplePara>
                      </CaptionContent>
                    </Caption>
                    <tgroup cols="4">
                      <colspec align="left" colname="c1" colnum="1"/>
                      <colspec align="left" colname="c2" colnum="2"/>
                      <colspec align="left" colname="c3" colnum="3"/>
                      <colspec align="left" colname="c4" colnum="4"/>
                      <thead>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>Shape descriptor</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Score (%)</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Contextual re-ranking (%)</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>Gain (%)</SimplePara>
                          </entry>
                        </row>
                      </thead>
                      <tbody>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>SS [<CitationRef CitationID="CR9">9</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>43.99</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>51.38</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+16.80</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>BAS [<CitationRef CitationID="CR2">2</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>75.20</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>82.43</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+9.61</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>85.40</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>91.84</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+7.54</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>ASC [<CitationRef CitationID="CR25">25</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>88.39</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>93.07</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+5.29</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>CFD [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>84.43</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>95.71</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+13.36</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>AIR [<CitationRef CitationID="CR17">17</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>93.67</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>99.80</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+6.54</SimplePara>
                          </entry>
                        </row>
                      </tbody>
                    </tgroup>
                  </Table>
                  <Para>
                    <Figure Category="Standard" Float="Yes" ID="Fig15">
                      <Caption Language="En">
                        <CaptionNumber>Fig. 15</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Contextual re-ranking percent gain for CFD [<CitationRef CitationID="CR30">30</CitationRef>] shape descriptor on the MPEG-7 classes</SimplePara>
                        </CaptionContent>
                      </Caption>
                      <MediaObject ID="MO27">
                        <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_2_Fig15_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                      </MediaObject>
                    </Figure>
                  </Para>
                  <Para>
                    <Figure Category="Standard" Float="Yes" ID="Fig16">
                      <Caption Language="En">
                        <CaptionNumber>Fig. 16</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Evolution of rankings along iterations on the MPEG-7 [<CitationRef CitationID="CR23">23</CitationRef>] dataset (<Emphasis Type="Italic">first column</Emphasis> contains the query image): the <Emphasis Type="Italic">first row</Emphasis> presents the results of CFD [<CitationRef CitationID="CR30">30</CitationRef>] shape descriptor; the <Emphasis Type="Italic">remaining rows</Emphasis> present the results of the <Emphasis Type="Italic">contextual re-ranking algorithm</Emphasis> for each iteration</SimplePara>
                        </CaptionContent>
                      </Caption>
                      <MediaObject ID="MO28">
                        <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_2_Fig16_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                      </MediaObject>
                    </Figure>
                  </Para>
                  <Table Float="Yes" ID="Tab3">
                    <Caption Language="En">
                      <CaptionNumber>Table 3</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Contextual rank aggregation on several content-based image retrieval tasks (mean average precision)</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <tgroup cols="4">
                      <colspec align="left" colname="c1" colnum="1"/>
                      <colspec align="left" colname="c2" colnum="2"/>
                      <colspec align="left" colname="c3" colnum="3"/>
                      <colspec align="left" colname="c4" colnum="4"/>
                      <thead>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>Image descriptors</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Type</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Dataset</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>Score (MAP) (%)</SimplePara>
                          </entry>
                        </row>
                      </thead>
                      <tbody>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>CFD [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>MPEG-7</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>80.71</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>ASC [<CitationRef CitationID="CR25">25</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>MPEG-7</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>85.28</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>CFD [<CitationRef CitationID="CR30">30</CitationRef>] + ASC [<CitationRef CitationID="CR25">25</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>MPEG-7</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">98.77</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>ACC [<CitationRef CitationID="CR18">18</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Color</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Soccer</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>37.23</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>BIC [<CitationRef CitationID="CR38">38</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Color</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Soccer</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>39.26</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>ACC [<CitationRef CitationID="CR18">18</CitationRef>] + BIC [<CitationRef CitationID="CR38">38</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Color</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Soccer</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">42.14</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>CCOM [<CitationRef CitationID="CR22">22</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Texture</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Brodatz</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>63.67</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>LAS [<CitationRef CitationID="CR40">40</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Texture</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Brodatz</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>75.15</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>CCOM [<CitationRef CitationID="CR22">22</CitationRef>] + LAS [<CitationRef CitationID="CR40">40</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Texture</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Brodatz</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">81.63</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                      </tbody>
                    </tgroup>
                  </Table>
                  <Para>
                    <Figure Category="Standard" Float="Yes" ID="Fig17">
                      <Caption Language="En">
                        <CaptionNumber>Fig. 17</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Contextual re-ranking and rank aggregation for shape descriptors</SimplePara>
                        </CaptionContent>
                      </Caption>
                      <MediaObject ID="MO29">
                        <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_2_Fig17_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                      </MediaObject>
                    </Figure>
                  </Para>
                  <Table Float="Yes" ID="Tab4">
                    <Caption Language="En">
                      <CaptionNumber>Table 4</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Combining post-processing methods using contextual re-ranking on the MPEG-7 dataset (Recall@40)</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <tgroup cols="4">
                      <colspec align="left" colname="c1" colnum="1"/>
                      <colspec align="left" colname="c2" colnum="2"/>
                      <colspec align="left" colname="c3" colnum="3"/>
                      <colspec align="left" colname="c4" colnum="4"/>
                      <thead>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>Algorithm</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Score (%)</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Contextual re-ranking (%)</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>Gain (%)</SimplePara>
                          </entry>
                        </row>
                      </thead>
                      <tbody>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>DOA [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>92.56</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">93.39</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">+0.90</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>Mutual kNN Graph [<CitationRef CitationID="CR21">21</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>93.40</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">93.68</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">+0.30</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                      </tbody>
                    </tgroup>
                  </Table>
                  <Table Float="Yes" ID="Tab5">
                    <Caption Language="En">
                      <CaptionNumber>Table 5</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Post-processing methods comparison on the MPEG-7 dataset (<Emphasis Type="Italic">Recall@40</Emphasis>)</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <tgroup cols="4">
                      <colspec align="left" colname="c1" colnum="1"/>
                      <colspec align="left" colname="c2" colnum="2"/>
                      <colspec align="left" colname="c3" colnum="3"/>
                      <colspec align="left" colname="c4" colnum="4"/>
                      <thead>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>Algorithm</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>Shape descriptor</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Score (%)</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>Gain (%)</SimplePara>
                          </entry>
                        </row>
                      </thead>
                      <tbody>
                        <row>
                          <entry align="left" nameend="c4" namest="c1">
                            <SimplePara>Shape descriptors</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>Data driven generative models (DDGM) [<CitationRef CitationID="CR42">42</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>−</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>80.03</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Contour features descriptor (CFD) [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>−</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>84.43</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Inner distance shape context (IDSC) [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>−</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>85.40</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Shape context (SC) [<CitationRef CitationID="CR4">4</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>−</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>86.80</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Aspect shape context (ASC) [<CitationRef CitationID="CR25">25</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>−</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>88.39</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Articulation-invariant representation (AIR) [<CitationRef CitationID="CR17">17</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>−</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>93.67</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" nameend="c4" namest="c1">
                            <SimplePara>Post-processing methods</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Graph transduction (LP) [<CitationRef CitationID="CR48">48</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>91.00</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+6.56</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Contextual re-ranking</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">91.84</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">+7.54</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Distance Optimization Algorithm (DOA) [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>CFD [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>92.56</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+9.63</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Contextual re-ranking</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>ASC [<CitationRef CitationID="CR25">25</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">93.07</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">+5.29</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Locally constrained diffusion process [<CitationRef CitationID="CR46">46</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>93.32</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+9.27</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Mutual kNN graph [<CitationRef CitationID="CR21">21</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>93.40</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+9.37</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Locally constrained diffusion process [<CitationRef CitationID="CR46">46</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>] + St. I [<CitationRef CitationID="CR41">41</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>93.80</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+9.84</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Locally constrained diffusion process [<CitationRef CitationID="CR46">46</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>] + St. I [<CitationRef CitationID="CR41">41</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>94.85</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+11.07</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Locally constrained diffusion process [<CitationRef CitationID="CR46">46</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>] + St. I and II [<CitationRef CitationID="CR41">41</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>95.60</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+11.94</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Contextual re-ranking</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>CFD [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">95.71</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">+13.36</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Locally constrained diffusion process [<CitationRef CitationID="CR46">46</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>ASC [<CitationRef CitationID="CR25">25</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>95.96</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+8.56</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Contextual re-ranking</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>AIR [<CitationRef CitationID="CR17">17</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">99.80</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">+6.54</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Tensor product graph [<CitationRef CitationID="CR47">47</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>AIR [<CitationRef CitationID="CR17">17</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>99.99</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>+6.75</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" nameend="c4" namest="c1">
                            <SimplePara>Combining post-processing methods</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Contextual re-ranking + DOA [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>CFD [<CitationRef CitationID="CR30">30</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">93.39</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">+10.61</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Contextual re-ranking + kNN graph [<CitationRef CitationID="CR21">21</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">93.68</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>
                              <Emphasis Type="Bold">+9.70</Emphasis>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" nameend="c4" namest="c1">
                            <SimplePara>Rank aggregation methods</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Co-transduction [<CitationRef CitationID="CR3">3</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>IDSC [<CitationRef CitationID="CR24">24</CitationRef>] + DDGM [<CitationRef CitationID="CR42">42</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>97.31</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Co-transduction [<CitationRef CitationID="CR3">3</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>SC [<CitationRef CitationID="CR4">4</CitationRef>] + DDGM [<CitationRef CitationID="CR42">42</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>97.45</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Co-transduction [<CitationRef CitationID="CR3">3</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>SC [<CitationRef CitationID="CR4">4</CitationRef>] + IDSC [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>97.72</SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Contextual re-ranking</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>CFD [<CitationRef CitationID="CR30">30</CitationRef>] + IDSC [<CitationRef CitationID="CR24">24</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">98.95</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>   Contextual re-ranking</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>CFD [<CitationRef CitationID="CR30">30</CitationRef>] + ASC [<CitationRef CitationID="CR25">25</CitationRef>]</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <Emphasis Type="Bold">99.38</Emphasis>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c4">
                            <SimplePara>−</SimplePara>
                          </entry>
                        </row>
                      </tbody>
                    </tgroup>
                  </Table>
                  <Para>The iterative behavior of the contextual re-ranking algorithm can be observed in results illustrated in Fig. <InternalRef RefID="Fig16">16</InternalRef>. The figure shows the evolution of rankings along the iterations. The first row presents 20 results for a query image (first column) according to the CFD [<CitationRef CitationID="CR30">30</CitationRef>] shape descriptor. The remaining rows present the results for each iteration of contextual re-ranking algorithm. We can observe the significant improvement in terms of precision, ranging from 40% (on the ranking computed by the CFD [<CitationRef CitationID="CR30">30</CitationRef>] descriptor) to 100% at the fifth iteration of the re-ranking algorithm.</Para>
                </Section3>
                <Section3 ID="Sec20">
                  <Heading>Texture descriptors</Heading>
                  <Para>The experiments considered three texture descriptors: local binary patterns (LBP) [<CitationRef CitationID="CR27">27</CitationRef>], local activity spectrum (LAS) [<CitationRef CitationID="CR40">40</CitationRef>], and color co-occurrence matrix (CCOM) [<CitationRef CitationID="CR22">22</CitationRef>]. We used the Brodatz [<CitationRef CitationID="CR5">5</CitationRef>] dataset, a popular dataset for texture descriptors evaluation. The Brodatz dataset is composed by 111 different textures. Each texture is divided into 16 blocks, such that 1,776 images are considered. Our re-ranking method presents positive gains, presented in Table <InternalRef RefID="Tab1">1</InternalRef>, ranging from +1.37 to 10.60%.</Para>
                </Section3>
                <Section3 ID="Sec21">
                  <Heading>Color descriptors</Heading>
                  <Para>Three color descriptors was considered for our evaluation: auto color correlograms (ACC) [<CitationRef CitationID="CR18">18</CitationRef>], border/interior pixel classification (BIC) [<CitationRef CitationID="CR38">38</CitationRef>], and global color histogram (GCH) [<CitationRef CitationID="CR39">39</CitationRef>]. The experiments were conducted on a database used in [<CitationRef CitationID="CR43">43</CitationRef>] and composed by images from seven soccer teams, containing 40 images per class. We can observe positive gains for all color descriptors, presented in Table <InternalRef RefID="Tab1">1</InternalRef>, ranging from <InlineEquation ID="IEq345"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq345.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$+$$]]></EquationSource></InlineEquation>2.42 to 9.63%.</Para>
                </Section3>
              </Section2>
              <Section2 ID="Sec22">
                <Heading>Experiment 3: rank aggregation</Heading>
                <Para>This section aims to evaluate the use of our re-ranking method to combine different CBIR descriptors. We selected two descriptors for each visual property (shape, color, and texture): descriptors with best effectiveness results are selected (except for the MPEG-7 dataset, for which the AIR [<CitationRef CitationID="CR17">17</CitationRef>] descriptor yields results very close to the maximum scores). Table <InternalRef RefID="Tab3">3</InternalRef> presents the MAP scores obtained for rank aggregation (in bold) considering these descriptors. We can observe significant gains compared with each isolated descriptors results. Figure <InternalRef RefID="Fig17">17</InternalRef> illustrates the precision <InlineEquation ID="IEq346"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq346.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$\times $$]]></EquationSource></InlineEquation> recall curves of shape descriptors CFD [<CitationRef CitationID="CR30">30</CitationRef>] and ASC [<CitationRef CitationID="CR25">25</CitationRef>] in different situations: before and after using the contextual re-ranking algorithm, and after using it for rank aggregation. As it can be observed, for both re-ranking and rank aggregation, very significant gains in terms of precision have been achieved.</Para>
              </Section2>
              <Section2 ID="Sec23">
                <Heading>Experiment 4: combining post-processing methods</Heading>
                <Para>In this section, we aim to evaluate the use of our re-ranking method combined with other post-processing methods. We considered two post-processing approaches: DOA [<CitationRef CitationID="CR30">30</CitationRef>] and Mutual kNN graph [<CitationRef CitationID="CR21">21</CitationRef>]. Table <InternalRef RefID="Tab4">4</InternalRef> presents the results for <Emphasis Type="Italic">MAP</Emphasis> and <Emphasis Type="Italic">Recall@40</Emphasis> measures. The gains are positives, ranging from <InlineEquation ID="IEq347"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq347.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$+$$]]></EquationSource></InlineEquation>0.30 to <InlineEquation ID="IEq348"><InlineMediaObject><ImageObject Color="BlackWhite" FileRef="13735_2012_2_Article_IEq348.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/></InlineMediaObject><EquationSource Format="TEX"><![CDATA[$$+$$]]></EquationSource></InlineEquation>0.90%.</Para>
              </Section2>
              <Section2 ID="Sec24">
                <Heading>Experiment 5: comparison with other approaches</Heading>
                <Para>We also evaluated our method in comparison with other state-of-the-art post-processing methods. We used the MPEG-7 dataset with the bullseye score again. Table <InternalRef RefID="Tab5">5</InternalRef> presents results of our contextual re-ranking algorithm (in bold) and several other post-processing methods in different tasks (re-ranking, rank aggregation, and combining post-processing methods). We also present the retrieval scores for some descriptors that have been used as input for these methods. We can observe that the contextual re-ranking method presents high effectiveness scores when compared with state-ot-the-art approaches. Note that our method has the best effectiveness performance when compared with all other post-processing methods in rank aggregation tasks.</Para>
              </Section2>
            </Section1>
            <Section1 ID="Sec25">
              <Heading>Conclusions</Heading>
              <Para>In this work, we have presented a new re-ranking method based on contextual information. The main idea consists in creating gray scale image representations of distance matrix and performing a re-ranking based on information extracted from these images. We conducted a large set of experiments, considering several descriptors and datasets. Experimental results demonstrate the use of our method in several image retrieval tasks based on shape, color and texture descriptors. The proposed method achieves very high effectiveness performance when compared with state-of-the-art post-processing methods on well-known datasets.</Para>
              <Para>Future work focuses on: (a) parallelizing and optimizing the proposed algorithm, (b) using other image processing techniques, as dynamic thresholding and other filtering approaches, (c) analyzing other regions of context images, and (d) investigating the use of context images for other applications (for clustering and computing the similarity between ranked lists, for example).</Para>
            </Section1>
          </Body>
          <BodyRef FileRef="BodyRef/PDF/13735_2012_Article_2.pdf" TargetType="OnlinePDF"/>
          <BodyRef FileRef="BodyRef/PDF/13735_2012_2_TEX.zip" TargetType="TEX"/>
          <ArticleBackmatter>
            <Acknowledgments>
              <Heading>Acknowledgments</Heading>
              <SimplePara>Authors thank FAEPEX, CAPES, FAPESP, CNPq, and AMD for financial support. Authors also thank DGA-UNICAMP for its support in this work.</SimplePara>
            </Acknowledgments>
            <Bibliography ID="Bib1">
              <Heading>References</Heading>
              <Citation ID="CR1">
                <CitationNumber>1.</CitationNumber>
                <BibUnstructured>Abowd GD, Dey AK, Brown PJ, Davies N, Smith M, Steggles P (1999) Towards a better understanding of context and context-awareness. In: Proceedings of the 1st international symposium on handheld and ubiquitous Computing, HUC’99, pp 304–307. doi: <ExternalRef><RefSource>10.1007/3-540-48157-5_29</RefSource><RefTarget TargetType="DOI" Address="10.1007/3-540-48157-5_29"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR2">
                <CitationNumber>2.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>N</Initials>
                    <FamilyName>Arica</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>FTY</Initials>
                    <FamilyName>Vural</FamilyName>
                  </BibAuthorName>
                  <Year>2003</Year>
                  <ArticleTitle Language="En">Bas: a perceptual shape descriptor based on the beam angle statistics</ArticleTitle>
                  <JournalTitle>Pattern Recogn Lett</JournalTitle>
                  <VolumeID>24</VolumeID>
                  <IssueID>9–10</IssueID>
                  <FirstPage>1627</FirstPage>
                  <LastPage>1639</LastPage>
                  <Occurrence Type="ZLBID">
                    <Handle>1048.68072</Handle>
                  </Occurrence>
                  <Occurrence Type="DOI">
                    <Handle>10.1016/S0167-8655(03)00002-3</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Arica N, Vural FTY (2003) Bas: a perceptual shape descriptor based on the beam angle statistics. Pattern Recogn Lett 24(9–10):1627–1639</BibUnstructured>
              </Citation>
              <Citation ID="CR3">
                <CitationNumber>3.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>X</Initials>
                    <FamilyName>Bai</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>B</Initials>
                    <FamilyName>Wang</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>X</Initials>
                    <FamilyName>Wang</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>W</Initials>
                    <FamilyName>Liu</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>Z</Initials>
                    <FamilyName>Tu</FamilyName>
                  </BibAuthorName>
                  <Year>2010</Year>
                  <ArticleTitle Language="En">Co-transduction for shape retrieval</ArticleTitle>
                  <JournalTitle>ECCV</JournalTitle>
                  <VolumeID>3</VolumeID>
                  <FirstPage>328</FirstPage>
                  <LastPage>341</LastPage>
                </BibArticle>
                <BibUnstructured>Bai X, Wang B, Wang X, Liu W, Tu Z (2010) Co-transduction for shape retrieval. ECCV 3:328–341</BibUnstructured>
              </Citation>
              <Citation ID="CR4">
                <CitationNumber>4.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>S</Initials>
                    <FamilyName>Belongie</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>J</Initials>
                    <FamilyName>Malik</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>J</Initials>
                    <FamilyName>Puzicha</FamilyName>
                  </BibAuthorName>
                  <Year>2002</Year>
                  <ArticleTitle Language="En">Shape matching and object recognition using shape contexts</ArticleTitle>
                  <JournalTitle>PAMI</JournalTitle>
                  <VolumeID>24</VolumeID>
                  <IssueID>4</IssueID>
                  <FirstPage>509</FirstPage>
                  <LastPage>522</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1109/34.993558</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Belongie S, Malik J, Puzicha J (2002) Shape matching and object recognition using shape contexts. PAMI 24(4):509–522</BibUnstructured>
              </Citation>
              <Citation ID="CR5">
                <CitationNumber>5.</CitationNumber>
                <BibBook>
                  <BibAuthorName>
                    <Initials>P</Initials>
                    <FamilyName>Brodatz</FamilyName>
                  </BibAuthorName>
                  <Year>1966</Year>
                  <BookTitle>Textures: a photographic album for artists and designers</BookTitle>
                  <PublisherName>Dover</PublisherName>
                  <PublisherLocation>USA</PublisherLocation>
                </BibBook>
                <BibUnstructured>Brodatz P (1966) Textures: a photographic album for artists and designers. Dover, USA</BibUnstructured>
              </Citation>
              <Citation ID="CR6">
                <CitationNumber>6.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>D</Initials>
                    <FamilyName>Coppersmith</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>LK</Initials>
                    <FamilyName>Fleischer</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>A</Initials>
                    <FamilyName>Rurda</FamilyName>
                  </BibAuthorName>
                  <Year>2010</Year>
                  <ArticleTitle Language="En">Ordering by weighted number of wins gives a good ranking for weighted tournaments</ArticleTitle>
                  <JournalTitle>ACM Trans Algorithms</JournalTitle>
                  <VolumeID>6</VolumeID>
                  <FirstPage>55:1</FirstPage>
                  <LastPage>55:13</LastPage>
                  <Occurrence Type="AMSID">
                    <Handle>2682624</Handle>
                  </Occurrence>
                  <Occurrence Type="DOI">
                    <Handle>10.1145/1798596.1798608</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Coppersmith D, Fleischer LK, Rurda A (2010) Ordering by weighted number of wins gives a good ranking for weighted tournaments. ACM Trans Algorithms 6:55:1–55:13</BibUnstructured>
              </Citation>
              <Citation ID="CR7">
                <CitationNumber>7.</CitationNumber>
                <BibChapter>
                  <BibAuthorName>
                    <Initials>WB</Initials>
                    <FamilyName>Croft</FamilyName>
                  </BibAuthorName>
                  <Year>2002</Year>
                  <ChapterTitle Language="En">Combining approaches to information retrieval</ChapterTitle>
                  <BibEditorName>
                    <Initials>WB</Initials>
                    <FamilyName>Croft</FamilyName>
                  </BibEditorName>
                  <Eds/>
                  <BookTitle>Advances in information retrieval. The information retrieval, vol 7</BookTitle>
                  <PublisherName>Springer</PublisherName>
                  <PublisherLocation>USA</PublisherLocation>
                  <FirstPage>1</FirstPage>
                  <LastPage>36</LastPage>
                </BibChapter>
                <BibUnstructured>Croft WB (2002) Combining approaches to information retrieval. In: Croft WB (ed) Advances in information retrieval. The information retrieval, vol 7. Springer, USA, pp 1–36</BibUnstructured>
              </Citation>
              <Citation ID="CR8">
                <CitationNumber>8.</CitationNumber>
                <BibUnstructured>da S Torres R, Falcão AX (2006) Content-based image retrieval: theory and applications. Revista de Informática Teórica e Aplicada 13(2):161–185</BibUnstructured>
              </Citation>
              <Citation ID="CR9">
                <CitationNumber>9.</CitationNumber>
                <BibUnstructured>da Torres RS, Falcão AX (2007) Contour salience descriptors for effective image retrieval and analysis. Image Vis Comput 25(1):3–13. doi: <ExternalRef><RefSource>10.1016/j.imavis.2005.12.010</RefSource><RefTarget TargetType="DOI" Address="10.1016/j.imavis.2005.12.010"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR10">
                <CitationNumber>10.</CitationNumber>
                <BibUnstructured>Dai HJ, Lai PT, Tsai RTH, Hsu WL (2010) Global ranking via data fusion. In: Proceedings of the 23rd international conference on computational linguistics: posters, COLING’10, pp 223–231</BibUnstructured>
              </Citation>
              <Citation ID="CR11">
                <CitationNumber>11.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>R</Initials>
                    <FamilyName>Datta</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>D</Initials>
                    <FamilyName>Joshi</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>J</Initials>
                    <FamilyName>Li</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>JZ</Initials>
                    <FamilyName>Wang</FamilyName>
                  </BibAuthorName>
                  <Year>2008</Year>
                  <ArticleTitle Language="En">Image retrieval: ideas, influences, and trends of the new age</ArticleTitle>
                  <JournalTitle>ACM Comput Surv</JournalTitle>
                  <VolumeID>40</VolumeID>
                  <FirstPage>5:1</FirstPage>
                  <LastPage>5:60</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1145/1348246.1348248</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Datta R, Joshi D, Li J, Wang JZ (2008) Image retrieval: ideas, influences, and trends of the new age. ACM Comput Surv 40:5:1–5:60</BibUnstructured>
              </Citation>
              <Citation ID="CR12">
                <CitationNumber>12.</CitationNumber>
                <BibUnstructured>Diaz F (2005) Regularizing ad hoc retrieval scores. In: CIKM’05, pp 672–679. doi: <ExternalRef><RefSource>10.1145/1099554.1099722</RefSource><RefTarget TargetType="DOI" Address="10.1145/1099554.1099722"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR13">
                <CitationNumber>13.</CitationNumber>
                <BibUnstructured>Dwork C, Kumar R, Naor M, Sivakumar D (2001) Rank aggregation methods for the web. In: Proceedings of the 10th international conference on World Wide Web. ACM, New York, WWW’01, pp 613–622. doi:<ExternalRef><RefSource>10.1145/371920.372165</RefSource><RefTarget Address="10.1145/371920.372165" TargetType="DOI"/></ExternalRef>
                </BibUnstructured>
              </Citation>
              <Citation ID="CR14">
                <CitationNumber>14.</CitationNumber>
                <BibUnstructured>Fagin R, Kumar R, Mahdian M, Sivakumar D, Vee E (2004) Comparing and aggregating rankings with ties. In: Proceedings of the twenty-third ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, PODS’04, pp 47–58. doi: <ExternalRef><RefSource>10.1145/1055558.1055568</RefSource><RefTarget TargetType="DOI" Address="10.1145/1055558.1055568"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR15">
                <CitationNumber>15.</CitationNumber>
                <BibUnstructured>Faria FF, Veloso A, Almeida HM, Valle E, da S Torres R, Gonçalves MA, Meira W Jr (2010) Learning to rank for content-based image retrieval. In: MIR’10, pp 285–294. doi: <ExternalRef><RefSource>10.1145/1743384.1743434</RefSource><RefTarget TargetType="DOI" Address="10.1145/1743384.1743434"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR16">
                <CitationNumber>16.</CitationNumber>
                <BibUnstructured>Fox EA, Shaw JA (1994) Combination of multiple searches. In: The second text retrieval conference (TREC-2), NIST, NIST Special Publication, vol 500–215, pp 243–252</BibUnstructured>
              </Citation>
              <Citation ID="CR17">
                <CitationNumber>17.</CitationNumber>
                <BibUnstructured>Gopalan R, Turaga P, Chellappa R (2010) Articulation-invariant representation of non-planar shapes. In: Proceedings of the 11th European conference on computer vision: part III, ECCV’10, pp 286–299. doi: <ExternalRef><RefSource>10.1007/978-3-642-15558-1_21</RefSource><RefTarget TargetType="DOI" Address="10.1007/978-3-642-15558-1_21"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR18">
                <CitationNumber>18.</CitationNumber>
                <BibUnstructured>Huang J, Kumar SR, Mitra M, Zhu WJ, Zabih R (1997) Image indexing using color correlograms. In: CVPR’97, p 762</BibUnstructured>
              </Citation>
              <Citation ID="CR19">
                <CitationNumber>19.</CitationNumber>
                <BibUnstructured>Jégou H, Harzallah H, Schmid C (2007) A contextual dissimilarity measure for accurate and efficient image search. In: CVPR, pp 1–8</BibUnstructured>
              </Citation>
              <Citation ID="CR20">
                <CitationNumber>20.</CitationNumber>
                <BibUnstructured>Ji S, Zhou K, Liao C, Zheng Z, Xue GR, Chapelle O, Sun G, Zha H (2009) Global ranking by exploiting user clicks. In: SIGIR’09, pp 35–42. doi: <ExternalRef><RefSource>10.1145/1571941.1571950</RefSource><RefTarget TargetType="DOI" Address="10.1145/1571941.1571950"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR21">
                <CitationNumber>21.</CitationNumber>
                <BibUnstructured>Kontschieder P, Donoser M, Bischof H (2009) Beyond pairwise shape similarity analysis. ACCV’09, pp 655–666. doi: <ExternalRef><RefSource>10.1007/978-3-642-12297-2_63</RefSource><RefTarget TargetType="DOI" Address="10.1007/978-3-642-12297-2_63"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR22">
                <CitationNumber>22.</CitationNumber>
                <BibUnstructured>Kovalev V, Volmer S (1998) Color co-occurence descriptors for querying-by-example. In: MMM’98, p 32</BibUnstructured>
              </Citation>
              <Citation ID="CR23">
                <CitationNumber>23.</CitationNumber>
                <BibUnstructured>Latecki LJ, Lakmper R, Eckhardt U (2000) Shape descriptors for non-rigid shapes with a single closed contour. In: CVPR, pp 424–429</BibUnstructured>
              </Citation>
              <Citation ID="CR24">
                <CitationNumber>24.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>H</Initials>
                    <FamilyName>Ling</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>DW</Initials>
                    <FamilyName>Jacobs</FamilyName>
                  </BibAuthorName>
                  <Year>2007</Year>
                  <ArticleTitle Language="En">Shape classification using the inner-distance</ArticleTitle>
                  <JournalTitle>PAMI</JournalTitle>
                  <VolumeID>29</VolumeID>
                  <IssueID>2</IssueID>
                  <FirstPage>286</FirstPage>
                  <LastPage>299</LastPage>
                  <BibArticleDOI>10.1109/TPAMI.2007.41</BibArticleDOI>
                  <Occurrence Type="DOI">
                    <Handle>10.1109/TPAMI.2007.41</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Ling H, Jacobs DW (2007) Shape classification using the inner-distance. PAMI 29(2):286–299. doi:<ExternalRef><RefSource>10.1109/TPAMI.2007.41</RefSource><RefTarget Address="10.1109/TPAMI.2007.41" TargetType="DOI"/></ExternalRef>
                </BibUnstructured>
              </Citation>
              <Citation ID="CR25">
                <CitationNumber>25.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>H</Initials>
                    <FamilyName>Ling</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>X</Initials>
                    <FamilyName>Yang</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>LJ</Initials>
                    <FamilyName>Latecki</FamilyName>
                  </BibAuthorName>
                  <Year>2010</Year>
                  <ArticleTitle Language="En">Balancing deformability and discriminability for shape matching</ArticleTitle>
                  <JournalTitle>ECCV</JournalTitle>
                  <VolumeID>3</VolumeID>
                  <FirstPage>411</FirstPage>
                  <LastPage>424</LastPage>
                </BibArticle>
                <BibUnstructured>Ling H, Yang X, Latecki LJ (2010) Balancing deformability and discriminability for shape matching. ECCV 3:411–424</BibUnstructured>
              </Citation>
              <Citation ID="CR26">
                <CitationNumber>26.</CitationNumber>
                <BibUnstructured>Liu YT, Liu TY, Qin T, Ma ZM, Li H (2007) Supervised rank aggregation. In: WWW 2007, pp 481–490</BibUnstructured>
              </Citation>
              <Citation ID="CR27">
                <CitationNumber>27.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>T</Initials>
                    <FamilyName>Ojala</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>M</Initials>
                    <FamilyName>Pietikäinen</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>T</Initials>
                    <FamilyName>Mäenpää</FamilyName>
                  </BibAuthorName>
                  <Year>2002</Year>
                  <ArticleTitle Language="En">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</ArticleTitle>
                  <JournalTitle>PAMI</JournalTitle>
                  <VolumeID>24</VolumeID>
                  <IssueID>7</IssueID>
                  <FirstPage>971</FirstPage>
                  <LastPage>987</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1109/TPAMI.2002.1017623</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Ojala T, Pietikäinen M, Mäenpää T (2002) Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. PAMI 24(7):971–987</BibUnstructured>
              </Citation>
              <Citation ID="CR28">
                <CitationNumber>28.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>G</Initials>
                    <FamilyName>Park</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>Y</Initials>
                    <FamilyName>Baek</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>HK</Initials>
                    <FamilyName>Lee</FamilyName>
                  </BibAuthorName>
                  <Year>2005</Year>
                  <ArticleTitle Language="En">Re-ranking algorithm using post-retrieval clustering for content-based image retrieval</ArticleTitle>
                  <JournalTitle>Inf Process Manag</JournalTitle>
                  <VolumeID>41</VolumeID>
                  <IssueID>2</IssueID>
                  <FirstPage>177</FirstPage>
                  <LastPage>194</LastPage>
                  <Occurrence Type="ZLBID">
                    <Handle>1080.68588</Handle>
                  </Occurrence>
                  <Occurrence Type="DOI">
                    <Handle>10.1016/j.ipm.2003.08.002</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Park G, Baek Y, Lee HK (2005) Re-ranking algorithm using post-retrieval clustering for content-based image retrieval. Inf Process Manag 41(2):177–194</BibUnstructured>
              </Citation>
              <Citation ID="CR29">
                <CitationNumber>29.</CitationNumber>
                <BibUnstructured>Pedronette DCG, da S Torres R (2010) Exploiting contextual information for image re-ranking. CIARP 1:541–548</BibUnstructured>
              </Citation>
              <Citation ID="CR30">
                <CitationNumber>30.</CitationNumber>
                <BibUnstructured>Pedronette DCG, da S Torres R (2010) Shape retrieval using contour features and distance optmization. In: VISAPP, vol 1, pp 197–202</BibUnstructured>
              </Citation>
              <Citation ID="CR31">
                <CitationNumber>31.</CitationNumber>
                <BibUnstructured>Pedronette DCG, da S Torres R (2011) Exploiting clustering approaches for image re-ranking. J Vis Languages Comput 22(6):453–466. doi: <ExternalRef><RefSource>10.1016/j.jvlc.2011.08.001</RefSource><RefTarget TargetType="DOI" Address="10.1016/j.jvlc.2011.08.001"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR32">
                <CitationNumber>32.</CitationNumber>
                <BibUnstructured>Pedronette DCG, da S Torres R (2011) Exploiting contextual information for rank aggregation. ICIP, pp 97–100. doi: <ExternalRef><RefSource>10.1109/ICIP.2011.6116726</RefSource><RefTarget TargetType="DOI" Address="10.1109/ICIP.2011.6116726"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR33">
                <CitationNumber>33.</CitationNumber>
                <BibUnstructured>Perronnin F, Liu Y, Renders JM (2009) A family of contextual measures of similarity between distributions with application to image retrieval. CVPR, pp 2358–2365</BibUnstructured>
              </Citation>
              <Citation ID="CR34">
                <CitationNumber>34.</CitationNumber>
                <BibUnstructured>Qin T, Liu TY, Zhang XD, Wang DS, Li H (2008) Global ranking using continuous conditional random fields. In: NIPS, pp 1281–1288</BibUnstructured>
              </Citation>
              <Citation ID="CR35">
                <CitationNumber>35.</CitationNumber>
                <BibUnstructured>Schalekamp F, Zuylen A (1998) Rank aggregation: together were strong. In: Proceeding. of 11th ALENEX, pp 38–51</BibUnstructured>
              </Citation>
              <Citation ID="CR36">
                <CitationNumber>36.</CitationNumber>
                <BibUnstructured>Schwander O, Nielsen F (2010) Reranking with contextual dissimilarity measures from representational Bregmanl k-means. In: VISAPP, vol 1, pp 118–122</BibUnstructured>
              </Citation>
              <Citation ID="CR37">
                <CitationNumber>37.</CitationNumber>
                <BibUnstructured>Sculley D (2007) Rank aggregation for similar items. In: SDM. doi: <ExternalRef><RefSource>10.1137/1.9781611972771.66</RefSource><RefTarget TargetType="DOI" Address="10.1137/1.9781611972771.66"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR38">
                <CitationNumber>38.</CitationNumber>
                <BibUnstructured>Stehling RO, Nascimento MA, Falcão AX (2002) A compact and efficient image retrieval approach based on border/interior pixel classification. In: CIKM’02, pp 102–109. doi: <ExternalRef><RefSource>10.1145/584792.584812</RefSource><RefTarget TargetType="DOI" Address="10.1145/584792.584812"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR39">
                <CitationNumber>39.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>MJ</Initials>
                    <FamilyName>Swain</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>DH</Initials>
                    <FamilyName>Ballard</FamilyName>
                  </BibAuthorName>
                  <Year>1991</Year>
                  <ArticleTitle Language="En">Color indexing</ArticleTitle>
                  <JournalTitle>IJCV</JournalTitle>
                  <VolumeID>7</VolumeID>
                  <IssueID>1</IssueID>
                  <FirstPage>11</FirstPage>
                  <LastPage>32</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1007/BF00130487</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Swain MJ, Ballard DH (1991) Color indexing. IJCV 7(1):11–32</BibUnstructured>
              </Citation>
              <Citation ID="CR40">
                <CitationNumber>40.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>B</Initials>
                    <FamilyName>Tao</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>BW</Initials>
                    <FamilyName>Dickinson</FamilyName>
                  </BibAuthorName>
                  <Year>2000</Year>
                  <ArticleTitle Language="En">Texture recognition and image retrieval using gradient indexing</ArticleTitle>
                  <JournalTitle>JVCIR</JournalTitle>
                  <VolumeID>11</VolumeID>
                  <IssueID>3</IssueID>
                  <FirstPage>327</FirstPage>
                  <LastPage>342</LastPage>
<Occurrence Type="DOI">
<Handle>10.1006/jvci.2000.0448</Handle>
</Occurrence>
                </BibArticle>
                <BibUnstructured>Tao B, Dickinson BW (2000) Texture recognition and image retrieval using gradient indexing. JVCIR 11(3):327–342</BibUnstructured>
              </Citation>
              <Citation ID="CR41">
                <CitationNumber>41.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>A</Initials>
                    <FamilyName>Temlyakov</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>BC</Initials>
                    <FamilyName>Munsell</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>JW</Initials>
                    <FamilyName>Waggoner</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>S</Initials>
                    <FamilyName>Wang</FamilyName>
                  </BibAuthorName>
                  <Year>2010</Year>
                  <ArticleTitle Language="En">Two perceptually motivated strategies for shape classification</ArticleTitle>
                  <JournalTitle>CVPR</JournalTitle>
                  <VolumeID>1</VolumeID>
                  <FirstPage>2289</FirstPage>
                  <LastPage>2296</LastPage>
<Occurrence Type="DOI">
<Handle>10.1109/CVPR.2010.5539912</Handle>
</Occurrence>
                </BibArticle>
                <BibUnstructured>Temlyakov A, Munsell BC, Waggoner JW, Wang S (2010) Two perceptually motivated strategies for shape classification. CVPR 1:2289–2296</BibUnstructured>
              </Citation>
              <Citation ID="CR42">
                <CitationNumber>42.</CitationNumber>
                <BibUnstructured>Tu Z, Yuille AL (2004) Shape matching and recognition-using generative models and informative features. ECCV, pp 195–209</BibUnstructured>
              </Citation>
              <Citation ID="CR43">
                <CitationNumber>43.</CitationNumber>
                <BibUnstructured>van de Weijer J, Schmid C (2006) Coloring local feature extraction. In: ECCV, vol Part II. Springer, Berlin, pp 334–348</BibUnstructured>
              </Citation>
              <Citation ID="CR44">
                <CitationNumber>44.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>J</Initials>
                    <FamilyName>Wang</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>Y</Initials>
                    <FamilyName>Li</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>X</Initials>
                    <FamilyName>Bai</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>Y</Initials>
                    <FamilyName>Zhang</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>C</Initials>
                    <FamilyName>Wang</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>N</Initials>
                    <FamilyName>Tang</FamilyName>
                  </BibAuthorName>
                  <Year>2011</Year>
                  <ArticleTitle Language="En">Learning context-sensitive similarity by shortest path propagation</ArticleTitle>
                  <JournalTitle>Pattern Recogn</JournalTitle>
                  <VolumeID>44</VolumeID>
                  <FirstPage>2367</FirstPage>
                  <LastPage>2374</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1016/j.patcog.2011.02.007</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Wang J, Li Y, Bai X, Zhang Y, Wang C, Tang N (2011) Learning context-sensitive similarity by shortest path propagation. Pattern Recogn 44:2367–2374</BibUnstructured>
              </Citation>
              <Citation ID="CR45">
                <CitationNumber>45.</CitationNumber>
                <BibUnstructured>Yang L, Ji D, Zhou G, Nie Y, Xiao G (2006) Document re-ranking using cluster validation and label propagation. In: CIKM’06, pp 690–697. doi: <ExternalRef><RefSource>10.1145/1183614.1183713</RefSource><RefTarget TargetType="DOI" Address="10.1145/1183614.1183713"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR46">
                <CitationNumber>46.</CitationNumber>
                <BibUnstructured>Yang X, Koknar-Tezel S, Latecki LJ (2009) Locally constrained diffusion process on locally densified distance spaces with applications to shape retrieval. In: CVPR, pp 357–364</BibUnstructured>
              </Citation>
              <Citation ID="CR47">
                <CitationNumber>47.</CitationNumber>
                <BibUnstructured>Yang X, Latecki LJ (2011) Affinity learning on a tensor product graph with applications to shape and image retrieval. In: IEEE conference on computer vision and pattern recognition (CVPR), pp 2369–2376. doi: <ExternalRef><RefSource>10.1109/CVPR.2011.5995325</RefSource><RefTarget TargetType="DOI" Address="10.1109/CVPR.2011.5995325"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR48">
                <CitationNumber>48.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>X</Initials>
                    <FamilyName>Yang</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>X</Initials>
                    <FamilyName>Bai</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>LJ</Initials>
                    <FamilyName>Latecki</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>Z</Initials>
                    <FamilyName>Tu</FamilyName>
                  </BibAuthorName>
                  <Year>2008</Year>
                  <ArticleTitle Language="En">Improving shape retrieval by learning graph transduction</ArticleTitle>
                  <JournalTitle>ECCV</JournalTitle>
                  <VolumeID>5305</VolumeID>
                  <FirstPage>788</FirstPage>
                  <LastPage>801</LastPage>
                </BibArticle>
                <BibUnstructured>Yang X, Bai X, Latecki LJ, Tu Z (2008) Improving shape retrieval by learning graph transduction. ECCV 5305:788–801</BibUnstructured>
              </Citation>
              <Citation ID="CR49">
                <CitationNumber>49.</CitationNumber>
                <BibUnstructured>Zhao D, Lin Z, Tang X (2007) Contextual distance for data perception. In: ICCV. doi: <ExternalRef><RefSource>10.1109/ICCV.2007.4408854</RefSource><RefTarget TargetType="DOI" Address="10.1109/ICCV.2007.4408854"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR50">
                <CitationNumber>50.</CitationNumber>
                <BibUnstructured>Zhu X (2005) Semi-supervised learning with graphs. PhD thesis, Pittsburgh, PA, USA, chair-Lafferty, John and Chair-Rosenfeld, Ronald</BibUnstructured>
              </Citation>
            </Bibliography>
          </ArticleBackmatter>
        </Article>
      </Issue>
    </Volume>
  </Journal>
</Publisher>
