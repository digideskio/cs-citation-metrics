<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE Publisher PUBLIC "-//Springer-Verlag//DTD A++ V2.4//EN" "http://devel.springer.de/A++/V2.4/DTD/A++V2.4.dtd">
<Publisher>
  <PublisherInfo>
    <PublisherName>Springer-Verlag</PublisherName>
    <PublisherLocation>London</PublisherLocation>
  </PublisherInfo>
  <Journal OutputMedium="All">
    <JournalInfo JournalProductType="ArchiveJournal" NumberingStyle="ContentOnly">
      <JournalID>13735</JournalID>
      <JournalPrintISSN>2192-6611</JournalPrintISSN>
      <JournalElectronicISSN>2192-662X</JournalElectronicISSN>
      <JournalTitle>International Journal of Multimedia Information Retrieval</JournalTitle>
      <JournalAbbreviatedTitle>Int J Multimed Info Retr</JournalAbbreviatedTitle>
      <JournalSubjectGroup>
        <JournalSubject Type="Primary">Computer Science</JournalSubject>
        <JournalSubject Type="Secondary">Information Systems Applications (incl. Internet)</JournalSubject>
        <JournalSubject Type="Secondary">Multimedia Information Systems</JournalSubject>
        <JournalSubject Type="Secondary">Computer Science, general</JournalSubject>
        <JournalSubject Type="Secondary">Image Processing and Computer Vision</JournalSubject>
        <JournalSubject Type="Secondary">Information Storage and Retrieval</JournalSubject>
        <JournalSubject Type="Secondary">Data Mining and Knowledge Discovery</JournalSubject>
        <SubjectCollection Code="Computer Science">SC6</SubjectCollection>
      </JournalSubjectGroup>
    </JournalInfo>
    <Volume OutputMedium="All">
      <VolumeInfo TocLevels="0" VolumeType="Regular">
        <VolumeIDStart>1</VolumeIDStart>
        <VolumeIDEnd>1</VolumeIDEnd>
        <VolumeIssueCount>4</VolumeIssueCount>
      </VolumeInfo>
      <Issue IssueType="Regular" OutputMedium="All">
        <IssueInfo IssueType="Regular" TocLevels="0">
          <IssueIDStart>4</IssueIDStart>
          <IssueIDEnd>4</IssueIDEnd>
          <IssueArticleCount>5</IssueArticleCount>
          <IssueHistory>
            <OnlineDate>
              <Year>2012</Year>
              <Month>10</Month>
              <Day>23</Day>
            </OnlineDate>
            <PrintDate>
              <Year>2012</Year>
              <Month>10</Month>
              <Day>22</Day>
            </PrintDate>
            <CoverDate>
              <Year>2012</Year>
              <Month>12</Month>
            </CoverDate>
            <PricelistYear>2012</PricelistYear>
          </IssueHistory>
          <IssueCopyright>
            <CopyrightHolderName>Springer-Verlag London</CopyrightHolderName>
            <CopyrightYear>2012</CopyrightYear>
          </IssueCopyright>
        </IssueInfo>
        <Article ID="s13735-012-0022-4" OutputMedium="All">
          <ArticleInfo ArticleType="OriginalPaper" ContainsESM="No" Language="En" NumberingStyle="ContentOnly" TocLevels="0">
            <ArticleID>22</ArticleID>
            <ArticleDOI>10.1007/s13735-012-0022-4</ArticleDOI>
            <ArticleSequenceNumber>1</ArticleSequenceNumber>
            <ArticleTitle Language="En" OutputMedium="All">Cost-sensitive learning in social image tagging: review, new ideas and evaluation</ArticleTitle>
            <ArticleCategory>Trends and Surveys</ArticleCategory>
            <ArticleFirstPage>205</ArticleFirstPage>
            <ArticleLastPage>222</ArticleLastPage>
            <ArticleHistory>
              <RegistrationDate>
                <Year>2012</Year>
                <Month>9</Month>
                <Day>26</Day>
              </RegistrationDate>
              <Received>
                <Year>2012</Year>
                <Month>8</Month>
                <Day>26</Day>
              </Received>
              <Revised>
                <Year>2012</Year>
                <Month>9</Month>
                <Day>23</Day>
              </Revised>
              <Accepted>
                <Year>2012</Year>
                <Month>9</Month>
                <Day>25</Day>
              </Accepted>
              <OnlineDate>
                <Year>2012</Year>
                <Month>10</Month>
                <Day>14</Day>
              </OnlineDate>
            </ArticleHistory>
            <ArticleCopyright>
              <CopyrightHolderName>Springer-Verlag London</CopyrightHolderName>
              <CopyrightYear>2012</CopyrightYear>
            </ArticleCopyright>
            <ArticleGrants Type="Regular">
              <MetadataGrant Grant="OpenAccess"/>
              <AbstractGrant Grant="OpenAccess"/>
              <BodyPDFGrant Grant="OpenAccess"/>
              <BodyHTMLGrant Grant="OpenAccess"/>
              <BibliographyGrant Grant="OpenAccess"/>
              <ESMGrant Grant="OpenAccess"/>
            </ArticleGrants>
          </ArticleInfo>
          <ArticleHeader>
            <AuthorGroup>
              <Author AffiliationIDS="Aff1">
                <AuthorName DisplayOrder="Western">
                  <GivenName>Zhenyang</GivenName>
                  <FamilyName>Li</FamilyName>
                </AuthorName>
                <Contact>
                  <Email>zhenyounglee@gmail.com</Email>
                </Contact>
              </Author>
              <Author AffiliationIDS="Aff2" CorrespondingAffiliationID="Aff2">
                <AuthorName DisplayOrder="Western">
                  <GivenName>Michael</GivenName>
                  <GivenName>S.</GivenName>
                  <FamilyName>Lew</FamilyName>
                </AuthorName>
                <Contact>
                  <Email>mlew@liacs.nl</Email>
                </Contact>
              </Author>
              <Affiliation ID="Aff1">
                <OrgName>University of Amsterdam</OrgName>
                <OrgAddress>
                  <City>Amsterdam</City>
                  <Country Code="NL">The Netherlands</Country>
                </OrgAddress>
              </Affiliation>
              <Affiliation ID="Aff2">
                <OrgName>Leiden University</OrgName>
                <OrgAddress>
                  <City>Leiden</City>
                  <Country Code="NL">The Netherlands</Country>
                </OrgAddress>
              </Affiliation>
            </AuthorGroup>
            <Abstract ID="Abs1" Language="En" OutputMedium="All">
              <Heading>Abstract</Heading>
              <Para>Visual concept learning typically requires a set of expert labeled, manual training images. However, acquiring a sufficient number of reliable annotations can be time-consuming or impractical. Therefore, in many situations it is preferable to perform unsupervised learning on user contributed tags from abundant sources such as social Internet communities and websites. Cost-sensitive learning is a natural approach toward unsupervised visual concept learning because it fundamentally optimizes the learning system accuracy regarding the cost of an error. This paper reviews the problem of cost-sensitive unsupervised learning of visual concepts from social images, presents the new ideas, and gives a comparative evaluation of representative approaches from the research literature.</Para>
            </Abstract>
            <KeywordGroup Language="En" OutputMedium="All">
              <Heading>Keywords</Heading>
              <Keyword>Visual concept learning</Keyword>
              <Keyword>Unsupervised learning</Keyword>
              <Keyword>Social images</Keyword>
              <Keyword>Social tagging</Keyword>
              <Keyword>Tag relevance learning</Keyword>
              <Keyword>Cost-sensitive learning</Keyword>
              <Keyword>Importance weighted classification</Keyword>
            </KeywordGroup>
          </ArticleHeader>
          <Body>
            <Section1 ID="Sec1">
              <Heading>Introduction</Heading>
              <Para>Visual concept learning is an important yet challenging problem in content-based multimedia information retrieval (CBMIR) areas [<CitationRef CitationID="CR1">1</CitationRef>]. It is fundamentally a classification task that determines whether an image or video shot is relevant to a given target concept. The semantic concepts can cover a wide range of topics such as those related to objects (e.g. car, lion), indoor and outdoor scenes (e.g. classroom, beach), events (e.g. parade, skiing), people, etc. Automatically detecting these concepts helps in improving text-based image or video retrieval, as well as complementing their manual annotations. However, how to effectively bridge the semantic gap between low-level visual features and high-level semantic concepts is still a key hindrance [<CitationRef CitationID="CR2">2</CitationRef>]. The performance of existing approaches can also be easily affected by the presence of intra-class variations, occlusion, background clutter, viewpoint and illumination changes in images and video clips [<CitationRef CitationID="CR3">3</CitationRef>]. In addition, another critical step along this task is the acquisition of sufficiently large amount of quality training data.</Para>
              <Para>It has been seen that large-scale data can directly benefit visual concept detection [<CitationRef CitationID="CR7">7</CitationRef>]. Rather than designing more intelligent classification algorithms and robust image features, we can simply use more data. The acquisition of reliable annotations, nevertheless, is a labor intensive process. For each concept to be learnt, training examples have to be annotated manually by expert annotators making these annotations expensive and limited. Labeling TRECVID 2010 dataset, for instance, requires collaborative annotation efforts from up to 47 research teams or organizations for 119,685 shots or keyframes with totally 130 concepts [<CitationRef CitationID="CR5">5</CitationRef>]. Such a tedious and costly manual labeling process will become extremely hard for the ultimate aim of annotating billions of images for thousands of visual concepts.</Para>
              <Para>On the other hand, with the popularity of social media, there are increasingly large amounts of images and videos available on the web. For example, Flickr now hosts over 5 billion images with roughly 10 million new uploaded photos daily [<CitationRef CitationID="CR4">4</CitationRef>] and YouTube serves close to 3 billion video views per day with 48 h of video uploaded every minute [<CitationRef CitationID="CR6">6</CitationRef>]. Apart from these rich multimedia databases, images and videos on the social networks are often accompanied by various forms of metadata like tags, ratings, comments and EXIF information.</Para>
              <Para>These social context cues offer meaningful information about the content of multimedia and make it much easier to amass training data for visual concept learning. In particular, the user-contributed tags provide valuable source of descriptive information about the visual content of images and video shots. However, these social tags tend to be uncontrolled, ambiguous and overly personalized. For example, Fig. <InternalRef RefID="Fig1">1</InternalRef>a includes two images in which the concept “bridge” and “bird” is obviously missing respectively. The photos in Fig. <InternalRef RefID="Fig1">1</InternalRef>b are labeled with some subjective tags, such as “rain”, “bus” or “horse”. These concepts are not easy to notice in the photos. The concepts “wheel” and “bridge”, in the upper image of Fig. <InternalRef RefID="Fig1">1</InternalRef>c, are ambiguous, since “wheel” is commonly referred to as a circular object under a car or bus rather than the one used to steer them, and the “bridge” here means the part of a ship where officers are controlling and steering the ship. The other photo in Fig. <InternalRef RefID="Fig1">1</InternalRef>c shows a dog wearing a rabbit costume. It is somewhat confusing to annotate it with concept either “dog” or “rabbit”. Automatically learning visual concepts from these weakly labeled web images thus appears as a nature way of replacing the expensive manual labeling. Some efforts on filtering or sampling the noisy tagged social images have been made in [<CitationRef CitationID="CR8">8</CitationRef>, <CitationRef CitationID="CR9">9</CitationRef>]. But how such weakly labeled training examples affect visual concept learning in terms of user tagging accuracy, and compared with expert-labeled ones, is yet to be addressed.<Figure Category="Standard" Float="Yes" ID="Fig1">
                  <Caption Language="En">
                    <CaptionNumber>Fig. 1</CaptionNumber>
                    <CaptionContent>
                      <SimplePara>Examples of social images with user-contributed tags. The <Emphasis Type="Italic">tags in bold</Emphasis> denote the ones we would consider their visual relevance with respect to the image content. In particular, the <Emphasis Type="Italic">tags with underlines</Emphasis> are thought of as truly relevant ones. It reveals three possible problems of social tagging: <Emphasis Type="Bold">a</Emphasis> incomplete tags, <Emphasis Type="Bold">b</Emphasis> subjective tags and <Emphasis Type="Bold">c</Emphasis> ambiguous tags.</SimplePara>
                    </CaptionContent>
                  </Caption>
                  <MediaObject ID="MO1">
                    <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_22_Fig1_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                  </MediaObject>
                </Figure>
              </Para>
              <Para>In this paper, we review and empirically compare methods of learning visual concepts from social images. First, we investigate two dominant algorithms: support vector machine (SVM) and boosting, using multiple image features for visual concept learning. In particular, a common feature combination procedure is proposed to be integrated into different variants of the boosting algorithm. Second, to analyze social tagging, we discuss a visual neighbor voting model to learn the visual relevance of tags with respect to the image content.</Para>
              <Para>This model was inspired by recent successful tag relevance learning methods [<CitationRef CitationID="CR10">10</CitationRef>–<CitationRef CitationID="CR12">12</CitationRef>], that propagate the annotation tags of training images to a target image. We summarize their work by literature-based weighting schemes, i.e. using uniform, distance-based and rank-based weights for each visually similar image, associated with a weighted nearest neighbor model. We also discuss a variation of cost sensitive learning called “importance weighted” classification that incorporates the example-dependent importance weights into the learning frameworks of SVM and boosting classifiers. These importance weights are based on the tag relevance learned by visual neighbor voting, since more relevant example images have to be emphasized more in the training process for a given concept. Therefore, we aim to discriminate between different training examples by their importance weights in the classifier learning procedure using cost-sensitive learning techniques. Apart from this, all the proposed algorithms are evaluated by both the socially tagged and manually tagged images so as to explore the impact of the user-contributed tags, in terms of tagging accuracy, towards visual concept learning, and in comparison with manual annotations.</Para>
              <Para>The remaining sections are organized as follows. Section <InternalRef RefID="Sec2">2</InternalRef> reviews some related works on visual concept learning and social image analysis. In Sect. <InternalRef RefID="Sec5">3</InternalRef>, we introduce and discuss the traditional SVM and boosting algorithms for visual concept learning using multiple image features. A visual neighbor voting model to exploit the tag relevance of social images is presented in Sect. <InternalRef RefID="Sec8">4</InternalRef>. Section <InternalRef RefID="Sec12">5</InternalRef> describes the cost-sensitive learning problem and introduces the importance weighted extensions of SVM and boosting classifiers instead of directly learning visual concepts from weakly labeled social images. The experimental setup is described in Sect. <InternalRef RefID="Sec20">6</InternalRef> and the comparative results are presented in Sect. <InternalRef RefID="Sec26">7</InternalRef>. Finally, we give conclusions in Sect. <InternalRef RefID="Sec31">8</InternalRef>.</Para>
            </Section1>
            <Section1 ID="Sec2">
              <Heading>Related work</Heading>
              <Section2 ID="Sec3">
                <Heading>Visual concept learning</Heading>
                <Para>The large-scale visual concept detection and annotation task (LS-VCDT) in ImageCLEF 2009 [<CitationRef CitationID="CR13">13</CitationRef>] used the MIR Flickr collection [<CitationRef CitationID="CR14">14</CitationRef>] as the benchmarking dataset. In total, 53 semantic concepts were evaluated and the team with the best results achieved an average AUC of 84 % on their best run [<CitationRef CitationID="CR15">15</CitationRef>]. In their approach, they extract SIFT-like features encoded with “bag-of-words” model in different color spaces. Both salient point detector and dense grid are used for point sampling and in combination with spatial pyramid. The concept classifiers are trained using SVMs with <InlineEquation ID="IEq1">
                    <EquationSource Format="TEX"><![CDATA[$$\chi ^2$$]]></EquationSource>
                  </InlineEquation> kernel.</Para>
                <Para>Overall, the current state-of-the-art approaches in visual concept learning and annotation tasks are based on the “bag-of-words” model obtained by clustering of SIFT-like features. Within the “bag-of-words” representation, different point sampling strategies (e.g. keypoint detector or dense sampling), choices of descriptors (e.g. SIFT or SURF) and visual word assignment (e.g. hard or soft assignment) have also been studied. Specifically, salient point detectors, such as Laplace-of-Gaussian [<CitationRef CitationID="CR16">16</CitationRef>] and Harris-Laplace [<CitationRef CitationID="CR17">17</CitationRef>] based detectors, introduce robustness against viewpoint and illumination changes. Nowak et al. [<CitationRef CitationID="CR18">18</CitationRef>] showed that sampling on a regular dense grid in a uniform fashion consistently outperforms complex salient point methods in scene classification, since using more image patches means that more of the appearance of an image can be captured. However, salient points have the advantages of ignoring the homogenous areas in the image which is superior for object detection. SIFT [<CitationRef CitationID="CR19">19</CitationRef>] and SURF [<CitationRef CitationID="CR20">20</CitationRef>] are two commonly used local feature descriptors. Uijlings et al. [<CitationRef CitationID="CR21">21</CitationRef>] presented several improvements upon speeding up the calculation of densely sampled SIFT and SURF descriptors for real-time classification.</Para>
                <Para>Additionally, visual vocabularies can be created with <Emphasis Type="Italic">k</Emphasis>-means clustering or tree-based algorithms (e.g. Random Forests [<CitationRef CitationID="CR22">22</CitationRef>]). Each descriptor is typically assigned to a single predefined visual word. But it has been shown that assigning each descriptor to multiple visual words using soft assignment is beneficial [<CitationRef CitationID="CR23">23</CitationRef>]. Beyond the “bag-of-words” model, Lazebnik et al. [<CitationRef CitationID="CR24">24</CitationRef>] proposed to use spatial pyramids of local features to encode a weak form of spatial information. It works by partitioning an image into increasingly fine sub-regions and then the histograms of local features found inside each sub-region are computed and weighted according to their pyramid levels. Another idea is to construct a hierarchical organization of the visual vocabulary aiming to obtain more discriminative image representations. Spatial patterns of low-level visual words can be combined in to intermediate-level phrases or even sentences of visual words [<CitationRef CitationID="CR25">25</CitationRef>].</Para>
                <Para>Support vector machine classification has been widely used for its outstanding performance and robustness against large feature vectors. The choice of kernel functions is quite important to the classification performance. Zhang et al. [<CitationRef CitationID="CR26">26</CitationRef>] determined that in a “bag-of-words” approach to concept detection, the earth movers’ distance and <InlineEquation ID="IEq2">
                    <EquationSource Format="TEX"><![CDATA[$$\chi ^2$$]]></EquationSource>
                  </InlineEquation> kernel give the best accuracy and are to be preferred. Due to computational efficiency, Maji et al. [<CitationRef CitationID="CR27">27</CitationRef>] proposed an efficient classification method using SVMs with histogram intersection kernels. Boosting is another popular classification algorithm which has been successfully used for face recognition and object detection [<CitationRef CitationID="CR28">28</CitationRef>, <CitationRef CitationID="CR29">29</CitationRef>].</Para>
                <Para>Moreover, Huiskes et al. [<CitationRef CitationID="CR7">7</CitationRef>] also pointed out that large-scale training data can directly benefit visual concept learning. Rather than designing more intelligent classification algorithms and robust image features, we can simply use more data. However, manually annotated image collections are usually size-limited due to the labor intensive process of manual labeling.</Para>
              </Section2>
              <Section2 ID="Sec4">
                <Heading>Social tagging analysis</Heading>
                <Para>The media on the social networking websites (e.g. Flickr, YouTube and Facebook) are often linked with various forms of metadata, such as tags, ratings, comments and EXIF information. This abundance of social data makes it much easier to amass training examples which could lead to performance improvements of classic visual concept learning systems. As shown in [<CitationRef CitationID="CR7">7</CitationRef>] and [<CitationRef CitationID="CR30">30</CitationRef>], the social data, in particular, the user-contributed tags, can serve directly as image features for learning visual concepts. Particularly for the concepts that are difficult to learn with low-level visual features alone, the improvements are often considerable.</Para>
                <Para>Despite the high popularity and advantages of social tagging, it is well known that tags provided by typical Internet users may be inconsistent and incomplete. The study in [<CitationRef CitationID="CR31">31</CitationRef>] revealed that user-provided tags are imprecise and only 50 % of tags are related to the image content. Bischoff et al. [<CitationRef CitationID="CR32">32</CitationRef>] provided the tag distributions in three tagging environments. Their study indicated that there were a variety of user tagging motivations, such as opinion expression, self-presentation or attraction of attention. And only 45–50 % of tags can be used to enhance search experience. Aiming for improving tagging quality, an effort on tag refinement was made by Liu et al. [<CitationRef CitationID="CR33">33</CitationRef>]. They estimate the initial tag relevance scores based on probability density estimation and adopted random walk over a tag similarity graph to refine the relevance scores.</Para>
                <Para>Another idea of learning visual relevance of the user-supplied tags with respect to the image content is based on the intuition that if users label visually similar images using the same tags, these tags are likely to reflect objective aspects of the visual content. Li et al. [<CitationRef CitationID="CR11">11</CitationRef>] and Verbeek et al. [<CitationRef CitationID="CR30">30</CitationRef>] proposed to propagate the annotation tags of training images to a target image by considering the presence of tags in its visual neighbors. Additionally, Ulges et al. [<CitationRef CitationID="CR34">34</CitationRef>] provided a probabilistic framework for detecting semantic concepts from weakly annotated training videos in the presence of irrelevant content. In their approach, the relevance of keyframes in the sequence is modeled as a latent random variable which is estimated during training. Therefore, we consider such exploitation of social tagging as a good starting point to aid visual concept learning.</Para>
              </Section2>
            </Section1>
            <Section1 ID="Sec5">
              <Heading>Learning visual concepts</Heading>
              <Section2 ID="Sec6">
                <Heading>SVM</Heading>
                <Para>Support vector machine algorithm constructs a hyperplane or set of hyperplanes in a high-dimensional space, which can be used for classification and regression analysis. It is a representation of the examples as points in space, mapped so that a good separation is achieved by the hyperplane that has the largest margin between the training data points of different classes, since in general the larger the margin the lower the generalization error of the classifier. Let <InlineEquation ID="IEq3">
                    <EquationSource Format="TEX"><![CDATA[$$S=\{(x_i ,\;y_i )\vert i=1,\ldots ,N\}\subset \mathbf{R}^d\times \{-1, +1\}$$]]></EquationSource>
                  </InlineEquation> be the training samples, the two-class soft-margin SVM model which allows for misclassified examples works by solving the following optimization problem:<Equation ID="Equ1">
                    <EquationNumber>1</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \mathop {\min }\limits _{\mathbf{w },b,\xi } \frac{1}{2}\left\Vert \mathbf{w } \right\Vert_\mathcal{H }^2 +C\sum \limits _{i=1}^N {\xi _i } \end{aligned}$$]]></EquationSource>
                  </Equation>
                  <Equation ID="Equ2">
                    <EquationNumber>2</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} s.t.\quad y_i (\mathbf{w }\cdot \varphi (x_i )+b)&\ge 1-\xi _i \nonumber \\ \xi _i&\ge 0 \end{aligned}$$]]></EquationSource>
                  </Equation>The non-zero slack variable <InlineEquation ID="IEq4">
                    <EquationSource Format="TEX"><![CDATA[$$\xi _i $$]]></EquationSource>
                  </InlineEquation> expresses how much the example <InlineEquation ID="IEq5">
                    <EquationSource Format="TEX"><![CDATA[$$x_i $$]]></EquationSource>
                  </InlineEquation> fails to have the required margin, so it is introduced to measure the degree of misclassification in the optimization function (<InternalRef RefID="Equ1">1</InternalRef>). <InlineEquation ID="IEq6">
                    <EquationSource Format="TEX"><![CDATA[$$\xi _i $$]]></EquationSource>
                  </InlineEquation> takes a value greater than <InlineEquation ID="IEq7">
                    <EquationSource Format="TEX"><![CDATA[$$1$$]]></EquationSource>
                  </InlineEquation> if the corresponding training example lies to the wrong side of the decision boundary. Therefore, <InlineEquation ID="IEq8">
                    <EquationSource Format="TEX"><![CDATA[$$\sum \nolimits _i {\xi _i } $$]]></EquationSource>
                  </InlineEquation> indicates an upper bound on the total number of training errors. <InlineEquation ID="IEq9">
                    <EquationSource Format="TEX"><![CDATA[$$C>0$$]]></EquationSource>
                  </InlineEquation> is a regularization constant which determines the trade-off between the empirical risk and model complexity. By means of applying the kernel trick <InlineEquation ID="IEq10">
                    <EquationSource Format="TEX"><![CDATA[$$\phi :\mathbf{R}^d\rightarrow \mathcal{H },$$]]></EquationSource>
                  </InlineEquation> we can map the input data points into a higher-dimensional feature space <InlineEquation ID="IEq11">
                    <EquationSource Format="TEX"><![CDATA[$$\mathcal{H }$$]]></EquationSource>
                  </InlineEquation> to create nonlinear classifiers. The classification decision function is defined as follows:<Equation ID="Equ3">
                    <EquationNumber>3</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} f(x)=\mathrm{sign}({\mathbf{w }\cdot \varphi (x)+b}) \end{aligned}$$]]></EquationSource>
                  </Equation>SVM is commonly regarded as a competitive choice for classification. And many state-of-the-art visual concept detection systems achieved their best results using SVM classifiers with <InlineEquation ID="IEq12">
                    <EquationSource Format="TEX"><![CDATA[$$\chi ^2$$]]></EquationSource>
                  </InlineEquation> [<CitationRef CitationID="CR15">15</CitationRef>, <CitationRef CitationID="CR26">26</CitationRef>]. Recently, multiple kernel learning has been a topic of interest which associates image features with kernel functions and jointly learn the optimal combination of the kernels [<CitationRef CitationID="CR35">35</CitationRef>]. In this paper, we combine several kernels of multiple features into a single model by averaging their values. The RBF-based kernel function is used to measure the similarity between two images: <InlineEquation ID="IEq13">
                    <EquationSource Format="TEX"><![CDATA[$$k(x_i ,x_j )=\exp (-d(x_i ,x_j )/\lambda ),$$]]></EquationSource>
                  </InlineEquation> where <InlineEquation ID="IEq14">
                    <EquationSource Format="TEX"><![CDATA[$$d(x_i ,x_j )$$]]></EquationSource>
                  </InlineEquation> is the distance in a feature space between two images and <InlineEquation ID="IEq15">
                    <EquationSource Format="TEX"><![CDATA[$$\lambda $$]]></EquationSource>
                  </InlineEquation> is set as the average of all pair-wise distances among all the training images.</Para>
              </Section2>
              <Section2 ID="Sec7">
                <Heading>Boosting</Heading>
                <Para>Boosting is an ensemble learning framework to construct a strong classifier by combining a set of inaccurate classification rules (weak learners). We propose to use three variants of the boosting algorithm, including AdaBoost [<CitationRef CitationID="CR36">36</CitationRef>], RealBoost [<CitationRef CitationID="CR37">37</CitationRef>] and GentleBoost [<CitationRef CitationID="CR37">37</CitationRef>], for visual concept learning. Adaboost is the most commonly used version in which the weak learner directly outputs discrete class labels and the final classifier is defined to be a linear combination of the weak learners from each stage. While in RealBoost procedures, the weak learner produces a class probability estimate and its contribution to the final classifier is half the logit-transform of this probability estimate. Friedman et al. [<CitationRef CitationID="CR37">37</CitationRef>] also showed that boosting provides a generalized way to sequentially fit additive regression models of the form:<Equation ID="Equ4">
                    <EquationNumber>4</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} H(x)=\sum \limits _{i=1}^T {h_{t} (x)} \end{aligned}$$]]></EquationSource>
                  </Equation>where <InlineEquation ID="IEq16">
                    <EquationSource Format="TEX"><![CDATA[$$x$$]]></EquationSource>
                  </InlineEquation> is the input feature vector and <InlineEquation ID="IEq17">
                    <EquationSource Format="TEX"><![CDATA[$$T$$]]></EquationSource>
                  </InlineEquation> is the number of boosting rounds. <InlineEquation ID="IEq18">
                    <EquationSource Format="TEX"><![CDATA[$$h_{t} (x)$$]]></EquationSource>
                  </InlineEquation> denotes a weak learner at each round <InlineEquation ID="IEq19">
                    <EquationSource Format="TEX"><![CDATA[$$t$$]]></EquationSource>
                  </InlineEquation>, and <InlineEquation ID="IEq20">
                    <EquationSource Format="TEX"><![CDATA[$$H(x)$$]]></EquationSource>
                  </InlineEquation> is the final strong classifier learner. Thereby, they derive a “gentler” version called GentleBoost, which differs from RealBoost in that it takes adaptive Newton stepping rather than exact optimization at each stage and tends to put less weight on the outlier data points.</Para>
                <Para>In order to merge multiple visual features into our concept learning system, a feature combination procedure is introduced to be integrated at each round of these three boosting variants. The traditional boosting produces only one component weak classifier at each iteration. By contrast, at each round of our extension of the boosting procedures, several weak classifiers are trained on samples of each feature, and then combined into a single one (a middle final classifier) [<CitationRef CitationID="CR38">38</CitationRef>]:<Equation ID="Equ5">
                    <EquationNumber>5</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} h_{t} =\sum \limits _{m=1}^M {\beta _m f_m (x)}\end{aligned}$$]]></EquationSource>
                  </Equation>
                  <Equation ID="Equ6">
                    <EquationNumber>6</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} s.t.\quad \sum \limits _{m=1}^M {\beta _m =1} \end{aligned}$$]]></EquationSource>
                  </Equation>where <InlineEquation ID="IEq21">
                    <EquationSource Format="TEX"><![CDATA[$$h_{t} $$]]></EquationSource>
                  </InlineEquation> denotes the final weak classifier at each round <InlineEquation ID="IEq22">
                    <EquationSource Format="TEX"><![CDATA[$$t$$]]></EquationSource>
                  </InlineEquation>, and <InlineEquation ID="IEq23">
                    <EquationSource Format="TEX"><![CDATA[$$f_m $$]]></EquationSource>
                  </InlineEquation> is the separately learned weak classifier using feature <InlineEquation ID="IEq24">
                    <EquationSource Format="TEX"><![CDATA[$$m$$]]></EquationSource>
                  </InlineEquation> . <InlineEquation ID="IEq25">
                    <EquationSource Format="TEX"><![CDATA[$$\beta _m $$]]></EquationSource>
                  </InlineEquation> indicates the linear combination weights, we can uniformly weight it by <InlineEquation ID="IEq26">
                    <EquationSource Format="TEX"><![CDATA[$$\beta _m =\textstyle {1 \over K}$$]]></EquationSource>
                  </InlineEquation> . Yet, another option for AdaBoost is to weight according to the same criteria of weighting the weak classifier at each round:<Equation ID="Equ7">
                    <EquationNumber>7</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \epsilon _m&= \text{ E}\left[ {w\cdot I(y\ne f_m (x))} \right]\end{aligned}$$]]></EquationSource>
                  </Equation>
                  <Equation ID="Equ8">
                    <EquationNumber>8</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \beta _m&= \frac{1}{2}\log ( {(1-\epsilon _m )/\epsilon _m }) \end{aligned}$$]]></EquationSource>
                  </Equation>where <InlineEquation ID="IEq27">
                    <EquationSource Format="TEX"><![CDATA[$$I(\cdot )$$]]></EquationSource>
                  </InlineEquation> denotes the indicator function which takes on the value 1 whenever the statement is true, and value 0 otherwise. <InlineEquation ID="IEq28">
                    <EquationSource Format="TEX"><![CDATA[$$w$$]]></EquationSource>
                  </InlineEquation> is the training weight for each example in boosting. Thus, these combination weights depend on the weighted training error rate of each weak classifier. Since RealBoost and GentleBoost use real-valued confidence-rated predictions rather than discrete positive or negative class labels <InlineEquation ID="IEq29">
                    <EquationSource Format="TEX"><![CDATA[$$\{-1,\, +1\},$$]]></EquationSource>
                  </InlineEquation> a second weighting method of feature combination for them is defined based on generalization error (out-of-sample error rate):<Equation ID="Equ9">
                    <EquationNumber>9</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \beta _m =\text{ E}\left[ {w\cdot \frac{1}{e^{-yf_m (x)}}} \right]=\text{ E}\left[ {w\cdot e^{yf_m (x)}} \right] \end{aligned}$$]]></EquationSource>
                  </Equation>
                </Para>
                <Para>where the term <InlineEquation ID="IEq30">
                    <EquationSource Format="TEX"><![CDATA[$$yf_m (x)$$]]></EquationSource>
                  </InlineEquation> indicates the margin, which is related to the generalization error. All the weights are normalized such that they sum up to <InlineEquation ID="IEq31">
                    <EquationSource Format="TEX"><![CDATA[$$1$$]]></EquationSource>
                  </InlineEquation>, i.e. Eq. (<InternalRef RefID="Equ6">6</InternalRef>). In addition to linear combination, we also propose to select the best one, obtaining the largest combination weight, of all the weak classifiers trained on each feature as the final weak classifier at each round:<Equation ID="Equ10">
                    <EquationNumber>10</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} h_{t} =\mathop {\arg \max }\limits _{f_{m \in M} } \beta _m \end{aligned}$$]]></EquationSource>
                  </Equation>This way is much like a feature selection process. Our AdaBoost, RealBoost and GentleBoost algorithms are respectively described in Figs. <InternalRef RefID="Fig2">2</InternalRef>, <InternalRef RefID="Fig3">3</InternalRef> and <InternalRef RefID="Fig4">4</InternalRef>.<Figure Category="Standard" Float="Yes" ID="Fig2">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 2</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>AdaBoost algorithm</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO11">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_22_Fig2_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                  <Figure Category="Standard" Float="Yes" ID="Fig3">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 3</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>RealBoost algorithm</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO12">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_22_Fig3_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                  <Figure Category="Standard" Float="Yes" ID="Fig4">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 4</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>GentleBoost algorithm</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO13">
                      <ImageObject Color="BlackWhite" FileRef="MediaObjects/13735_2012_22_Fig4_HTML.gif" Format="GIF" Rendition="HTML" Type="Linedraw"/>
                    </MediaObject>
                  </Figure>
                </Para>
              </Section2>
            </Section1>
            <Section1 ID="Sec8">
              <Heading>Exploiting tag relevance</Heading>
              <Section2 ID="Sec9">
                <Heading>Visual neighbor voting model</Heading>
                <Para>A recent research topic on determining the visual relevance of the social tags has been studied in [<CitationRef CitationID="CR11">11</CitationRef>, <CitationRef CitationID="CR30">30</CitationRef>, <CitationRef CitationID="CR39">39</CitationRef>]. In general, the key idea is based on the nearest neighbor model that propagates the annotation tags of the visually most similar training images to a target image. Here, inspired by their work, we summarize it as a weighted nearest neighbor voting model: for each tag, a seed image will receive relevance votes from its visual neighbors which are labeled with this tag by users and the votes can be weighted according to their visual similarities. Figure <InternalRef RefID="Fig5">5</InternalRef> illustrates an overview of this visual neighbor voting model without considering the contribution weight for each vote. Specifically, given an annotation concept <InlineEquation ID="IEq32">
                    <EquationSource Format="TEX"><![CDATA[$$w,$$]]></EquationSource>
                  </InlineEquation> its visual relevance <InlineEquation ID="IEq33">
                    <EquationSource Format="TEX"><![CDATA[$$r$$]]></EquationSource>
                  </InlineEquation> with respect to a seed image <InlineEquation ID="IEq34">
                    <EquationSource Format="TEX"><![CDATA[$$x_i $$]]></EquationSource>
                  </InlineEquation> is defined by taking a weighted sum of the votes from its <InlineEquation ID="IEq35">
                    <EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource>
                  </InlineEquation> nearest neighboring images:<Equation ID="Equ11">
                    <EquationNumber>11</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} r(x_i ,w)&= \sum \limits _{j=1}^K {\pi _{ij} v(x_j ,w)}\end{aligned}$$]]></EquationSource>
                  </Equation>
                  <Equation ID="Equ12">
                    <EquationNumber>12</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} v(x_j ,w)&= \left\{ \begin{array}{l@{\quad }l} 1-\varepsilon&\text{ if}\ w\in x_j ^{\prime }\mathrm{s}\; \mathrm{tag}\;\mathrm{list} \\ \varepsilon&\text{ otherwise} \end{array} \right. \end{aligned}$$]]></EquationSource>
                  </Equation>where <InlineEquation ID="IEq36">
                    <EquationSource Format="TEX"><![CDATA[$$v(x_j ,w)$$]]></EquationSource>
                  </InlineEquation> indicates the vote from the neighbor image <InlineEquation ID="IEq37">
                    <EquationSource Format="TEX"><![CDATA[$$x_j ,$$]]></EquationSource>
                  </InlineEquation> i.e. whether <InlineEquation ID="IEq38">
                    <EquationSource Format="TEX"><![CDATA[$$x_j $$]]></EquationSource>
                  </InlineEquation> is labeled with target concept <InlineEquation ID="IEq39">
                    <EquationSource Format="TEX"><![CDATA[$$w.$$]]></EquationSource>
                  </InlineEquation> And we use <InlineEquation ID="IEq40">
                    <EquationSource Format="TEX"><![CDATA[$$\pi _{ij} $$]]></EquationSource>
                  </InlineEquation> to denote the contribution weight when image <InlineEquation ID="IEq41">
                    <EquationSource Format="TEX"><![CDATA[$$x_j $$]]></EquationSource>
                  </InlineEquation> is voting on image <InlineEquation ID="IEq42">
                    <EquationSource Format="TEX"><![CDATA[$$x_i .$$]]></EquationSource>
                  </InlineEquation> The introduction of the non-negative constant <InlineEquation ID="IEq43">
                    <EquationSource Format="TEX"><![CDATA[$$\varepsilon $$]]></EquationSource>
                  </InlineEquation> (e.g. <InlineEquation ID="IEq44">
                    <EquationSource Format="TEX"><![CDATA[$$10^{-5}$$]]></EquationSource>
                  </InlineEquation>) is a technicality to avoid zero prediction when none of the <InlineEquation ID="IEq45">
                    <EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource>
                  </InlineEquation> nearest neighbor <InlineEquation ID="IEq46">
                    <EquationSource Format="TEX"><![CDATA[$$x_j $$]]></EquationSource>
                  </InlineEquation> is annotated with concept <InlineEquation ID="IEq47">
                    <EquationSource Format="TEX"><![CDATA[$$w.$$]]></EquationSource>
                  </InlineEquation> To ensure proper distribution and normalization so that <InlineEquation ID="IEq48">
                    <EquationSource Format="TEX"><![CDATA[$$r\in (0,\,1),$$]]></EquationSource>
                  </InlineEquation> we require that <InlineEquation ID="IEq49">
                    <EquationSource Format="TEX"><![CDATA[$$\pi _{ij} >0$$]]></EquationSource>
                  </InlineEquation> and <InlineEquation ID="IEq50">
                    <EquationSource Format="TEX"><![CDATA[$$\sum \nolimits _j {\pi _{ij} } =1.$$]]></EquationSource>
                  </InlineEquation>
                  <Figure Category="Standard" Float="Yes" ID="Fig5">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 5</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Visual neighbor voting model. The tag relevance with respect to the visual content of an image is modeled by accumulating the neighbor votes received from visually most similar images of the seed image. For example, since four neighboring images are annotated with concept “butterfly”, the seed image will obtain four votes for its tag relevance estimation. Moreover, if we consider to recommend new tags for the seed image, the concept “garden” would be preferred, because the accumulated neighbor votes for it is three</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO15">
                      <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_22_Fig5_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>The only parameter of this model is thereby <InlineEquation ID="IEq51">
                    <EquationSource Format="TEX"><![CDATA[$$\pi _{ij} $$]]></EquationSource>
                  </InlineEquation>, and we see that this leads to three weighting schemes for this weighted nearest neighbor model:<OrderedList>
                    <ListItem>
                      <ItemNumber>1.</ItemNumber>
                      <ItemContent>
                        <Para>Uniform weighting: <InlineEquation ID="IEq52">
                            <EquationSource Format="TEX"><![CDATA[$$\pi _{ij} $$]]></EquationSource>
                          </InlineEquation> is equally weighted for all the visual neighbors.</Para>
                      </ItemContent>
                    </ListItem>
                    <ListItem>
                      <ItemNumber>2.</ItemNumber>
                      <ItemContent>
                        <Para>Distance-based weighting: <InlineEquation ID="IEq53">
                            <EquationSource Format="TEX"><![CDATA[$$\pi _{ij} $$]]></EquationSource>
                          </InlineEquation> is weighted according to the measure of distance in the feature space between image <InlineEquation ID="IEq54">
                            <EquationSource Format="TEX"><![CDATA[$$x_i $$]]></EquationSource>
                          </InlineEquation> and neighboring image <InlineEquation ID="IEq55">
                            <EquationSource Format="TEX"><![CDATA[$$x_j .$$]]></EquationSource>
                          </InlineEquation>
                        </Para>
                      </ItemContent>
                    </ListItem>
                    <ListItem>
                      <ItemNumber>3.</ItemNumber>
                      <ItemContent>
                        <Para>Rank-based weighting: <InlineEquation ID="IEq56">
                            <EquationSource Format="TEX"><![CDATA[$$\pi _{ij} $$]]></EquationSource>
                          </InlineEquation> is weighted according to the ranking of image <InlineEquation ID="IEq57">
                            <EquationSource Format="TEX"><![CDATA[$$x_j $$]]></EquationSource>
                          </InlineEquation> among all the <InlineEquation ID="IEq58">
                            <EquationSource Format="TEX"><![CDATA[$$x_i $$]]></EquationSource>
                          </InlineEquation>’s visual neighbors which are well ranked by their distance measure.</Para>
                      </ItemContent>
                    </ListItem>
                  </OrderedList>Based on these weighting approaches, below we present two effective tag relevance learning models driven by diverse features in an unsupervised or supervised manner.</Para>
              </Section2>
              <Section2 ID="Sec10">
                <Heading>Unsupervised tag relevance learning</Heading>
                <Para>In order to seek a generic and unsupervised tag relevance learning model using the weighted neighbor voting strategy, we employ the uniform weighting scheme for all the visual neighbors, as well as the multiple feature learners [<CitationRef CitationID="CR11">11</CitationRef>, <CitationRef CitationID="CR39">39</CitationRef>]. Specifically, we first perform tag relevance learning by searching for the nearest neighbors using each feature measure. Then, several base learners trained under different feature measures are combined in an uniform manner, since we have no prior knowledge of which base learner is most appropriate for a given target tag. Assume we just consider the <InlineEquation ID="IEq59">
                    <EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource>
                  </InlineEquation> nearest neighbors of the seed image <InlineEquation ID="IEq60">
                    <EquationSource Format="TEX"><![CDATA[$$x_i .$$]]></EquationSource>
                  </InlineEquation> Since each visual neighbor will be weighted by <InlineEquation ID="IEq61">
                    <EquationSource Format="TEX"><![CDATA[$$\pi _{ij} =\textstyle {1 \over K}$$]]></EquationSource>
                  </InlineEquation>, the model (<InternalRef RefID="Equ11">11</InternalRef>) can be inferred as:<Equation ID="Equ13">
                    <EquationNumber>13</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} r(x_i ,w)=\sum \limits _{j=1}^K {\frac{1}{K}v(x_j ,w)} \end{aligned}$$]]></EquationSource>
                  </Equation>However, tags occurring frequently in the training image collection may dominate the results. To restrain such effects, we take into account the tag’s prior frequency to estimate its prior probability [<CitationRef CitationID="CR11">11</CitationRef>]. Concretely, the prior probability for a given concept <InlineEquation ID="IEq62">
                    <EquationSource Format="TEX"><![CDATA[$$w$$]]></EquationSource>
                  </InlineEquation> is approximated as:<Equation ID="Equ14">
                    <EquationNumber>14</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} p_\mathrm{prior} (w)=\frac{N_w }{N } \end{aligned}$$]]></EquationSource>
                  </Equation>where <InlineEquation ID="IEq63">
                    <EquationSource Format="TEX"><![CDATA[$$N_w $$]]></EquationSource>
                  </InlineEquation> is the number of training images tagged with concept <InlineEquation ID="IEq64">
                    <EquationSource Format="TEX"><![CDATA[$$w$$]]></EquationSource>
                  </InlineEquation>, and <InlineEquation ID="IEq65">
                    <EquationSource Format="TEX"><![CDATA[$$N$$]]></EquationSource>
                  </InlineEquation> denotes the size of the entire training set. In general, the more neighboring images annotated with the target concept, the larger the tag relevance value would be. In the meanwhile, tags with high frequency are penalized for their high prior probabilities. As a result, we obtain the unsupervised tag relevance learning model using multiple features as follows [<CitationRef CitationID="CR39">39</CitationRef>]:<Equation ID="Equ15">
                    <EquationNumber>15</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} r_m (x_i ,w)&= \sum \limits _{j=1}^K {\frac{1}{K}v_m (x_j ,w)} -\frac{N_w }{N } \end{aligned}$$]]></EquationSource>
                  </Equation>
                  <Equation ID="Equ16">
                    <EquationNumber>16</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} r(x_i ,w)&= \frac{1}{M}\sum \limits _{m=1}^M {r_m (x_i ,w)} \end{aligned}$$]]></EquationSource>
                  </Equation>where <InlineEquation ID="IEq66">
                    <EquationSource Format="TEX"><![CDATA[$$r_m $$]]></EquationSource>
                  </InlineEquation> is the tag relevance learner trained using feature <InlineEquation ID="IEq67">
                    <EquationSource Format="TEX"><![CDATA[$$m$$]]></EquationSource>
                  </InlineEquation>. Note that function (<InternalRef RefID="Equ15">15</InternalRef>) does not necessarily obtain positive results, so in practice we set the minimum value <InlineEquation ID="IEq68">
                    <EquationSource Format="TEX"><![CDATA[$$\varphi $$]]></EquationSource>
                  </InlineEquation>, a very small constant (e.g. <InlineEquation ID="IEq69">
                    <EquationSource Format="TEX"><![CDATA[$$10^{-5})$$]]></EquationSource>
                  </InlineEquation>, to avoid negative results in our experiments.</Para>
              </Section2>
              <Section2 ID="Sec11">
                <Heading>Supervised tag relevance learning</Heading>
                <Para>When manually-labeled training images of given tags are available, the weighting parameter <InlineEquation ID="IEq70">
                    <EquationSource Format="TEX"><![CDATA[$$\pi _{ij} $$]]></EquationSource>
                  </InlineEquation> can be optimized to fit the tag relevance function. To this end, we employ two supervised tag relevance learning methods by performing distance-based and rank-based weighting. We follow the method proposed in [<CitationRef CitationID="CR30">30</CitationRef>], maximizing the log-likelihood of the tag relevance predictions for training images. The objective function is defined as follows:<Equation ID="Equ17">
                    <EquationNumber>17</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \mathcal{L }=\sum \limits _{i,w} {\mu _{iw} \log ( {{r}^{\prime }(x_i ,w)})} \end{aligned}$$]]></EquationSource>
                  </Equation>Note that if the annotation concept <InlineEquation ID="IEq71">
                    <EquationSource Format="TEX"><![CDATA[$$w$$]]></EquationSource>
                  </InlineEquation> is visually relevant to an image <InlineEquation ID="IEq72">
                    <EquationSource Format="TEX"><![CDATA[$$x_i ,$$]]></EquationSource>
                  </InlineEquation> we aim to maximize its tag relevance <InlineEquation ID="IEq73">
                    <EquationSource Format="TEX"><![CDATA[$${r}^{\prime }=r;$$]]></EquationSource>
                  </InlineEquation> however, <InlineEquation ID="IEq74">
                    <EquationSource Format="TEX"><![CDATA[$${r}^{\prime }=1-r$$]]></EquationSource>
                  </InlineEquation> should be maximized if concept <InlineEquation ID="IEq75">
                    <EquationSource Format="TEX"><![CDATA[$$w$$]]></EquationSource>
                  </InlineEquation> is irrelevant to image <InlineEquation ID="IEq76">
                    <EquationSource Format="TEX"><![CDATA[$$x_i .$$]]></EquationSource>
                  </InlineEquation> And <InlineEquation ID="IEq77">
                    <EquationSource Format="TEX"><![CDATA[$$\mu _{iw} $$]]></EquationSource>
                  </InlineEquation> is the bias cost that takes into account the imbalance between concept presence and absence. Indeed, in practice, there are much more tag absences than presences, and absences are often much noisier than presences. This is because even if most concepts in annotations are relevant, the annotation often does not include all relevant concepts. We set <InlineEquation ID="IEq78">
                    <EquationSource Format="TEX"><![CDATA[$$\mu _{iw} =1/N^+$$]]></EquationSource>
                  </InlineEquation> if concept <InlineEquation ID="IEq79">
                    <EquationSource Format="TEX"><![CDATA[$$w$$]]></EquationSource>
                  </InlineEquation> is relevant, where <InlineEquation ID="IEq80">
                    <EquationSource Format="TEX"><![CDATA[$$N^+$$]]></EquationSource>
                  </InlineEquation> is the total number of positive training examples, and likewise <InlineEquation ID="IEq81">
                    <EquationSource Format="TEX"><![CDATA[$$\mu _{iw} =1/N^-$$]]></EquationSource>
                  </InlineEquation> when irrelevant, where <InlineEquation ID="IEq82">
                    <EquationSource Format="TEX"><![CDATA[$$N^-$$]]></EquationSource>
                  </InlineEquation> is the number of negative examples.</Para>
                <Para>To define the weights directly as a function of the distance or rank metric, we use the weighting function introduced in [<CitationRef CitationID="CR30">30</CitationRef>] which was defined for distance-based weights, and here we also apply it to getting rank-based weights:<Equation ID="Equ18">
                    <EquationNumber>18</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \pi _{ij} =\frac{\exp ( {-d_{\varvec{\theta }} (x_i ,x_j )})}{\sum \nolimits _{j^{\prime }} {\exp ( {-d_{\varvec{\theta }} (x_i ,x_{j^{\prime }} )})} } \end{aligned}$$]]></EquationSource>
                  </Equation>where <InlineEquation ID="IEq83">
                    <EquationSource Format="TEX"><![CDATA[$$d_\theta $$]]></EquationSource>
                  </InlineEquation> is a distance or rank metric with parameter <InlineEquation ID="IEq84">
                    <EquationSource Format="TEX"><![CDATA[$${\varvec{\theta }}$$]]></EquationSource>
                  </InlineEquation> that we want to optimize. Therefore, the weights <InlineEquation ID="IEq85">
                    <EquationSource Format="TEX"><![CDATA[$$\pi _{ij} $$]]></EquationSource>
                  </InlineEquation> decay exponentially with the distance or rank metric. Here, we use linear combination for <InlineEquation ID="IEq86">
                    <EquationSource Format="TEX"><![CDATA[$$d_{\varvec{\theta }} (x_i ,x_j )={\varvec{\theta }} ^T {{\varvec{d}}}_{ij} ,$$]]></EquationSource>
                  </InlineEquation> where <InlineEquation ID="IEq87">
                    <EquationSource Format="TEX"><![CDATA[$${{\varvec{d}}}_{ij} $$]]></EquationSource>
                  </InlineEquation> is a vector of all base distances between image <InlineEquation ID="IEq88">
                    <EquationSource Format="TEX"><![CDATA[$$x_i $$]]></EquationSource>
                  </InlineEquation> and image <InlineEquation ID="IEq89">
                    <EquationSource Format="TEX"><![CDATA[$$x_j $$]]></EquationSource>
                  </InlineEquation>, or a vector of ranks for image <InlineEquation ID="IEq90">
                    <EquationSource Format="TEX"><![CDATA[$$x_j $$]]></EquationSource>
                  </InlineEquation> among the <InlineEquation ID="IEq91">
                    <EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource>
                  </InlineEquation>nearest neighbors of image <InlineEquation ID="IEq92">
                    <EquationSource Format="TEX"><![CDATA[$$x_i $$]]></EquationSource>
                  </InlineEquation> under each distance measure, and the parameter <InlineEquation ID="IEq93">
                    <EquationSource Format="TEX"><![CDATA[$${\varvec{\theta }} =(\theta _1 ,\ldots , \theta _M )$$]]></EquationSource>
                  </InlineEquation> contains the positive coefficients of the linear distance or rank combination.</Para>
                <Para>As we mentioned above, the weighted nearest neighbor voting model (<InternalRef RefID="Equ11">11</InternalRef>) tends to have relatively low recall scores for rare annotation keywords: to receive a high probability for the presence of a tag, it needs to be present among most visual neighbors with a significant weight. This, however, is unlikely to be the case for rare annotation terms. To overcome this problem, Verbeek et al. [<CitationRef CitationID="CR30">30</CitationRef>] introduced to perform concept-specific logistic transformation to boost the probability for rare concepts and decrease it for frequent ones. The logistic model uses the weighted neighbor voting predictions by defining:<Equation ID="Equ19">
                    <EquationNumber>19</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} r_{iw}&= \sum \limits _{j=1}^K {\pi _{ij} v(x_j ,w)}\end{aligned}$$]]></EquationSource>
                  </Equation>
                  <Equation ID="Equ20">
                    <EquationNumber>20</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} r(x_i ,w)&= \sigma (\alpha _w \cdot r_{iw} +\beta _w ) \end{aligned}$$]]></EquationSource>
                  </Equation>where <InlineEquation ID="IEq94">
                    <EquationSource Format="TEX"><![CDATA[$$\sigma (z)=1/(1+\exp (-z))$$]]></EquationSource>
                  </InlineEquation> is the sigmoid or logistic function and <InlineEquation ID="IEq95">
                    <EquationSource Format="TEX"><![CDATA[$$r_{iw} $$]]></EquationSource>
                  </InlineEquation> is the relevance estimation of concept <InlineEquation ID="IEq96">
                    <EquationSource Format="TEX"><![CDATA[$$w$$]]></EquationSource>
                  </InlineEquation> with respect to image <InlineEquation ID="IEq97">
                    <EquationSource Format="TEX"><![CDATA[$$x_i $$]]></EquationSource>
                  </InlineEquation>, which is learned by visual neighbor voting and using weighting function (<InternalRef RefID="Equ18">18</InternalRef>). This concept-specific model is equivalent to (<InternalRef RefID="Equ11">11</InternalRef>) up to an affine transformation. In practice, we estimate the parameters <InlineEquation ID="IEq98">
                    <EquationSource Format="TEX"><![CDATA[$$\{\alpha _w ,\;\beta _w \}$$]]></EquationSource>
                  </InlineEquation> and <InlineEquation ID="IEq99">
                    <EquationSource Format="TEX"><![CDATA[$$\varvec{\theta }$$]]></EquationSource>
                  </InlineEquation> in an alternating fashion.</Para>
              </Section2>
            </Section1>
            <Section1 ID="Sec12">
              <Heading>Cost/importance weighted concept learning</Heading>
              <Para>Despite the high popularity and advantages of social tagging, it is well known that tags provided by the grassroot Internet users are actually far from satisfactory as qualified descriptive indexing keywords for the visual content of the web images. Therefore, in this section, several cost/importance weighted concept learning algorithms are considered to solve the problem of directly using noisy tags of social images for visual concept learning. These approaches are inspired by current cost-sensitive learning techniques. First, we exploit the visual relevance of the tags that are present in the social images as shown in the previous section. Second, the tag relevance with respect to each training examples is integrated into the supervised learning process of SVM and boosting classifiers, in the form of importance weights.</Para>
              <Section2 ID="Sec13">
                <Heading>Cost-sensitive learning</Heading>
                <Para>The design of optimal classifiers with respect to losses that weight certain types of errors of training examples more heavily than others is denoted as cost-sensitive learning in machine learning and data mining communities. Classification problems such as fraud detection, medical diagnosis or object detection in computer vision are naturally cost sensitive. For example, in a face recognition-based door locker system, the cost of mistakenly allowing an imposter to enter the house may be much higher than that of mistakenly rejecting a host, because the former kind of error would be a disaster and obviously much more serious than the latter.</Para>
                <Para>Actually, the cost-sensitive learning process may involve many kinds of costs, such as test cost, teaching cost, intervention cost, etc., among which the most studied type is the misclassification cost [<CitationRef CitationID="CR40">40</CitationRef>]. Furthermore, the misclassification cost can also be categorized into two groups, i.e. problems with <Emphasis Type="Italic">class-dependent</Emphasis> cost [<CitationRef CitationID="CR41">41</CitationRef>–<CitationRef CitationID="CR43">43</CitationRef>] and <Emphasis Type="Italic">example-dependent</Emphasis> cost [<CitationRef CitationID="CR44">44</CitationRef>, <CitationRef CitationID="CR45">45</CitationRef>]. In the former kind of problems, the cost is determined by error type, that is, misclassifying any example of a certain class into another class will always have the same cost, while misclassifying an example into different classes may result in different cost. In the latter kind of problems, the cost is determined by the example, while different examples may have different misclassification cost even when their error types are the same. Our work will focus on example-dependent cost-sensitive learning. Denote an example image <InlineEquation ID="IEq100">
                    <EquationSource Format="TEX"><![CDATA[$$x$$]]></EquationSource>
                  </InlineEquation> and its class label <InlineEquation ID="IEq101">
                    <EquationSource Format="TEX"><![CDATA[$$y$$]]></EquationSource>
                  </InlineEquation>. Given a set of examples <InlineEquation ID="IEq102">
                    <EquationSource Format="TEX"><![CDATA[$$x\in X$$]]></EquationSource>
                  </InlineEquation> with class labels <InlineEquation ID="IEq103">
                    <EquationSource Format="TEX"><![CDATA[$$y\in Y$$]]></EquationSource>
                  </InlineEquation> and <InlineEquation ID="IEq104">
                    <EquationSource Format="TEX"><![CDATA[$$\vert Y\vert =L,$$]]></EquationSource>
                  </InlineEquation> the traditional machine learning or classification methods try to generate a hypothesis <InlineEquation ID="IEq105">
                    <EquationSource Format="TEX"><![CDATA[$$h:X\rightarrow \{1,\ldots ,L\}$$]]></EquationSource>
                  </InlineEquation> minimizing the expected <Emphasis Type="Italic">misclassification error</Emphasis>:<Equation ID="Equ21">
                    <EquationNumber>21</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \mathop {\arg \min }\limits _h \text{ E}_{x,y} \left[ {I(h(x)\ne y)} \right] \end{aligned}$$]]></EquationSource>
                  </Equation>where we use <InlineEquation ID="IEq106">
                    <EquationSource Format="TEX"><![CDATA[$$I(\cdot )$$]]></EquationSource>
                  </InlineEquation> to denote the indicator function which takes on the value 1 whenever the statement is true, and value 0 otherwise. Thus, these methods implicitly assume that the costs of all kinds of mistakes are the same. In our concern problem of example-dependent cost-sensitive learning, the general cost function <InlineEquation ID="IEq107">
                    <EquationSource Format="TEX"><![CDATA[$$C_{h(x)} =C(x,y,h(x))$$]]></EquationSource>
                  </InlineEquation> specifies how much classification cost is incurred when an example <InlineEquation ID="IEq108">
                    <EquationSource Format="TEX"><![CDATA[$$x$$]]></EquationSource>
                  </InlineEquation> with correct label <InlineEquation ID="IEq109">
                    <EquationSource Format="TEX"><![CDATA[$$y$$]]></EquationSource>
                  </InlineEquation> is predicted to belong to class <InlineEquation ID="IEq110">
                    <EquationSource Format="TEX"><![CDATA[$$h(x).$$]]></EquationSource>
                  </InlineEquation> Thereby it allows for cost dependence on each example <InlineEquation ID="IEq111">
                    <EquationSource Format="TEX"><![CDATA[$$x$$]]></EquationSource>
                  </InlineEquation>. We can also assume that the correct predictions are normalized so that <InlineEquation ID="IEq112">
                    <EquationSource Format="TEX"><![CDATA[$$C_y =C(x,y,y)=0.$$]]></EquationSource>
                  </InlineEquation> Again, given a set of training examples <InlineEquation ID="IEq113">
                    <EquationSource Format="TEX"><![CDATA[$$S=(x,\varvec{C})^N$$]]></EquationSource>
                  </InlineEquation>, where <InlineEquation ID="IEq114">
                    <EquationSource Format="TEX"><![CDATA[$$\varvec{C}$$]]></EquationSource>
                  </InlineEquation> is a vector of costs of misclassifying an example <InlineEquation ID="IEq115">
                    <EquationSource Format="TEX"><![CDATA[$$x$$]]></EquationSource>
                  </InlineEquation> as all possible labels, our goal is to find a classifier <InlineEquation ID="IEq116">
                    <EquationSource Format="TEX"><![CDATA[$$h$$]]></EquationSource>
                  </InlineEquation> which minimizes the expected <Emphasis Type="Italic">misclassification cost</Emphasis>:<Equation ID="Equ22">
                    <EquationNumber>22</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \mathop {\arg \min }\limits _h \text{ E}_{x,y,C} \left[ {C_{h(x)} \cdot I(h(x)\ne y)} \right] \end{aligned}$$]]></EquationSource>
                  </Equation>Our problem of learning visual concepts from weakly labeled social images can be viewed as a cost-sensitive learning problem, since for a given concept misclassifying a more relevant image should result in a higher cost than misclassifying an irrelevant image.</Para>
              </Section2>
              <Section2 ID="Sec14">
                <Heading>From misclassification cost to importance weight</Heading>
                <Para>Recently, significant work has attempted to convert machine learning algorithms and classification theory into cost-sensitive algorithms and theory. The research in this area falls mainly into three categories: (1) extending a particular classifier learning algorithm so as to produce cost-sensitive generalizations; (2) using Bayes risk theory to assign each example to its lowest risk class; (3) making arbitrary classification algorithms into cost-sensitive ones. In particular, a general conversion proposed in [<CitationRef CitationID="CR44">44</CitationRef>] (and further study on multi-class case in [<CitationRef CitationID="CR45">45</CitationRef>]) is based on cost-proportionate weighting of the training examples, which can be realized either by feeding the weights to specific classification learners (e.g. boosting), or by carefully subsampling the training examples drawn from a weighted distribution. Rather than using “cost matrix” formulation which is more typical in cost-sensitive learning, they formulate example-dependent misclassification cost in the form of one importance weight per example and reduce this cost-sensitive learning problem into an importance weighted classification problem which can be solved very well by weighted rejection sampling techniques.</Para>
                <Para>When the output space of the classification problem is binary, costs are associated with false negative and false positive, true negative and true positive predictions in the cost matrix formulation. Given an example and its cost matrix, only two entries, i.e. (false positive, true negative) or (true positive, false negative), are relevant for that example in the learning process, because it can only actually be either positive or negative example. Elkan et al. [<CitationRef CitationID="CR42">42</CitationRef>] and Zadrozny et al. [<CitationRef CitationID="CR44">44</CitationRef>] pointed out that these misclassification costs can be further reduced to one degree of freedom from a decision-making perspective: (false positive–true negative) or (false negative–true positive), which is the difference in cost between classifying an example incorrectly and correctly. For instance, consider the cost matrix in Table <InternalRef RefID="Tab1">1</InternalRef>, the cost difference we denote as example importance <InlineEquation ID="IEq117">
                    <EquationSource Format="TEX"><![CDATA[$$c$$]]></EquationSource>
                  </InlineEquation> here is defined as follows:<Equation ID="Equ23">
                    <EquationNumber>23</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} c=\left\{ \begin{array}{l} c_{01} -c_{00},\quad \mathrm{if}\;y=-1 \\ c_{10} -c_{11},\quad \mathrm{if}\;y=+1 \end{array} \right. \end{aligned}$$]]></EquationSource>
                  </Equation>This cost difference controls the importance of correct classification and just vary on an example-by-example basis. Then given a set of examples with the form <InlineEquation ID="IEq118">
                    <EquationSource Format="TEX"><![CDATA[$$(x,y,c)$$]]></EquationSource>
                  </InlineEquation>, we aim to find a classifier <InlineEquation ID="IEq119">
                    <EquationSource Format="TEX"><![CDATA[$$h$$]]></EquationSource>
                  </InlineEquation> achieving the minimal importance weighted misclassification error:<Equation ID="Equ24">
                    <EquationNumber>24</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \mathop {\arg \min }\limits _h \text{ E}_{x,y,c} \left[ {c\cdot I(h(x)\ne y)} \right] \end{aligned}$$]]></EquationSource>
                  </Equation>An iterative weighting method was proposed for multi-class cost-sensitive learning problems in [<CitationRef CitationID="CR45">45</CitationRef>]. It also makes use of the importance weighted classification method, but critically differs from per-example formulation of the two-class cost-sensitive learning problem described above in that there is one classification cost associated with each possible prediction <InlineEquation ID="IEq120">
                    <EquationSource Format="TEX"><![CDATA[$$h(x)$$]]></EquationSource>
                  </InlineEquation>, whereas in the binary case there is a single importance weight associated with each example <InlineEquation ID="IEq121">
                    <EquationSource Format="TEX"><![CDATA[$$x$$]]></EquationSource>
                  </InlineEquation>. In order to take into account the different costs associated with multiple ways of misclassifying examples, they make a conversion by use of expanding data space. Specifically, given a set of examples consisting of <InlineEquation ID="IEq122">
                    <EquationSource Format="TEX"><![CDATA[$$S=(x,\overrightarrow{C})$$]]></EquationSource>
                  </InlineEquation> of size <InlineEquation ID="IEq123">
                    <EquationSource Format="TEX"><![CDATA[$$N,$$]]></EquationSource>
                  </InlineEquation> where <InlineEquation ID="IEq124">
                    <EquationSource Format="TEX"><![CDATA[$$\overrightarrow{C}$$]]></EquationSource>
                  </InlineEquation> is the cost vector specified above. The expanded data space <InlineEquation ID="IEq125">
                    <EquationSource Format="TEX"><![CDATA[$${S}^{\prime }$$]]></EquationSource>
                  </InlineEquation> of size <InlineEquation ID="IEq126">
                    <EquationSource Format="TEX"><![CDATA[$$NL$$]]></EquationSource>
                  </InlineEquation>, where <InlineEquation ID="IEq127">
                    <EquationSource Format="TEX"><![CDATA[$$L=\;\vert Y\vert $$]]></EquationSource>
                  </InlineEquation> is the size of the class label set, is defined as follows:<Equation ID="Equ25">
                    <EquationNumber>25</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} {S}^{\prime }=\left\{ { (x,y,\mathop {\max }\limits _{{y}^{\prime }} C_{{y}^{\prime }} -C_y )\vert \; \forall y \in Y} \right\} \end{aligned}$$]]></EquationSource>
                  </Equation>
                  <Table Float="Yes" ID="Tab1">
                    <Caption Language="En">
                      <CaptionNumber>Table 1</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>An example of cost matrix for binary classification</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <tgroup cols="3">
                      <colspec align="left" colname="c1" colnum="1"/>
                      <colspec align="left" colname="c2" colnum="2"/>
                      <colspec align="left" colname="c3" colnum="3"/>
                      <thead>
                        <row>
                          <entry align="left" colname="c1"/>
                          <entry align="left" colname="c2">
                            <SimplePara>Predict negative</SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>Predict positive</SimplePara>
                          </entry>
                        </row>
                      </thead>
                      <tbody>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>Actual negative</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>
                              <InlineEquation ID="IEq128">
                                <EquationSource Format="TEX"><![CDATA[$$c_{00} $$]]></EquationSource>
                              </InlineEquation>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <InlineEquation ID="IEq129">
                                <EquationSource Format="TEX"><![CDATA[$$c_{01} $$]]></EquationSource>
                              </InlineEquation>
                            </SimplePara>
                          </entry>
                        </row>
                        <row>
                          <entry align="left" colname="c1">
                            <SimplePara>Actual positive</SimplePara>
                          </entry>
                          <entry align="left" colname="c2">
                            <SimplePara>
                              <InlineEquation ID="IEq130">
                                <EquationSource Format="TEX"><![CDATA[$$c_{10} $$]]></EquationSource>
                              </InlineEquation>
                            </SimplePara>
                          </entry>
                          <entry align="left" colname="c3">
                            <SimplePara>
                              <InlineEquation ID="IEq131">
                                <EquationSource Format="TEX"><![CDATA[$$c_{11} $$]]></EquationSource>
                              </InlineEquation>
                            </SimplePara>
                          </entry>
                        </row>
                      </tbody>
                    </tgroup>
                  </Table>
                </Para>
                <Para>The importance weights given here, thereby, are more like benefits than costs, since larger costs will be mapped to smaller weights. However, as we adopt one-against-all strategy to solve multi-class classification problem using binary classifiers, in the following study we will focus on two-class cost-sensitive learning in which there is only one importance weight per example. How to further formulate this problem when the output space is out of binary is our future work and beyond the scope of this paper. Below, we will make an attempt to incorporate these importance weights into SVM and boosting classifier learning process, rather than employing resampling techniques, though it is more general and can be applied to arbitrary classifier learners.</Para>
              </Section2>
              <Section2 ID="Sec15">
                <Heading>Importance weighted SVM</Heading>
                <Para>The problem of designing a cost-sensitive extension to the SVM learning model has been studied in [<CitationRef CitationID="CR46">46</CitationRef>–<CitationRef CitationID="CR48">48</CitationRef>]. In addition to a general conversion by resampling, [<CitationRef CitationID="CR46">46</CitationRef>] proposed to shift the decision boundary by simply adjusting the threshold of the standard SVM classifier. This boundary movement method is obviously flawed when the data are non-separable, in which case cost-sensitivity requires a modification of both the separating hyperplane <InlineEquation ID="IEq132">
                    <EquationSource Format="TEX"><![CDATA[$$\mathbf{w } $$]]></EquationSource>
                  </InlineEquation> and classifier threshold <InlineEquation ID="IEq133">
                    <EquationSource Format="TEX"><![CDATA[$$b.$$]]></EquationSource>
                  </InlineEquation> Another widely researched approach is to bias the penalties in the loss function [<CitationRef CitationID="CR44">44</CitationRef>, <CitationRef CitationID="CR47">47</CitationRef>, <CitationRef CitationID="CR48">48</CitationRef>]. It consists of introducing different penalty factors for different SVM slack variables of examples during training. Based on this idea, we modify the optimization formula (<InternalRef RefID="Equ1">1</InternalRef>) to incorporate the importance weights associated with each example:<Equation ID="Equ26">
                    <EquationNumber>26</EquationNumber>
                    <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \mathop {\min }\limits _{\mathbf{w } ,b,\xi } \frac{1}{2}\left\Vert \mathbf{w } \right\Vert_\mathcal{H }^2 +C\sum \limits _{i=1}^N {c_i \cdot \xi _i } \end{aligned}$$]]></EquationSource>
                  </Equation>where <InlineEquation ID="IEq134">
                    <EquationSource Format="TEX"><![CDATA[$$c_i $$]]></EquationSource>
                  </InlineEquation> is the importance weight of example <InlineEquation ID="IEq135">
                    <EquationSource Format="TEX"><![CDATA[$$x_i $$]]></EquationSource>
                  </InlineEquation> and now regularization constant <InlineEquation ID="IEq136">
                    <EquationSource Format="TEX"><![CDATA[$$C$$]]></EquationSource>
                  </InlineEquation> controls model complexity versus importance weighted training errors. As shown in Eq. (<InternalRef RefID="Equ26">26</InternalRef>), the biased penalties method has direct effect on the support vectors of SVM classifier. However, it suffers from a flaw that it has limited ability to enforce cost-sensitivity when the training data points are separable, which is the opposite case of boundary movement method. Since, in practice, the training data are more likely to be non-separable, our implementation is based on the loss function (<InternalRef RefID="Equ26">26</InternalRef>) employing the biased penalties.</Para>
              </Section2>
              <Section2 ID="Sec16">
                <Heading>Importance weighted boosting</Heading>
                <Section3 ID="Sec17">
                  <Heading>Importance weighted AdaBoost</Heading>
                  <Para>Various cost-sensitive extensions of AdaBoost algorithm are available in the literature, including AdaCost [<CitationRef CitationID="CR49">49</CitationRef>], CSB0, CSB1, CSB2 [<CitationRef CitationID="CR50">50</CitationRef>], and AdaC1, AdaC2, AdaC3 [<CitationRef CitationID="CR51">51</CitationRef>]. A straightforward idea to feed example importance weights to boosting procedures is to modify the initial boosting weights so as to break the importance symmetry. However, boosting re-updates all the weights at each iteration which may quickly destroy the initial asymmetry, and the predictor obtained after convergence usually makes little difference from that produced with symmetric initial conditions. Another natural heuristic is to modify the way of updating weights in the boosting procedures. Most of the previously proposed approaches [<CitationRef CitationID="CR49">49</CitationRef>–<CitationRef CitationID="CR51">51</CitationRef>] attempt to address this problem in AdaBoost, achieving cost-sensitivity by manipulation of its re-weighting mechanism and confidence parameters. AdaCost [<CitationRef CitationID="CR49">49</CitationRef>], for instance, introduces a cost adjustment function into weight updating rule of AdaBoost, aiming to increase the weight of a training example with higher importance “more” if it is misclassified, but decrease its weights “less” if otherwise. However, the selection of the cost adjustment factor in AdaCost is ad-hoc and may easily induce poor performance [<CitationRef CitationID="CR50">50</CitationRef>]. Sun et al. [<CitationRef CitationID="CR51">51</CitationRef>] suggested a justified inference of weight updating parameter to maintain the boosting efficiency in reducing the weighted training error, while integrating the misclassification cost into the weight updating formula. Our importance weighted extensions of Adaboost are implemented using AdaC2 and AdaC3 algorithms [<CitationRef CitationID="CR51">51</CitationRef>], which respectively feed the importance weights to the weight updating rule of Eqs. (<InternalRef RefID="Equ28">28</InternalRef>) and (<InternalRef RefID="Equ28">28</InternalRef>) at each round:<Equation ID="Equ27">
                      <EquationNumber>27</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned}&\begin{array}{ll} \displaystyle \alpha _t =\frac{1}{2}\log \frac{\sum \nolimits _{i,\;y_i =h_t (x_i )} {c_i w_i } }{\sum \nolimits _{i,\;y_i \ne h_t (x_i )} {c_i w_i } } \\ \displaystyle w_i \leftarrow c_i w_i e^{-\alpha _t y_i h_t (x_i )},\;i=1,\ldots ,N \\ \end{array}\end{aligned}$$]]></EquationSource>
                    </Equation>
                    <Equation ID="Equ28">
                      <EquationNumber>28</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned}&\begin{array}{ll} \displaystyle \alpha _t \!=\! \frac{1}{2}\log \frac{\sum \nolimits _i {c_i w_i } \!+\!\sum \nolimits _{i,\;y_i \!=\!h_t (x_i )} {c_i ^2w_i } \!-\!\sum \nolimits _{i,\;y_i \ne h_t (x_i )} {c_i ^2w_i } }{\sum \nolimits _i {c_i w_i } \!-\!\sum \nolimits _{i,\;y_i \!=\!h_t (x_i )} {c_i ^2w_i } \!+\!\sum \nolimits _{i,\;y_i \ne h_t (x_i )} {c_i ^2w_i } }\\ \displaystyle w_i \leftarrow c_i w_i e^{-\alpha _t c_i y_i h_t (x_i )},\;i=1,\ldots ,N \end{array}\nonumber \\ \end{aligned}$$]]></EquationSource>
                    </Equation>where <InlineEquation ID="IEq137">
                      <EquationSource Format="TEX"><![CDATA[$$c_i $$]]></EquationSource>
                    </InlineEquation> denotes the importance weight for each example <InlineEquation ID="IEq138">
                      <EquationSource Format="TEX"><![CDATA[$$x_i .$$]]></EquationSource>
                    </InlineEquation> The weight updating function of AdaC2 or AdaC3, i.e. Eq. (<InternalRef RefID="Equ28">28</InternalRef>) or (<InternalRef RefID="Equ28">28</InternalRef>), will be equivalent to the weight updating function of original AdaBoost algorithm in Fig. <InternalRef RefID="Fig2">2</InternalRef>, when the importance weight items are all set to 1.</Para>
                </Section3>
                <Section3 ID="Sec18">
                  <Heading>Importance weighted Gentleboost</Heading>
                  <Para>As far as we know, there have been no cost-sensitive extension reported for GentleBoost in the literature. Furthermore, none of the weight manipulations in cost-sensitive AdaBoost can be easily applied to derive cost-sensitive extensions for other boosting variants, such as GentleBoost. Therefore, we next attempt to derive the importance weighted extensions for GentleBoost by following the formulation of the additive logistic regression mode [<CitationRef CitationID="CR37">37</CitationRef>].</Para>
                  <Para>Boosting provides a generalized way to sequentially fit an additive regression model (<InternalRef RefID="Equ4">4</InternalRef>) and it minimizes the following exponential cost function, one term of the additive model at a time:<Equation ID="Equ29">
                      <EquationNumber>29</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} J(H)=E\left[ {e^{-yH(x)}} \right] \end{aligned}$$]]></EquationSource>
                    </Equation>where <InlineEquation ID="IEq139">
                      <EquationSource Format="TEX"><![CDATA[$$y$$]]></EquationSource>
                    </InlineEquation> denotes the class label <InlineEquation ID="IEq140">
                      <EquationSource Format="TEX"><![CDATA[$$\{-1,\;+1\}$$]]></EquationSource>
                    </InlineEquation>, and the term <InlineEquation ID="IEq141">
                      <EquationSource Format="TEX"><![CDATA[$$y{}H(x)$$]]></EquationSource>
                    </InlineEquation> indicates the margin, which is related to the generalization error (out-of-sample error rate). This cost function can be thought of as a differentiable upper bound on the misclassification rate [<CitationRef CitationID="CR52">52</CitationRef>]. It also shows that <InlineEquation ID="IEq142">
                      <EquationSource Format="TEX"><![CDATA[$$J(H)$$]]></EquationSource>
                    </InlineEquation> is minimized at:<Equation ID="Equ30">
                      <EquationNumber>30</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} H(x)=\frac{1}{2}\log \frac{P(y=+1\vert x)}{P(y=-1\vert x)} \end{aligned}$$]]></EquationSource>
                    </Equation>Hence we have<InlineEquation ID="IEq143">
                      <EquationSource Format="TEX"><![CDATA[$$P(y=+1\vert x)=\sigma (2H(x))$$]]></EquationSource>
                    </InlineEquation>, where <InlineEquation ID="IEq144">
                      <EquationSource Format="TEX"><![CDATA[$$\sigma (z)= \quad 1/(1+\exp (-z))$$]]></EquationSource>
                    </InlineEquation> is the logistic or sigmoid function. This is equivalent to the usual logistic transform of <InlineEquation ID="IEq145">
                      <EquationSource Format="TEX"><![CDATA[$$P(y=+1\vert x)$$]]></EquationSource>
                    </InlineEquation> up to a factor <InlineEquation ID="IEq146">
                      <EquationSource Format="TEX"><![CDATA[$$2$$]]></EquationSource>
                    </InlineEquation>. Boosting, consequently, can be viewed as step-wise estimation procedures for fitting an additive logistic regression model. In particular, GentleBoost optimizes <InlineEquation ID="IEq147">
                      <EquationSource Format="TEX"><![CDATA[$$J(H)$$]]></EquationSource>
                    </InlineEquation> using adaptive Newton steps, which corresponds to minimizing a weighted squared error at each step. Specifically, at each round <InlineEquation ID="IEq148">
                      <EquationSource Format="TEX"><![CDATA[$$t$$]]></EquationSource>
                    </InlineEquation>, the function <InlineEquation ID="IEq149">
                      <EquationSource Format="TEX"><![CDATA[$$H$$]]></EquationSource>
                    </InlineEquation> is updated as <InlineEquation ID="IEq150">
                      <EquationSource Format="TEX"><![CDATA[$$H(x)\leftarrow H(x)+h_{t} (x),$$]]></EquationSource>
                    </InlineEquation>where <InlineEquation ID="IEq151">
                      <EquationSource Format="TEX"><![CDATA[$$h_{t} (x)$$]]></EquationSource>
                    </InlineEquation> take one Newton step to minimize a second order Taylor approximation of the cost function <InlineEquation ID="IEq152">
                      <EquationSource Format="TEX"><![CDATA[$$J$$]]></EquationSource>
                    </InlineEquation>:<Equation ID="Equ31">
                      <EquationNumber>31</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \mathop {\arg \min }\limits _{h_{t} } J(H+h_{t} )&\!=\!\mathop {\arg \min }\limits _{h_{t} } \text{ E}\left[ {e^{\!-\!y(H(x)\!+\!h_{t} (x))}} \right]\nonumber \\ \quad \quad \quad \quad \quad&\simeq \mathop {\arg \min }\limits _{h_{t} } \text{ E}\left[ {e^{\!-\!yH(x)}(y\!-\!h_{{}t} (x))^2} \right]\\ \quad \quad \quad \quad \quad&\!=\!\mathop {\arg \min }\limits _{h_{t} } \text{ E}\left[ {w\cdot (y\!-\!h_{{}t} (x))^2} \right]\nonumber \end{aligned}$$]]></EquationSource>
                    </Equation>
                    <Equation ID="Equ32">
                      <EquationNumber>32</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} s.t. \quad w&\!=\!&e^{\!-\!yH(x)} \end{aligned}$$]]></EquationSource>
                    </Equation>Replacing the expectation with empirical cost over training data, it reduces to minimizing the weighted squared error:<Equation ID="Equ33">
                      <EquationNumber>33</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} J_{wse} =\sum \limits _{i=1}^N {w_i (y_i -h_{t} (x_i ))^2} \end{aligned}$$]]></EquationSource>
                    </Equation>where <InlineEquation ID="IEq153">
                      <EquationSource Format="TEX"><![CDATA[$$N$$]]></EquationSource>
                    </InlineEquation> is the number of training examples.</Para>
                  <Para>First, we propose to incorporate importance weight into the cost function formula as a linear factor:<Equation ID="Equ34">
                      <EquationNumber>34</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} J(H)=\text{ E}\left[ {c\cdot e^{-yH(x)}} \right] \end{aligned}$$]]></EquationSource>
                    </Equation>where <InlineEquation ID="IEq154">
                      <EquationSource Format="TEX"><![CDATA[$$c$$]]></EquationSource>
                    </InlineEquation> denote the importance weight for each example <InlineEquation ID="IEq155">
                      <EquationSource Format="TEX"><![CDATA[$$x$$]]></EquationSource>
                    </InlineEquation>. Hence, we also choose to minimize the second order Taylor approximation of this new cost function:<Equation ID="Equ35">
                      <EquationNumber>35</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \mathop {\arg \min }\limits _{h_{t} } J(H\!+\!h_t)&\!=\!\mathop {\arg \min }\limits _{h_{t} } \text{ E}\left[ {c\cdot e^{\!-\!y(H(x)\!+\!h_t (x))}} \right]\nonumber \\ \quad \quad \quad \quad \quad&\simeq \mathop {\arg \min }\limits _{h_{t} } \text{ E}\left[ {c\cdot e^{-yH(x)}(y-h_t (x))^2} \right]\\ \quad \quad \quad \quad \quad&= \mathop {\arg \min }\limits _{h_{t} } \text{ E}\left[ {w\cdot (y-h_t (x))^2} \right]\nonumber \end{aligned}$$]]></EquationSource>
                    </Equation>
                    <Equation ID="Equ36">
                      <EquationNumber>36</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} s.t.\quad w&= c\cdot e^{-yH(x)} \end{aligned}$$]]></EquationSource>
                    </Equation>Empirically, this also reduces to minimizing the weighted square error in (<InternalRef RefID="Equ33">33</InternalRef>), but with a new weight function (<InternalRef RefID="Equ36">36</InternalRef>). The weighs thus get updated by:<Equation ID="Equ37">
                      <EquationNumber>37</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \begin{aligned} w^{(t+1)}&=ce^{-y(H(x)+h_{t+1} (x))} \\&=ce^{-yH(x)}\cdot e^{-yh_{t+1} (x)} \\&=w^{(t)}\cdot e^{-yh_{t+1} (x)} \\ \end{aligned} \end{aligned}$$]]></EquationSource>
                    </Equation>This is equivalent to initializing the boosting weights with importance weights, but updating them using the same rule in GentleBoost.</Para>
                  <Para>Compared with the exponential influence of the term <InlineEquation ID="IEq156">
                      <EquationSource Format="TEX"><![CDATA[$$y{}H(x)$$]]></EquationSource>
                    </InlineEquation> which is associated with the generalization error, the importance weight <InlineEquation ID="IEq157">
                      <EquationSource Format="TEX"><![CDATA[$$c$$]]></EquationSource>
                    </InlineEquation> has much less effect on the cost function (<InternalRef RefID="Equ34">34</InternalRef>) as a linear factor. Therefore, a second heuristic idea is to formulate it inside the exponent of the cost function:<Equation ID="Equ38">
                      <EquationNumber>38</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \quad \quad \quad \quad J(H)=\text{ E}\left[ {e^{-cyH(x)}} \right] \end{aligned}$$]]></EquationSource>
                    </Equation>Now the second order Taylor approximation we want to optimize is defined as follows:<Equation ID="Equ39">
                      <EquationNumber>39</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} \begin{aligned} \mathop {\arg \min }\limits _{h_{t} } J(H\!+\!h_t )&\!=\!\mathop {\arg \min }\limits _{h_{t} } \text{ E}\left[ {e^{\!-\!cy(H(x)\!+\!h_t (x))}} \right] \\&\simeq \mathop {\arg \min }\limits _{h_{t} } \text{ E}\left[ {e^{\!-\!cyH(x)}(y\!-\!c\cdot h_t (x))^2} \right] \\ \end{aligned} \end{aligned}$$]]></EquationSource>
                    </Equation>It then, empirically, reduces to minimizing the weighted squared error of the form:<Equation ID="Equ40">
                      <EquationNumber>40</EquationNumber>
                      <EquationSource Format="TEX"><![CDATA[$$\begin{aligned} J_{wse} =\sum \limits _{i=1}^N {w_i (y_i -c_i \cdot h_{t} (x_i ))^2} \end{aligned}$$]]></EquationSource>
                    </Equation>where <InlineEquation ID="IEq158">
                      <EquationSource Format="TEX"><![CDATA[$$w_i =e^{-c_i y_i H(x_i )}$$]]></EquationSource>
                    </InlineEquation>. However, in order to minimize the sum of squared residuals, the target value of <InlineEquation ID="IEq159">
                      <EquationSource Format="TEX"><![CDATA[$$h_{t} (x_i )$$]]></EquationSource>
                    </InlineEquation> for each example <InlineEquation ID="IEq160">
                      <EquationSource Format="TEX"><![CDATA[$$x_i $$]]></EquationSource>
                    </InlineEquation> depends on its importance weight factor <InlineEquation ID="IEq161">
                      <EquationSource Format="TEX"><![CDATA[$$c_i $$]]></EquationSource>
                    </InlineEquation>. It makes no sense at all that the weak learner seeks different prediction ranges for different examples and we are not able to solve this problem by following the formulation of GentleBoost any more. Overall, our importance weighted Gentleboost is implemented according to the cost function (<InternalRef RefID="Equ34">34</InternalRef>), which only modifies the initialization procedure of the original GentleBoost in Fig. <InternalRef RefID="Fig4">4</InternalRef>.</Para>
                </Section3>
              </Section2>
              <Section2 ID="Sec19">
                <Heading>Tag relevance-based importance weighting</Heading>
                <Para>Since one-against-all strategy is performed to reduce our multi-class classification problem into multiple binary problems, two tag relevance-based importance weighting schemes are proposed, namely per-concept weighting and per-image weighting, concentrating on the binary distinction of positive versus negative. In general, for a given concept, higher relevance value leads to a higher importance weight in the training process. And we assume that all tag relevance values are normalized into <InlineEquation ID="IEq162">
                    <EquationSource Format="TEX"><![CDATA[$$(0,\,1).$$]]></EquationSource>
                  </InlineEquation>
                </Para>
                <Para>In per-concept weighting scheme, for each annotation concept, we first learn the visual relevance of this concept with respect to all the training images even if it is not present in the user-contributed tags of an image. Then, to solve the binary classification problem of a target concept, all the images labeled with this concept are trained as positive examples and take importance weights that equal to their tag relevance value, while images not labeled with this concept, as negative examples, take importance weights according to <InlineEquation ID="IEq163">
                    <EquationSource Format="TEX"><![CDATA[$$(1-TagRelevance).$$]]></EquationSource>
                  </InlineEquation> On the other hand, for each training image, we only learn the relevance of all its user-provided tags in per-image weighting scheme. And then their tag relevance and importance weights are equivalently used regardless of an image being trained as positive or negative example in a binary classification problem of a given concept.</Para>
              </Section2>
            </Section1>
            <Section1 ID="Sec20">
              <Heading>Experimental setup</Heading>
              <Section2 ID="Sec21">
                <Heading>Dataset</Heading>
                <Para>
                  <Emphasis Type="Bold">Social20</Emphasis> [<CitationRef CitationID="CR53">53</CitationRef>] is a collection of 19,972 social-tagged images with 20 diverse visual concepts randomly collected from Flickr. For each concept, it consists of 1,000 example images labeled with that concept, as well as other annotation concepts, by user tagging. It has been known that social tags can be very subjective and overly personalized, as a result, often irrelevant to the visual contents of images. Therefore, these social images have also been manually relabeled in terms of their visual relevance: we consider a semantic concept and an image relevant if the concept is clearly visible in the image and we shall relate the concept to the visual content easily and consistently with common knowledge. Finally, only 5,241 images are preserved after the manual relabeling, because some of the images are visually irrelevant to all of our target 20 concepts. The dataset is evenly split into training data and testing data. In our experiments, we have used both social and manual tags to investigate our algorithms and the performance evaluation is always based on the manual annotations.</Para>
              </Section2>
              <Section2 ID="Sec22">
                <Heading>Evaluation criteria</Heading>
                <Section3 ID="Sec23">
                  <Heading>Image ranking evaluation</Heading>
                  <Para>To measure image ranking performance we use average precision (AP) and break event point precision (BEP). For a given semantic concept, we rank all the images by their predicted probabilities and evaluate precisions at each position according to the manual annotations. AP averages the precision over all positions of relevant images, whereas BEP computes the precision just at one position, which is the number of relevant images that are manually labeled with that concept. Both measures are evaluated per concept, and finally averaged over all the concepts to obtain a single measure. These measures indicate how well we can retrieve relevant images from the database in response to the keyword-based user queries.</Para>
                </Section3>
                <Section3 ID="Sec24">
                  <Heading>Concept ranking evaluation</Heading>
                  <Para>In addition to image ranking measures, we also evaluate concept ranking performance by mean reciprocal rank (MRR). For each image, we rank all its possible concepts by their predictions, then compute mean of the reciprocal ranks of the manually annotated concepts for this image and finally average them over all the images. This measures how well we can automatically identify or recommend relevant annotation concepts for images.</Para>
                </Section3>
              </Section2>
              <Section2 ID="Sec25">
                <Heading>Visual feature extraction</Heading>
                <Para>We extract global features and local features of images which are commonly used for image retrieval and categorization to enhance the performance of visual concept learning. There are two types of global visual features: Color and Gist. The Color features consist of the color correlogram [<CitationRef CitationID="CR54">54</CitationRef>], the texture moments [<CitationRef CitationID="CR55">55</CitationRef>] and the RGB color moments. The Gist is a popular global feature which represents the dominant spatial structure of a scene by a set of perceptual dimensions, such as naturalness, openness, roughness, expansion, ruggedness [<CitationRef CitationID="CR56">56</CitationRef>]. As for local features we use the SIFT descriptor [<CitationRef CitationID="CR19">19</CitationRef>], and both dense grid and Laplacian of Gaussian (LoG) keypoint detector are used for point sampling. Each local feature descriptor is quantized using k-means clustering (1,000 cluster centers) on samples from the training set, and images are then represented as “bag-of-words” histograms. In order to encode the spatial layout of the image to some degree, we follow the approach of [<CitationRef CitationID="CR24">24</CitationRef>], and compute the histogram by two-level spatial pyramids over different image regions. The images are sampled over three horizontal sub-regions, i.e. 1 <InlineEquation ID="IEq164">
                    <EquationSource Format="TEX"><![CDATA[$$\times $$]]></EquationSource>
                  </InlineEquation> 3, reflecting the typical top, middle and bottom layout of landscape photography. At last, two-level histograms are weighted and combined into a single histogram (<InlineEquation ID="IEq165">
                    <EquationSource Format="TEX"><![CDATA[$$4\times 1{,}000-d$$]]></EquationSource>
                  </InlineEquation>). To compute distances from the feature descriptors in the visual neighbor voting model and SVMs kernel functions, we use Euclidean distance (<InlineEquation ID="IEq166">
                    <EquationSource Format="TEX"><![CDATA[$$L_2 )$$]]></EquationSource>
                  </InlineEquation> for Color and Gist features, Chi-square distance (<InlineEquation ID="IEq167">
                    <EquationSource Format="TEX"><![CDATA[$$\chi ^2)$$]]></EquationSource>
                  </InlineEquation> for SIFT and Dense SIFT histograms.</Para>
              </Section2>
            </Section1>
            <Section1 ID="Sec26">
              <Heading>Experimental results</Heading>
              <Section2 ID="Sec27">
                <Heading>Experiment 1: tag relevance learning</Heading>
                <Para>In our first set of experiments, we used different variants of the visual neighbor voting model to predict the visual relevance of the target 20 annotated concepts. The tag relevance learning methods we evaluated include one unsupervised model using uniform weights and two supervised models using distance- or rank-based weights. A common parameter to optimize for all these models is <InlineEquation ID="IEq168">
                    <EquationSource Format="TEX"><![CDATA[$$K,$$]]></EquationSource>
                  </InlineEquation> which is the number of visual neighbors used to vote a seed image. We test and choose <InlineEquation ID="IEq169">
                    <EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource>
                  </InlineEquation> from the set <InlineEquation ID="IEq170">
                    <EquationSource Format="TEX"><![CDATA[$$\{10,\,20,\,50,\,100,\,200,\,500,\,1{,}\!000\}.$$]]></EquationSource>
                  </InlineEquation> The supervised learning models, particularly, required to be trained on a set of manually labeled example images. This can be done either using held-out data or in a leave-one-out manner. In our experiments, we have used the same training set for neighbor voting and supervised learning in leave-one-out manner. Moreover, we investigate this visual neighbor voting model both by use of images with social tags and manual annotations. The social-tagged dataset was filtered by relabeling and the resultant manually tagged dataset has a smaller size than the former. Because of the noise in the social tags, performance was always evaluated based on the manual annotations. In Fig. <InternalRef RefID="Fig6">6</InternalRef>, we give an overview of performance of the three tag relevance learning methods in terms of AP, BEP and MRR, as a function of the number of visual neighbors <InlineEquation ID="IEq171">
                    <EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource>
                  </InlineEquation> which is used in the nearest neighbor searching process.<Figure Category="Standard" Float="Yes" ID="Fig6">
                    <Caption Language="En">
                      <CaptionNumber>Fig. 6</CaptionNumber>
                      <CaptionContent>
                        <SimplePara>Comparison in terms of AP, BEP and MRR performance of visual neighbor voting model using uniform, distance-based and rank-based weights. All the models are trained with different values for parameter <Emphasis Type="Italic">K</Emphasis>, as well as using <Emphasis Type="Bold">a</Emphasis> social tags or <Emphasis Type="Bold">b</Emphasis> manual tags. Note the log scale on the <Emphasis Type="Italic">horizontal axis</Emphasis>.</SimplePara>
                      </CaptionContent>
                    </Caption>
                    <MediaObject ID="MO46">
                      <ImageObject Color="Color" FileRef="MediaObjects/13735_2012_22_Fig6_HTML.gif" Format="GIF" Rendition="HTML" Type="LinedrawHalftone"/>
                    </MediaObject>
                  </Figure>
                </Para>
                <Para>As shown in Fig. <InternalRef RefID="Fig6">6</InternalRef>a when trained on social-tagged images, all the variants of the weighted nearest neighbor voting model, i.e. using uniform, distance-based and rank-based weights, can make constant improvements in terms of AP, BEP and MRR performance with an increasing number of visual neighbors used for voting. Meanwhile, using much more neighbors has a slight negative effect on performance. This is easy to understand that it is more likely to include useful visual neighbors from more different neighborhoods, however, more neighbors will lead to more noise when most of the useful neighbors have been included. The optimal parameter setting for our three variant models is <InlineEquation ID="IEq172">
                    <EquationSource Format="TEX"><![CDATA[$$K=100, K=200,$$]]></EquationSource>
                  </InlineEquation> and <InlineEquation ID="IEq173">
                    <EquationSource Format="TEX"><![CDATA[$$K=500,$$]]></EquationSource>
                  </InlineEquation> respectively. In addition, we observe that the uniform and rank-based weighting models get very comparable results in terms of AP and BEP. But the MRR score evaluated using uniform weights drops significantly as a result of using more and more neighbors, and it is mostly much lower than that when using distance-based or rank-based weights. Therefore the supervised tag relevance learning model has much better discriminative capabilities between semantic concepts than the unsupervised learning model in this case. Using rank-based weights always yields higher values of AP, BEP and MRR than using distance-based weights.</Para>
                <Para>The results of using manual annotations, in Fig. <InternalRef RefID="Fig6">6</InternalRef>b, illustrate a considerable performance improvement compared to using social tags. And the increase is more pronounced in terms of AP and BEP than in MRR. We can observe very similar impact of using an increasing number of visual neighbors on performance. However, the AP, BEP and MRR scores yielded by the uniform weighting model start to decrease quickly from the beginning with a relatively small value of parameter <InlineEquation ID="IEq174">
                    <EquationSource Format="TEX"><![CDATA[$$K.$$]]></EquationSource>
                  </InlineEquation> The optimal choice of <InlineEquation ID="IEq175">
                    <EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource>
                  </InlineEquation> neighbors, in this case, is <InlineEquation ID="IEq176">
                    <EquationSource Format="TEX"><![CDATA[$$K=50, \quad K=200$$]]></EquationSource>
                  </InlineEquation> and <InlineEquation ID="IEq177">
                    <EquationSource Format="TEX"><![CDATA[$$K=200$$]]></EquationSource>
                  </InlineEquation> respectively. The unsupervised tag relevance learning model now is largely outperformed by the supervised learning models in terms of all the evaluation criteria. Likewise, using rank-based weights achieves better performance than using distance-based weights.</Para>
                <Para>For the following experiments, we also use these three tag relevance learning methods for comparisons with other visual concept learning algorithms, and the parameter of <InlineEquation ID="IEq178">
                    <EquationSource Format="TEX"><![CDATA[$$K$$]]></EquationSource>
                  </InlineEquation> neighbors is always set optimally.</Para>
              </Section2>
              <Section2 ID="Sec28">
                <Heading>Experiment 2: visual concept learning</Heading>
                <Para>In this section we investigate SVMs, boosting variants, as well as their importance weighted extensions for visual concept learning by use of social tags or manual annotations. First, we evaluate different variants of the boosting algorithm, and feature combination approaches integrated at each round of boosting procedures. Second, an overall comparison of performance between SVMs, boosting variants and tag relevance learning methods is presented. Third, we analyze the results of our importance weighted SVMs and boosting algorithms when learning visual concepts from weakly labeled social images.</Para>
                <Section3 ID="Sec29">
                  <Heading>Evaluating boosting variants</Heading>
                  <Para>We compare three boosting variants, including AdaBoost, RealBoost and GentleBoost. Three different feature combination approaches are also integrated into each boosting variant and evaluated. Moreover, we follow the AdaBoost.MH algorithm [<CitationRef CitationID="CR37">37</CitationRef>] to convert the multi-class problem using one-against-all strategy. However, rather than building one large tree using class label as an additional input feature, we implemented it using the more traditional direct approach of building separate trees to solve each binary problem. All the boosting variants used classification and regression tress (CART) as weak learners. The parameters of CART classifiers are optimally selected. Unless otherwise noted, we at most construct 100 trees for each feature, i.e. the maximal number of boosting rounds is 100.</Para>
                  <Para>From the results in Table <InternalRef RefID="Tab2">2</InternalRef> we can make several observations. For both choices of using social tags and manual tags, GentleBoost achieves the best performance among all the boosting variants. AdaBoost and RealBoost over-emphasize on the atypical examples which eventually result in inferior rules. By contrast, GentleBoost is numerically robust and gives less emphasis to misclassified examples at each round since the increase in the weight of the example is quadratic in the negative margin, rather than exponential [<CitationRef CitationID="CR57">57</CitationRef>]. Additionally, combining the weak learners trained on multiple features at each round of boosting procedures consistently has a beneficial effect on all the boosting variants, since the uniform or error-based weighting scheme completely outperforms the feature selection approach (selecting the best one). In general, the uniform weighting works slightly better than the error-based weighting. However, the contrary is the case for GentleBoost when using social tags. Using manual annotations greatly improves the performance of using social tags. But the improvement is more noticeable in terms of AP and BEP than in MRR. In particular, the MRR score of AdaBoost even drops a little when using manual annotations. The reason for this might be that there are much less training examples in the manually labeled dataset. We note that the boosting algorithm might be improved, particularly in terms of MRR performance, using other multi-class algorithms, such as [<CitationRef CitationID="CR58">58</CitationRef>]. In the following experiments of visual concept learning, we just consider the better performing uniform weighting scheme in all the boosting algorithms for comparisons.<Table Float="Yes" ID="Tab2">
                      <Caption Language="En">
                        <CaptionNumber>Table 2</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Comparison on AP, BEP and MRR (%) for different boosting variants</SimplePara>
                        </CaptionContent>
                      </Caption>
                      <tgroup cols="10">
                        <colspec align="left" colname="c1" colnum="1"/>
                        <colspec align="left" colname="c2" colnum="2"/>
                        <colspec align="left" colname="c3" colnum="3"/>
                        <colspec align="left" colname="c4" colnum="4"/>
                        <colspec align="left" colname="c5" colnum="5"/>
                        <colspec align="left" colname="c6" colnum="6"/>
                        <colspec align="left" colname="c7" colnum="7"/>
                        <colspec align="left" colname="c8" colnum="8"/>
                        <colspec align="left" colname="c9" colnum="9"/>
                        <colspec align="left" colname="c10" colnum="10"/>
                        <thead>
                          <row>
                            <entry align="left" colname="c1"/>
                            <entry align="left" colname="c2">
                              <SimplePara>Ada(b)</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>Real(b)</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>Gentle(b)</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>Ada(u)</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>Real(u)</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>Gentle(u)</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>Ada(e)</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>Real(e)</SimplePara>
                            </entry>
                            <entry align="left" colname="c10">
                              <SimplePara>Gentle(e)</SimplePara>
                            </entry>
                          </row>
                        </thead>
                        <tbody>
                          <row>
                            <entry align="left" nameend="c10" namest="c1">
                              <SimplePara>(a) Social tags</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   AP</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>69.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>62.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">71.6</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>71.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>67.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">71.9</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>70.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>66.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c10">
                              <SimplePara>
                                <Emphasis Type="Italic">71.8</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   BEP</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>65.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>59.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">68.0</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>67.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>64.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>
                                <Emphasis Type="Italic">68.5</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>67.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>64.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c10">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">68.6</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   MRR</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>59.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>41.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">68.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>70.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>55.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>
                                <Emphasis Type="Italic">71.0</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>65.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>51.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c10">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">71.3</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                        </tbody>
                      </tgroup>
                      <tgroup cols="10">
                        <colspec align="left" colname="c1" colnum="1"/>
                        <colspec align="left" colname="c2" colnum="2"/>
                        <colspec align="left" colname="c3" colnum="3"/>
                        <colspec align="left" colname="c4" colnum="4"/>
                        <colspec align="left" colname="c5" colnum="5"/>
                        <colspec align="left" colname="c6" colnum="6"/>
                        <colspec align="left" colname="c7" colnum="7"/>
                        <colspec align="left" colname="c8" colnum="8"/>
                        <colspec align="left" colname="c9" colnum="9"/>
                        <colspec align="left" colname="c10" colnum="10"/>
                        <thead>
                          <row>
                            <entry align="left" nameend="c10" namest="c1">
                              <SimplePara>(b) Manual tags</SimplePara>
                            </entry>
                          </row>
                        </thead>
                        <tbody>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   AP</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>81.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>76.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">83.4</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>84.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>81.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">85.0</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>83.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>80.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c10">
                              <SimplePara>
                                <Emphasis Type="Italic">84.7</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   BEP</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>75.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>71.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">77.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>78.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>75.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">78.8</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>77.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>74.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c10">
                              <SimplePara>
                                <Emphasis Type="Italic">78.6</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   MRR</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>53.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>47.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">69.8</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>61.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>64.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>
                                <Emphasis Type="Italic">72.6</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>53.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>62.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c10">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">72.8</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                        </tbody>
                      </tgroup>
                      <tfooter>
                        <SimplePara>(b), (u) and (e), respectively, denote selecting the best feature, uniform and error-based weighting scheme for feature combination at each round of boosting procedures. The better performance between boosting variants using each weighting scheme is italicized, while the best performance among all methods is bolded</SimplePara>
                      </tfooter>
                    </Table>
                  </Para>
                </Section3>
                <Section3 ID="Sec30">
                  <Heading>Learning visual concepts</Heading>
                  <Para>In addition to boosting algorithms, we also use SVMs to learn separate classifiers for each concept by one-against-all strategy. In order to rank the concepts for a given image we need to compare the output scores of different SVM classifiers. To this end we perform cross-validation on the training data to fit a sigmoid function to map the SVM scores to probabilities. The regularization parameter <InlineEquation ID="IEq179">
                      <EquationSource Format="TEX"><![CDATA[$$C$$]]></EquationSource>
                    </InlineEquation> of the SVMs is also optimally selected by fivefold cross-validation.</Para>
                  <Para>In Table <InternalRef RefID="Tab3">3</InternalRef>, we present the overall results of all the visual concept learning algorithms described in this paper. As illustrated in Table <InternalRef RefID="Tab3">3</InternalRef>a when learned from social-tagged images, the visual neighbor voting model using uniform and rank-based weights obtains the best results in terms of AP and BEP respectively, while the SVM approach outperforms other classification algorithms in terms of concept ranking evaluation. In Table <InternalRef RefID="Tab3">3</InternalRef>b, by contrast, we observe an obvious improvement in performance when trained using manual annotations. SVMs now achieve the best performance in terms of all of our evaluation criteria. Furthermore, in both cases, visual neighbor voting model using rank-based weights and GentleBoost classifier gives more competitive performance than other variants of the tag relevance learning model or the boosting algorithm. We have to emphasize that SVM classifier exhibits more powerful discriminative capabilities between semantic concepts than all the other classifiers in our experiments, as it yields much higher MRR scores in both cases.<Table Float="Yes" ID="Tab3">
                      <Caption Language="En">
                        <CaptionNumber>Table 3</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Overall comparison on AP, BEP and MRR (%) for visual concept learning</SimplePara>
                        </CaptionContent>
                      </Caption>
                      <tgroup cols="4">
                        <colspec align="left" colname="c1" colnum="1"/>
                        <colspec align="left" colname="c2" colnum="2"/>
                        <colspec align="left" colname="c3" colnum="3"/>
                        <colspec align="left" colname="c4" colnum="4"/>
                        <thead>
                          <row>
                            <entry align="left" colname="c1"/>
                            <entry align="left" colname="c2">
                              <SimplePara>AP</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>BEP</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>MRR</SimplePara>
                            </entry>
                          </row>
                        </thead>
                        <tbody>
                          <row>
                            <entry align="left" nameend="c4" namest="c1">
                              <SimplePara>(a) Social tags</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Uniform</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">74.8</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>69.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>64.2</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Distance</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>72.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>68.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>70.3</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Rank</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>74.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">70.0</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>70.7</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Ada</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>71.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>67.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>70.1</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Real</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>67.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>64.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>55.9</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Gentle</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>71.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>68.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>71.0</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   SVM</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>73.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>69.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">74.2</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" nameend="c4" namest="c1">
                              <SimplePara>(b) Manual tags</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Uniform</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>82.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>77.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>68.0</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Distance</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>83.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>77.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>72.3</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Rank</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>84.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>78.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>72.8</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Ada</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>84.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>78.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>61.9</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Real</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>81.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>75.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>64.5</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   Gentle</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>85.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>78.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>72.6</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>   SVM</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">86.9</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">80.0</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">78.9</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                        </tbody>
                      </tgroup>
                      <tfooter>
                        <SimplePara>The best performance among all methods in terms of each evaluation criterion is italicized and bolded</SimplePara>
                      </tfooter>
                    </Table>
                  </Para>
                  <Para>In order to feed the importance weights to our importance weighted classifiers, we first perform tag relevance learning on the training dataset. Specifically, we learn the tag relevance of each training example by visual neighbor voting in a leave-one-out manner. Here, the unsupervised tag relevance learning model using uniform weights is preferred, since the supervised learning models require manually labeled training data. We also study two relevance-based importance weighting schemes, i.e. per-image and per-concept weighting, to convert the tag relevance into importance weights for each training example. Apart from this, we use the same configurations, such as the choice of kernel function in SVM or weak learner in boosting, as above for our importance weighted SVMs and boosting algorithms in the following experiments.</Para>
                  <Para>As shown in Tables <InternalRef RefID="Tab3">3</InternalRef>a and <InternalRef RefID="Tab4">4</InternalRef>, the cost-sensitive extensions of AdaBoost, i.e. AdaC2 and AdaC3, have very poor performance in terms of MRR, while they make some improvements in AP or BEP in comparison to classic AdaBoost without using importance weights. The importance weighted GentleBoost works much better than them. In particular, compared with original GentleBoost, its MRR score increases by up to 1.1 %, which is hard to achieve for GentleBoost even using manual annotations. Note that there was not a comparison on GentleBoost using cost-sensitive versus importance weighting because we were not aware of a cost-sensitive GentleBoost in the research literature. Incorporating the importance weights into SVM classifiers gives the best performance. And the largest improvement made in terms of AP, BEP and MRR score is 2.5, 1.7 and 0.9 %, respectively. A limitation of the importance weighted classification is that for visual concepts that have large intra-class variations, it may fail to learn the example images with relatively rare visual appearance, since these examples probably have less visual neighbors in the training dataset, thus have smaller importance weights. As a result, the semantic concepts that are hard to learn due to intra-class variations will become harder to learn.<Table Float="Yes" ID="Tab4">
                      <Caption Language="En">
                        <CaptionNumber>Table 4</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Comparison on AP, BEP and MRR (%) for cost-sensitive and importance weighted concept learning</SimplePara>
                        </CaptionContent>
                      </Caption>
                      <tgroup cols="9">
                        <colspec align="left" colname="c1" colnum="1"/>
                        <colspec align="left" colname="c2" colnum="2"/>
                        <colspec align="left" colname="c3" colnum="3"/>
                        <colspec align="left" colname="c4" colnum="4"/>
                        <colspec align="left" colname="c5" colnum="5"/>
                        <colspec align="left" colname="c6" colnum="6"/>
                        <colspec align="left" colname="c7" colnum="7"/>
                        <colspec align="left" colname="c8" colnum="8"/>
                        <colspec align="left" colname="c9" colnum="9"/>
                        <thead>
                          <row>
                            <entry align="left" colname="c1"/>
                            <entry align="left" colname="c2">
                              <SimplePara>AdaC2(i)</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>AdaC3(i)</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>Gentle-IW(i)</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>SVM-IW(i)</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>AdaC2(c)</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>AdaC3(c)</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>Gentle-IW(c)</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>SVM-IW(c)</SimplePara>
                            </entry>
                          </row>
                        </thead>
                        <tbody>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>AP</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>73.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>72.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>72.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>
                                <Emphasis Type="Italic">75.8</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>73.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>73.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>72.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">76.1</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>BEP</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>68.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>67.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>68.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">71.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>69.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>68.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>68.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>
                                <Emphasis Type="Italic">71.2</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>MRR</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>66.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>60.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>72.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>
                                <Emphasis Type="Italic">75.0</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>63.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>61.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>71.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">75.1</Emphasis>
                              </SimplePara>
                            </entry>
                          </row>
                        </tbody>
                      </tgroup>
                      <tfooter>
                        <SimplePara>Gentle-IW and SVM-IW denote the importance weighted GentleBoost and SVM. (i) and (c) denote per-image and per-concept weighing scheme for tag relevance-based importance weighting. The better performance between methods using each weighing scheme is italicized, while the best performance among all methods is bolded</SimplePara>
                      </tfooter>
                    </Table>
                  </Para>
                  <Para>Table <InternalRef RefID="Tab5">5</InternalRef> lists the performance in terms of AP for all 20 annotation concepts in our evaluation dataset. It reveals that only around 52 % of the user-supplied annotation concepts are truly related to the visual content of the training images. In general, concepts with higher user tagging accuracy achieve higher AP scores. For example, the most precisely user-labeled concept “flower” yields a higher score than the others when training with social tags, and the concept “lion” obtains a significant improvement when using manual annotations. However, some concepts can still perform well even with bad tagging accuracy, such as “kitchen” and “classroom”. On the other hand, there is no obvious rise in terms of AP score for semantic concepts, such as “boat”, even though when learning from manually annotated images. And similar observations can be made on the performance in terms of BEP and MRR which are not given here.<Table Float="Yes" ID="Tab5">
                      <Caption Language="En">
                        <CaptionNumber>Table 5</CaptionNumber>
                        <CaptionContent>
                          <SimplePara>Comparison on AP (%) for All 20 concepts</SimplePara>
                        </CaptionContent>
                      </Caption>
                      <tgroup cols="9">
                        <colspec align="left" colname="c1" colnum="1"/>
                        <colspec align="left" colname="c2" colnum="2"/>
                        <colspec align="left" colname="c3" colnum="3"/>
                        <colspec align="left" colname="c4" colnum="4"/>
                        <colspec align="left" colname="c5" colnum="5"/>
                        <colspec align="left" colname="c6" colnum="6"/>
                        <colspec align="left" colname="c7" colnum="7"/>
                        <colspec align="left" colname="c8" colnum="8"/>
                        <colspec align="left" colname="c9" colnum="9"/>
                        <thead>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>AP</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>Uniform</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>Distance</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>Rank</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>Gentle</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>SVM</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>Gentle-IW</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>SVM-IW</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>Tagging accuracy</SimplePara>
                            </entry>
                          </row>
                        </thead>
                        <tbody>
                          <row>
                            <entry align="left" nameend="c9" namest="c1">
                              <SimplePara>(a) Social tags</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Airplane</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>49.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>
                                <Emphasis Type="Italic">57.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>52.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>50.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>53.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>51.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>51.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>45.3</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Beach</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>68.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>68.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>67.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>66.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>68.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>68.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>
                                <Emphasis Type="Italic">71.8</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>33.1</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Boat</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>57.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>58.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">59.4</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>55.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>53.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>55.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>58.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>44.9</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Bridge</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>85.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>86.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>86.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>86.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>86.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>
                                <Emphasis Type="Italic">87.0</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>86.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>76.6</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Bus</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>91.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>90.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>92.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>92.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">94.5</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>92.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>94.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>62.8</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Utterfly</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>92.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>85.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>88.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>86.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>91.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>86.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>
                                <Emphasis Type="Italic">93.1</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>68.8</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Car</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>82.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>82.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">83.2</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>78.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>82.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>79.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>83.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>55.2</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Cityscape</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>
                                <Emphasis Type="Italic">97.4</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>91.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>96.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>91.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>91.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>90.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>96.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>64.0</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Classroom</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>75.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>66.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>76.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>65.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">76.8</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>61.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>76.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>38.6</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Dog</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>87.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>83.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>85.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>88.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">88.9</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>88.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>88.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>75.2</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Flower</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>96.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>97.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>97.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>
                                <Emphasis Type="Italic">97.8</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>97.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>97.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>97.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>82.9</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Harbor</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>
                                <Emphasis Type="Italic">78.2</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>70.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>74.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>68.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>69.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>68.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>76.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>50.4</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Horse</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>86.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>87.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">89.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>82.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>83.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>83.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>85.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>73.6</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Kitchen</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>84.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>81.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>84.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>81.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>88.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>84.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>
                                <Emphasis Type="Italic">89.2</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>38.6</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Lion</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>48.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>45.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>46.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>45.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>39.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>45.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>
                                <Emphasis Type="Italic">48.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>34.6</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Mountain</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>82.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>80.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>83.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>83.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>83.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>84.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>
                                <Emphasis Type="Italic">85.5</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>47.6</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Rhino</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>70.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>61.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>73.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>60.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>71.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>62.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>
                                <Emphasis Type="Italic">75.5</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>36.0</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Sheep</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>
                                <Emphasis Type="Italic">75.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>64.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>68.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>74.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>70.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>72.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>75.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>53.0</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Street</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>69.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>69.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>71.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>68.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>66.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>66.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>
                                <Emphasis Type="Italic">71.6</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>43.8</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Tiger</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>16.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>16.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>16.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>16.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>15.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>
                                <Emphasis Type="Italic">16.8</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>16.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>23.4</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Mean</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>74.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>72.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>74.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>71.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>73.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c7">
                              <SimplePara>72.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c8">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">76.1</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c9">
                              <SimplePara>52.4</SimplePara>
                            </entry>
                          </row>
                        </tbody>
                      </tgroup>
                      <tgroup cols="9">
                        <colspec align="left" colname="c1" colnum="1"/>
                        <colspec align="left" colname="c2" colnum="2"/>
                        <colspec align="left" colname="c3" colnum="3"/>
                        <colspec align="left" colname="c4" colnum="4"/>
                        <colspec align="left" colname="c5" colnum="5"/>
                        <colspec align="left" colname="c6" colnum="6"/>
                        <colspec align="left" colname="c7" colnum="7"/>
                        <colspec align="left" colname="c8" colnum="8"/>
                        <colspec align="left" colname="c9" colnum="9"/>
                        <thead>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara> AP</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>Uniform</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>Distance</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>Rank</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>Gentle</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>SVM</SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                        </thead>
                        <tbody>
                          <row>
                            <entry align="left" nameend="c9" namest="c1">
                              <SimplePara>(b) Manual tags</SimplePara>
                            </entry>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Airplane</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>71.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>76.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>77.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>69.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">80.9</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Beach</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>70.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>69.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>70.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>73.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">75.1</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Boat</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>58.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>59.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>61.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>
                                <Emphasis Type="Italic">62.6</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>61.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Bridge</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>85.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>86.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>86.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>87.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">88.9</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Bus</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>91.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>92.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>92.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>93.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">95.5</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Butterfly</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>93.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>93.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>94.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>94.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">94.6</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Car</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>83.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>84.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>84.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>84.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">84.9</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Cityscape</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>98.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>97.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>
                                <Emphasis Type="Italic">98.4</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>98.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>97.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Classroom</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>81.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>79.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>80.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>83.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">86.5</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Dog</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>87.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>86.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>86.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>90.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">90.7</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Flower</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>96.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>96.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>96.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>97.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">97.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Harbor</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>90.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>90.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>90.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>91.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">92.2</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Horse</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>88.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>
                                <Emphasis Type="Italic">91.9</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>91.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>85.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>89.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Kitchen</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>85.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>84.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>85.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>88.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">91.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Lion</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>65.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>68.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>70.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>78.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">79.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Mountain</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>83.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>85.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>85.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>86.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">87.2</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Rhino</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>83.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>86.4</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>86.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>88.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">91.3</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Sheep</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>77.2</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>76.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>78.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>
                                <Emphasis Type="Italic">81.7</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>81.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Street</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>74.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>73.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>75.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>76.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">78.6</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Tiger</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>90.1</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>91.9</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>91.5</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>88.7</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="Italic">92.8</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                          <row>
                            <entry align="left" colname="c1">
                              <SimplePara>    Mean</SimplePara>
                            </entry>
                            <entry align="left" colname="c2">
                              <SimplePara>82.8</SimplePara>
                            </entry>
                            <entry align="left" colname="c3">
                              <SimplePara>83.6</SimplePara>
                            </entry>
                            <entry align="left" colname="c4">
                              <SimplePara>84.3</SimplePara>
                            </entry>
                            <entry align="left" colname="c5">
                              <SimplePara>85.0</SimplePara>
                            </entry>
                            <entry align="left" colname="c6">
                              <SimplePara>
                                <Emphasis Type="BoldItalic">86.9</Emphasis>
                              </SimplePara>
                            </entry>
                            <entry align="left" colname="c7"/>
                            <entry align="left" colname="c8"/>
                            <entry align="left" colname="c9"/>
                          </row>
                        </tbody>
                      </tgroup>
                      <tfooter>
                        <SimplePara>Comparison in terms of AP of all 20 concepts, as well as their mean. (a) and (b) illustrate the results when learning from social tags and manual tags respectively. Only the best performing boosting algorithm—GentleBoost, and its importance weighted extension Gentle-IW are given here. In addition, per-concept weighting is used for Gentle-IW and SVM-IW. The user tagging accuracy of each concept in our training dataset is also given at the last column in (a). The best performance among all methods for each concept is italicized, while the highest mean values are both italicized and bolded</SimplePara>
                      </tfooter>
                    </Table>
                  </Para>
                </Section3>
              </Section2>
            </Section1>
            <Section1 ID="Sec31">
              <Heading>Conclusions</Heading>
              <Para>We have explored two dominant classification paradigms, namely, SVM and Boosting, for visual concept learning. In our experiments, we considered both the use of social tags and manual annotations of training images to evaluate the proposed methods. The results show that the visual neighbor voting model works well for image ranking when learning from user-tagged images, while SVM classifiers perform best using manual annotations. Visual neighbor voting using rank-based weights and GentleBoost classification also achieve top tier performance relative to other variants of the tag relevance learning model or the boosting algorithm. Note that a limiting aspect of our work is that there are many diverse parameters in each approach. It would not be surprising that any single approach can be optimized further and this would logically have an effect on the quantitative performance.</Para>
              <Para>Indeed, for a given concept, relevant images have to be emphasized more in the training process than irrelevant images. Therefore we introduced an importance weighted extension to incorporate the example-dependent importance weights into SVM and boosting classifiers. Experimental results demonstrate that the importance weighted approaches are competitive with the state of the art approaches.</Para>
              <Para>We found that some semantic concepts remain difficult to learn in our experiments. Regarding unsupervised visual concept learning, it was found in the experiments that classes such as <Emphasis Type="Italic">tiger</Emphasis> and <Emphasis Type="Italic">airplane</Emphasis> had low average precision across all the machine learning algorithms. From studying the manual visual concept learning results, it appears that a significant reason is the noise in the social training tags.</Para>
              <Para>In the case of visual concept learning using approaches from the research literature on the unsupervised social imaging test set, three different algorithms performed best for three different performance measures. Specifically, the Uniform, Rank and SVM methods performed best for the performance measures AP, BEP and MRR, respectively. No single research literature approach had the best performance for all accuracy measures.</Para>
              <Para>Learning visual concepts from social images is a difficult and challenging problem. This is in large part due to the fact that user supplied tags are typically ambiguous, subjective and incomplete. We have two conclusions from this study. First, overall, the “cost-sensitive” and “importance weighting” approaches are promising and typically have top tier performance in our experiments. Second, the performance measure does have a major impact on the comparative results. Any single algorithm is unlikely to perform best for all performance measures. One grand challenge in the future will be designing algorithms which address the issues of tag ambiguity, subjectivity and incompleteness. Another grand challenge is to design new social tagging learning methods to optimize different performance measures which arise due to the needs of different real life situations.</Para>
            </Section1>
          </Body>
          <BodyRef FileRef="BodyRef/PDF/13735_2012_Article_22.pdf" TargetType="OnlinePDF"/>
          <BodyRef FileRef="BodyRef/PDF/13735_2012_22_TEX.zip" TargetType="TEX"/>
          <ArticleBackmatter>
            <Acknowledgments>
              <Heading>Acknowledgments</Heading>
              <SimplePara>This work was supported by the MIR Institute and Leiden University.</SimplePara>
            </Acknowledgments>
            <Bibliography ID="Bib1">
              <Heading>References</Heading>
              <Citation ID="CR1">
                <CitationNumber>1.</CitationNumber>
                <BibUnstructured>Lew MS, Sebe N, Djeraba C, Jain R (Feb 2006) Content-based multimedia information retrieval: state of the art and challenges. ACM Trans Multimed Comput Commun Appl 2(1):1–19. doi:<ExternalRef>
                    <RefSource>10.1145/1126004.1126005</RefSource>
                    <RefTarget Address="10.1145/1126004.1126005" TargetType="DOI"/>
                  </ExternalRef>
                </BibUnstructured>
              </Citation>
              <Citation ID="CR2">
                <CitationNumber>2.</CitationNumber>
                <BibUnstructured>Wang C, Zhang L, Zhang HJ (2008) Learning to reduce the semantic gap in web image retrieval and annotation. In: Proc. ACM SIGIR research and development in information retrieval (SIGIR ’08), pp 355–362. doi: <ExternalRef><RefSource>10.1145/1390334.1390396</RefSource><RefTarget TargetType="DOI" Address="10.1145/1390334.1390396"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR3">
                <CitationNumber>3.</CitationNumber>
                <BibUnstructured>Datta R, Joshi D, Li J, Wang JZ (May 2008) Image retrieval: ideas, influences, and trends of the new age. ACM Comput Surv 40(2): 1–60. doi:<ExternalRef>
                    <RefSource>10.1145/1348246.1348248</RefSource>
                    <RefTarget Address="10.1145/1348246.1348248" TargetType="DOI"/>
                  </ExternalRef>
                </BibUnstructured>
              </Citation>
              <Citation ID="CR4">
                <CitationNumber>4.</CitationNumber>
                <BibUnstructured>Flickr Blog (2010) 5 Billion Photos on Flickr. <ExternalRef>
                    <RefSource>http://blog.flickr.net/2010/09/19/5000000000/</RefSource>
                    <RefTarget Address="http://blog.flickr.net/2010/09/19/5000000000/" TargetType="URL"/>
                  </ExternalRef>
                </BibUnstructured>
              </Citation>
              <Citation ID="CR5">
                <CitationNumber>5.</CitationNumber>
                <BibUnstructured>Quenot G, Tseng A, Safadi B, Ayache S ( 2010) TRECVID 2010 collaborative annotation. <ExternalRef>
                    <RefSource>http://mrim.imag.fr/tvca2010/</RefSource>
                    <RefTarget Address="http://mrim.imag.fr/tvca2010/" TargetType="URL"/>
                  </ExternalRef>
                </BibUnstructured>
              </Citation>
              <Citation ID="CR6">
                <CitationNumber>6.</CitationNumber>
                <BibUnstructured>Richmond S (2011) YouTube users uploading two days of video every minute. Daily Telegraph, <ExternalRef>
                    <RefSource>http://www.telegraph.co.uk/technology/goole/8536634/YouTube-users-uploading-two-days-of-video-every-minute.html/</RefSource>
                    <RefTarget Address="http://www.telegraph.co.uk/technology/goole/8536634/YouTube-users-uploading-two-days-of-video-every-minute.html/" TargetType="URL"/>
                  </ExternalRef>. Retrieved May 26, 2011</BibUnstructured>
              </Citation>
              <Citation ID="CR7">
                <CitationNumber>7.</CitationNumber>
                <BibUnstructured>Huiskes MJ, Thomee B, Lew MS (2010) New trends and ideas in visual concept detection. In: Proc. ACM Int’l Conf. Multimedia Information Retrieval (MIR ’10). pp 527–536. doi: <ExternalRef><RefSource>10.1145/1743384.1743475</RefSource><RefTarget TargetType="DOI" Address="10.1145/1743384.1743475"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR8">
                <CitationNumber>8.</CitationNumber>
                <BibUnstructured>Chang S-F, He J, Jiang Y-G, Khoury EE, Ngo C-W, Yanagawa A, Zavesky E, Columbia University/VIREO-CityU/IRIT TRECVID, (2008) High-level feature extraction and interactive video search”. In: TRECVID 2008:2008</BibUnstructured>
              </Citation>
              <Citation ID="CR9">
                <CitationNumber>9.</CitationNumber>
                <BibUnstructured>Zhu S, Wang G, Ngo C-W, Jiang Y-G (2010) On the sampling of web images for learning visual concept classifiers. In: Proc. ACM Int’l Conf. image and video retrieval (CIVR ’10). pp 50–57. doi: <ExternalRef><RefSource>10.1145/1816041.1816051</RefSource><RefTarget TargetType="DOI" Address="10.1145/1816041.1816051"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR10">
                <CitationNumber>10.</CitationNumber>
                <BibUnstructured>Makadia A, Pavlovic V, Kumar S (2008) A new baseline for image annotation. In: Proc. European Conf. Computer Vision (ECCV ’08). pp 316–329. doi: <ExternalRef><RefSource>10.1007/978-3-540-88690-7_24</RefSource><RefTarget TargetType="DOI" Address="10.1007/978-3-540-88690-7_24"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR11">
                <CitationNumber>11.</CitationNumber>
                <BibUnstructured>Li X, Snoek CGM, Worring M (2009) Learning social tag relevance by neighbor voting. IEEE Trans Multimedia. pp 1310–1322</BibUnstructured>
              </Citation>
              <Citation ID="CR12">
                <CitationNumber>12.</CitationNumber>
                <BibUnstructured>Guillaumin M, Mensink T, Verbeek J, Schmid C (2009) Tagprop: discriminative metric learning in nearest neighbor models for image auto-annotation. In: Proc. IEEE Int’l Conf. Computer Vision (ICCV ’09). pp 309–316. doi: <ExternalRef><RefSource>10.1109/ICCV.2009.5459266</RefSource><RefTarget TargetType="DOI" Address="10.1109/ICCV.2009.5459266"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR13">
                <CitationNumber>13.</CitationNumber>
                <BibUnstructured>Nowak S, Dunker P (2009) Overview of the CLEF2009 large-scale visual concept detection and annotation task. In: CLEF working notes 2009</BibUnstructured>
              </Citation>
              <Citation ID="CR14">
                <CitationNumber>14.</CitationNumber>
                <BibUnstructured>Huiskes MJ, Lew MS (2008) The MIR Flickr retrieval evaluation. In: Proc. ACM Int’l Conf. multimedia information retrieval (MIR ’08) pp 39–43. doi: <ExternalRef><RefSource>10.1145/1460096.1460104</RefSource><RefTarget TargetType="DOI" Address="10.1145/1460096.1460104"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR15">
                <CitationNumber>15.</CitationNumber>
                <BibUnstructured>Sande KEA, Gevers T, Smeulders AWM (2009) The University of Amsterdam’s concept detection system at ImageCLEF 2009. In: CLEF working notes 2009</BibUnstructured>
              </Citation>
              <Citation ID="CR16">
                <CitationNumber>16.</CitationNumber>
                <BibUnstructured>Mikolajczyk K, Schmid C (2002) An affine invariant interest point detector. In: Proc. European Conf. computer vision (ECCV ’02). pp 128–142. doi: <ExternalRef><RefSource>10.1007/3-540-47969-4_9</RefSource><RefTarget TargetType="DOI" Address="10.1007/3-540-47969-4_9"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR17">
                <CitationNumber>17.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>T</Initials>
                    <FamilyName>Tuytelaars</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>K</Initials>
                    <FamilyName>Mikolajczyk</FamilyName>
                  </BibAuthorName>
                  <Year>2008</Year>
                  <ArticleTitle Language="En">Local Invariant Feature Detectors: A Survey</ArticleTitle>
                  <JournalTitle>Found Trends Comput Graph Visions</JournalTitle>
                  <VolumeID>3</VolumeID>
                  <IssueID>3</IssueID>
                  <FirstPage>177</FirstPage>
                  <LastPage> 280</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1561/0600000017</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Tuytelaars T, Mikolajczyk K (2008) Local Invariant Feature Detectors: A Survey. Found Trends Comput Graph Visions 3(3):177– 280</BibUnstructured>
              </Citation>
              <Citation ID="CR18">
                <CitationNumber>18.</CitationNumber>
                <BibUnstructured>Nowak E, Jurie F, Triggs B ( 2006) Sampling strategies for bag-of-features image classification. In: Proc. European Conf. computer vision (ECCV ’06). pp 490–503. doi: <ExternalRef><RefSource>10.1007/11744085_38</RefSource><RefTarget TargetType="DOI" Address="10.1007/11744085_38"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR19">
                <CitationNumber>19.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>D</Initials>
                    <FamilyName>Lowe</FamilyName>
                  </BibAuthorName>
                  <Year>2004</Year>
                  <ArticleTitle Language="En">Distinctive image features from scale-invariant keypoints</ArticleTitle>
                  <JournalTitle>Int J Comput Vision</JournalTitle>
                  <VolumeID>60</VolumeID>
                  <IssueID>2</IssueID>
                  <FirstPage>91</FirstPage>
                  <LastPage>110</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1023/B:VISI.0000029664.99615.94</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Lowe D (2004) Distinctive image features from scale-invariant keypoints. Int J Comput Vision 60(2):91–110</BibUnstructured>
              </Citation>
              <Citation ID="CR20">
                <CitationNumber>20.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>H</Initials>
                    <FamilyName>Bay</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>A</Initials>
                    <FamilyName>Ess</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>T</Initials>
                    <FamilyName>Tuytelaars</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>LV</Initials>
                    <FamilyName>Gool</FamilyName>
                  </BibAuthorName>
                  <Year>2008</Year>
                  <ArticleTitle Language="En">Speed-up robust features</ArticleTitle>
                  <JournalTitle>Comput Vision Image Underst</JournalTitle>
                  <VolumeID>110</VolumeID>
                  <FirstPage>346</FirstPage>
                  <LastPage>359</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1016/j.cviu.2007.09.014</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Bay H, Ess A, Tuytelaars T, Gool LV (2008) Speed-up robust features. Comput Vision Image Underst 110:346–359</BibUnstructured>
              </Citation>
              <Citation ID="CR21">
                <CitationNumber>21.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>JRR</Initials>
                    <FamilyName>Uijlings</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>AWM</Initials>
                    <FamilyName>Smeulders</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>RJH</Initials>
                    <FamilyName>Scha</FamilyName>
                  </BibAuthorName>
                  <Year>2010</Year>
                  <ArticleTitle Language="En">Real-time visual concept classification</ArticleTitle>
                  <JournalTitle>IEEE Trans. Multimed</JournalTitle>
                  <VolumeID>12</VolumeID>
                  <IssueID>7</IssueID>
                  <FirstPage>665</FirstPage>
                  <LastPage>681</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1109/TMM.2010.2052027</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Uijlings JRR, Smeulders AWM, Scha RJH (2010) Real-time visual concept classification. IEEE Trans. Multimed 12(7):665–681</BibUnstructured>
              </Citation>
              <Citation ID="CR22">
                <CitationNumber>22.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>F</Initials>
                    <FamilyName>Moosmann</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>E</Initials>
                    <FamilyName>Nowak</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>F</Initials>
                    <FamilyName>Jurie</FamilyName>
                  </BibAuthorName>
                  <Year>2008</Year>
                  <ArticleTitle Language="En">Randomized clustering forests for image classification</ArticleTitle>
                  <JournalTitle>IEEE Trans Pattern Anal Mach Intell</JournalTitle>
                  <VolumeID>9</VolumeID>
                  <FirstPage>1632</FirstPage>
                  <LastPage>1646</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1109/TPAMI.2007.70822</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Moosmann F, Nowak E, Jurie F (2008) Randomized clustering forests for image classification. IEEE Trans Pattern Anal Mach Intell 9:1632–1646</BibUnstructured>
              </Citation>
              <Citation ID="CR23">
                <CitationNumber>23.</CitationNumber>
                <BibUnstructured>Gemert J, Veenman C, Smeulders A, Geusebroek J (2009) Visual Word Ambiguity. IEEE Trans Pattern Anal Mach Intell, 32:1271–1283</BibUnstructured>
              </Citation>
              <Citation ID="CR24">
                <CitationNumber>24.</CitationNumber>
                <BibUnstructured>Lazebnik S, Schmid C, Ponce J (2006) Beyond bags of features: spatial pyramid matching for recognizing natural scene categories. In: Proc. IEEE Int’l Conf. Computer Vision and Pattern Recognition (CVPR ’06), vol 2. pp 2169–2178. doi: <ExternalRef><RefSource>10.1109/CVPR.2006.68</RefSource><RefTarget TargetType="DOI" Address="10.1109/CVPR.2006.68"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR25">
                <CitationNumber>25.</CitationNumber>
                <BibUnstructured>Yuan J, Wu Y, Yang M (2007) Discovery of collocation patterns: from visual words to visual phrases. In: Proc. IEEE Int’l Conf. computer vision and pattern recognition (CVPR ’07). pp 1–8. doi: <ExternalRef><RefSource>10.1109/CVPR.2007.383222</RefSource><RefTarget TargetType="DOI" Address="10.1109/CVPR.2007.383222"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR26">
                <CitationNumber>26.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>J</Initials>
                    <FamilyName>Zhang</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>M</Initials>
                    <FamilyName>Marszalek</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>S</Initials>
                    <FamilyName>Lazebnik</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>C</Initials>
                    <FamilyName>Schmid</FamilyName>
                  </BibAuthorName>
                  <Year>2007</Year>
                  <ArticleTitle Language="En">Local features and kernels for classification of texture and object categories: a comprehensive study</ArticleTitle>
                  <JournalTitle>Int J Comput Vision</JournalTitle>
                  <VolumeID>73</VolumeID>
                  <IssueID>2</IssueID>
                  <FirstPage>213</FirstPage>
                  <LastPage>238</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1007/s11263-006-9794-4</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Zhang J, Marszalek M, Lazebnik S, Schmid C (2007) Local features and kernels for classification of texture and object categories: a comprehensive study. Int J Comput Vision 73(2):213–238</BibUnstructured>
              </Citation>
              <Citation ID="CR27">
                <CitationNumber>27.</CitationNumber>
                <BibUnstructured>Maji S, Berg A, Malik J (2008) Classification using intersection kernel support vector machines is efficient. In: Proc. IEEE Int’l Conf. computer vision and pattern recognition (CVPR ’08). pp 1–8. doi: <ExternalRef><RefSource>10.1109/CVPR.2008.4587630</RefSource><RefTarget TargetType="DOI" Address="10.1109/CVPR.2008.4587630"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR28">
                <CitationNumber>28.</CitationNumber>
                <BibUnstructured>Viola P, Jones M (2001) Rapid object detection using a boosted cascade of simple features. In: Proc. IEEE Int’l Conf. computer vision and pattern recognition (CVPR ’01), vol 1. pp 511–518. doi: <ExternalRef><RefSource>10.1109/CVPR.2001.990517</RefSource><RefTarget TargetType="DOI" Address="10.1109/CVPR.2001.990517"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR29">
                <CitationNumber>29.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>A</Initials>
                    <FamilyName>Torralba</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>KP</Initials>
                    <FamilyName>Murphy</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>WT</Initials>
                    <FamilyName>Freeman</FamilyName>
                  </BibAuthorName>
                  <Year>2007</Year>
                  <ArticleTitle Language="En">Sharing visual features for multiclass and multiview object detection</ArticleTitle>
                  <JournalTitle>IEEE Trans Pattern Anal Mach Intell</JournalTitle>
                  <VolumeID>29</VolumeID>
                  <IssueID>5</IssueID>
                  <FirstPage>854</FirstPage>
                  <LastPage>869</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1109/TPAMI.2007.1055</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Torralba A, Murphy KP, Freeman WT (2007) Sharing visual features for multiclass and multiview object detection. IEEE Trans Pattern Anal Mach Intell 29(5):854–869</BibUnstructured>
              </Citation>
              <Citation ID="CR30">
                <CitationNumber>30.</CitationNumber>
                <BibUnstructured>Verbeek J, Guillaumin M, Mensink T, Schmid C (2010) Image annotation with TagProp on the MIRFLICKR set. In: Proc. ACM Int’l Conf. multimedia information retrieval (MIR ’10). doi: <ExternalRef><RefSource>10.1145/1743384.1743476</RefSource><RefTarget TargetType="DOI" Address="10.1145/1743384.1743476"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR31">
                <CitationNumber>31.</CitationNumber>
                <BibUnstructured>Kennedy LS, Chang S-F, Kozintsev IV (2006) To search or to label: predicting the performance of search-based automatic image classifiers. In: Proc. ACM Int’l Conf. multimedia information retrieval (MIR ’06)</BibUnstructured>
              </Citation>
              <Citation ID="CR32">
                <CitationNumber>32.</CitationNumber>
                <BibUnstructured>Bischoff K, Firan CS, Nejdl W, Paiu R (2008) Can All Tags Be Used for Search. In: Proc. ACM Int’l Conf. information and knowledge management (CIKM ’08)</BibUnstructured>
              </Citation>
              <Citation ID="CR33">
                <CitationNumber>33.</CitationNumber>
                <BibUnstructured>Liu D, Hua XS, Yang L, Wang M, Zhang HJ (2009) Tag Ranking. In: Proc. ACM Conf. World Wide Web (WWW ’09). doi: <ExternalRef><RefSource>10.1145/1526709.1526757</RefSource><RefTarget TargetType="DOI" Address="10.1145/1526709.1526757"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR34">
                <CitationNumber>34.</CitationNumber>
                <BibUnstructured>Ulges A, Schulze C, Keysers D, Breuel T (2008) Identifying relevant frames in weakly labeled videos for training concept detectors. In: Proc. ACM Int’l Conf. image and video retrieval (CIVR ’08). pp 9–16. doi: <ExternalRef><RefSource>10.1145/1386352.1386358</RefSource><RefTarget TargetType="DOI" Address="10.1145/1386352.1386358"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR35">
                <CitationNumber>35.</CitationNumber>
                <BibUnstructured>Gehler P, Nowozin S (2009) On feature combination for multiclass object classification. In: Proc. IEEE Int’l Conf. computer vision (ICCV ’09). pp 221–228. doi: <ExternalRef><RefSource>10.1109/ICCV.2009.5459169</RefSource><RefTarget TargetType="DOI" Address="10.1109/ICCV.2009.5459169"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR36">
                <CitationNumber>36.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>Y</Initials>
                    <FamilyName>Freund</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>R</Initials>
                    <FamilyName>Schapire</FamilyName>
                  </BibAuthorName>
                  <Year>1997</Year>
                  <ArticleTitle Language="En">A decision-theoretic generalization of online learning and an application to boosting</ArticleTitle>
                  <JournalTitle>J Comput Syst Sci</JournalTitle>
                  <VolumeID>55</VolumeID>
                  <IssueID>1</IssueID>
                  <FirstPage>119</FirstPage>
                  <LastPage>139</LastPage>
                  <Occurrence Type="AMSID">
                    <Handle>1473055</Handle>
                  </Occurrence>
                  <Occurrence Type="DOI">
                    <Handle>10.1006/jcss.1997.1504</Handle>
                  </Occurrence>
                  <Occurrence Type="ZLBID">
                    <Handle>0880.68103</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Freund Y, Schapire R (1997) A decision-theoretic generalization of online learning and an application to boosting. J Comput Syst Sci 55(1):119–139</BibUnstructured>
              </Citation>
              <Citation ID="CR37">
                <CitationNumber>37.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>J</Initials>
                    <FamilyName>Friedman</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>T</Initials>
                    <FamilyName>Hastie</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>R</Initials>
                    <FamilyName>Tibshirani</FamilyName>
                  </BibAuthorName>
                  <Year>2000</Year>
                  <ArticleTitle Language="En">Additive logistic regression: a statistical view of boosting</ArticleTitle>
                  <JournalTitle>Ann Stat</JournalTitle>
                  <VolumeID>38</VolumeID>
                  <FirstPage>337</FirstPage>
                  <LastPage>374</LastPage>
                  <Occurrence Type="AMSID">
                    <Handle>1790002</Handle>
                  </Occurrence>
                  <Occurrence Type="DOI">
                    <Handle>10.1214/aos/1016218223</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Friedman J, Hastie T, Tibshirani R (2000) Additive logistic regression: a statistical view of boosting. Ann Stat 38:337–374</BibUnstructured>
              </Citation>
              <Citation ID="CR38">
                <CitationNumber>38.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>XC</Initials>
                    <FamilyName>Yin</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>CP</Initials>
                    <FamilyName>Liu</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>Z</Initials>
                    <FamilyName>Han</FamilyName>
                  </BibAuthorName>
                  <Year>2005</Year>
                  <ArticleTitle Language="En">Feature combination using boosting</ArticleTitle>
                  <JournalTitle>Pattern Recognit Lett</JournalTitle>
                  <VolumeID>26</VolumeID>
                  <IssueID>14</IssueID>
                  <FirstPage>2195</FirstPage>
                  <LastPage>2205</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1016/j.patrec.2005.03.029</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Yin XC, Liu CP, Han Z (2005) Feature combination using boosting. Pattern Recognit Lett 26(14):2195–2205</BibUnstructured>
              </Citation>
              <Citation ID="CR39">
                <CitationNumber>39.</CitationNumber>
                <BibUnstructured>Li X, Snoek CGM, Worring M (2010) Unsupervised multi-feature tag relevance learning for social image retrieval. In: Proc. ACM Int’l Conf. image and video retrieval (CIVR ’10). pp 10–17. doi: <ExternalRef><RefSource>10.1145/1816041.1816044</RefSource><RefTarget TargetType="DOI" Address="10.1145/1816041.1816044"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR40">
                <CitationNumber>40.</CitationNumber>
                <BibUnstructured>Turney P (2000) Types of cost in inductive concept learning. In: Proc. Int’l Conf. machine learning workshop cost-sensitive learning (ICML ’00). pp 15–21</BibUnstructured>
              </Citation>
              <Citation ID="CR41">
                <CitationNumber>41.</CitationNumber>
                <BibUnstructured>Domingos P (1999) MetaCost: a general method for making classifiers cost-sensitive. In: Proc. ACM SIGKDD. pp 155–164. doi: <ExternalRef><RefSource>10.1145/312129.312220</RefSource><RefTarget TargetType="DOI" Address="10.1145/312129.312220"/></ExternalRef>. </BibUnstructured>
              </Citation>
              <Citation ID="CR42">
                <CitationNumber>42.</CitationNumber>
                <BibUnstructured>Elkan C (2001) The foundations of cost-sensitive learning. In: Proc. 17th Int’l Joint Conf. artificial intelligence. pp 973–978</BibUnstructured>
              </Citation>
              <Citation ID="CR43">
                <CitationNumber>43.</CitationNumber>
                <BibUnstructured>Zhou Z-H, Liu X-Y (2006) On multi-class cost-sensitive learning. In: Proc. 21st Nat’l Conf. artificial intelligence. pp 567–572</BibUnstructured>
              </Citation>
              <Citation ID="CR44">
                <CitationNumber>44.</CitationNumber>
                <BibUnstructured>Zadrozny B, Langford J, Abe N (2003) Cost-sensitive learning by cost-proportionate example weighting. In: Proc. IEEE 3rd Int’l Conf. data mining. pp 435–442. doi: <ExternalRef><RefSource>10.1109/ICDM.2003.1250950</RefSource><RefTarget TargetType="DOI" Address="10.1109/ICDM.2003.1250950"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR45">
                <CitationNumber>45.</CitationNumber>
                <BibUnstructured>Abe N, Zadrozny B, Langford J (2004) An iterative method for multi-class cost-sensitive learning. In: Proc. ACM SIGKDD. pp 3–11. doi: <ExternalRef><RefSource>10.1145/1014052.1014056</RefSource><RefTarget TargetType="DOI" Address="10.1145/1014052.1014056"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR46">
                <CitationNumber>46.</CitationNumber>
                <BibUnstructured>Karakoulas G, Shawe-Taylor J (1999) Optimizing classifiers for imbalanced training sets. In: Proc. neural information processing systems workshop (NIPS ’99). pp 253–259</BibUnstructured>
              </Citation>
              <Citation ID="CR47">
                <CitationNumber>47.</CitationNumber>
                <BibUnstructured>Brefeld U, Geibel P, Wysotzki F (2003) Support vector machines with example dependent costs. In: Proc. European Conf. machine learning (ECML ’03). pp 23–34. doi: <ExternalRef><RefSource>10.1007/978-3-540-39857-8_5</RefSource><RefTarget TargetType="DOI" Address="10.1007/978-3-540-39857-8_5"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR48">
                <CitationNumber>48.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>FR</Initials>
                    <FamilyName>Bach</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>D</Initials>
                    <FamilyName>Heckerman</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>E</Initials>
                    <FamilyName>Horvitz</FamilyName>
                  </BibAuthorName>
                  <Year>2006</Year>
                  <ArticleTitle Language="En">Considering cost asymmetry in learning classifiers</ArticleTitle>
                  <JournalTitle>J Mach Learn Res</JournalTitle>
                  <VolumeID>7</VolumeID>
                  <FirstPage>1713</FirstPage>
                  <LastPage>1741</LastPage>
                  <Occurrence Type="AMSID">
                    <Handle>2274422</Handle>
                  </Occurrence>
                  <Occurrence Type="ZLBID">
                    <Handle>1222.68137</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Bach FR, Heckerman D, Horvitz E (2006) Considering cost asymmetry in learning classifiers. J Mach Learn Res 7:1713–1741</BibUnstructured>
              </Citation>
              <Citation ID="CR49">
                <CitationNumber>49.</CitationNumber>
                <BibUnstructured>Fan W, Stolfo S, Zhang J, Chan P (1999) AdaCost: misclassification cost-sensitive boosting. In: Proc. 16th Int’l Conf. machine learning (ICML ’99). pp 97–105</BibUnstructured>
              </Citation>
              <Citation ID="CR50">
                <CitationNumber>50.</CitationNumber>
                <BibUnstructured>Ting KM (2000) A comparative study of cost-sensitive boosting algorithms. In: Proc. 17th Int’l Conf. machine learning (ICML ’00). pp 983–990</BibUnstructured>
              </Citation>
              <Citation ID="CR51">
                <CitationNumber>51.</CitationNumber>
                <BibUnstructured>Sun Y, Wong AKC, Wang Y (2005) Parameter inference of cost-sensitive boosting algorithms. In: Proc. 4th Int’l Conf. machine learning and data mining in Pattern Recognition. pp 21–30. doi: <ExternalRef><RefSource>10.1007/11510888_3</RefSource><RefTarget TargetType="DOI" Address="10.1007/11510888_3"/></ExternalRef>.</BibUnstructured>
              </Citation>
              <Citation ID="CR52">
                <CitationNumber>52.</CitationNumber>
                <BibUnstructured>Schapire R (2001) The boosting approach to machine learning: an overview. In: MSRI workshop on nonlinear estimation and classification</BibUnstructured>
              </Citation>
              <Citation ID="CR53">
                <CitationNumber>53.</CitationNumber>
                <BibUnstructured>Li X, Snoek C, Worring M (2009) Social20: a ground-truth set for tag-based social image retrieval. <ExternalRef>
                    <RefSource>http://staff.science.uva.nl/~xirong/index.php?n=Research.TagRelevanceLearning</RefSource>
                    <RefTarget Address="http://staff.science.uva.nl/~xirong/index.php?n=Research.TagRelevanceLearning" TargetType="URL"/>
                  </ExternalRef>
                </BibUnstructured>
              </Citation>
              <Citation ID="CR54">
                <CitationNumber>54.</CitationNumber>
                <BibUnstructured>Huang J, Kumar S, Mitra M, Zhu W, Zabih R (1997) Image indexing using color correlograms. In: Proc. IEEE Int’l Conf. computer vision and pattern recognition (CVPR ’97)</BibUnstructured>
              </Citation>
              <Citation ID="CR55">
                <CitationNumber>55.</CitationNumber>
                <BibUnstructured>Yu H, Li M, Zhang H, Feng J (2002) Color texture moment for content-based image retrieval. In: Proc. IEEE Int’l Conf. image processing (ICIP ’02). pp 929–932</BibUnstructured>
              </Citation>
              <Citation ID="CR56">
                <CitationNumber>56.</CitationNumber>
                <BibArticle>
                  <BibAuthorName>
                    <Initials>A</Initials>
                    <FamilyName>Oliva</FamilyName>
                  </BibAuthorName>
                  <BibAuthorName>
                    <Initials>A</Initials>
                    <FamilyName>Torralba</FamilyName>
                  </BibAuthorName>
                  <Year>2001</Year>
                  <ArticleTitle Language="En">Modeling the shape of the scene: a holistic representation of the spatial envelope</ArticleTitle>
                  <JournalTitle>Int J Comput Vision</JournalTitle>
                  <VolumeID>42</VolumeID>
                  <IssueID>3</IssueID>
                  <FirstPage>145</FirstPage>
                  <LastPage>175</LastPage>
                  <Occurrence Type="DOI">
                    <Handle>10.1023/A:1011139631724</Handle>
                  </Occurrence>
                  <Occurrence Type="ZLBID">
                    <Handle>0990.68601</Handle>
                  </Occurrence>
                </BibArticle>
                <BibUnstructured>Oliva A, Torralba A (2001) Modeling the shape of the scene: a holistic representation of the spatial envelope. Int J Comput Vision 42(3):145–175</BibUnstructured>
              </Citation>
              <Citation ID="CR57">
                <CitationNumber>57.</CitationNumber>
                <BibUnstructured>Freund Y, Schapire RE (2000) Discussion of the paper ‘Additive Logistic Regression: A Statistical View of Boosting’. In: The Annals of Statistics, vol 28, issue 2, pp 391–393</BibUnstructured>
              </Citation>
              <Citation ID="CR58">
                <CitationNumber>58.</CitationNumber>
                <BibUnstructured>Guruswami V, Sahai A (1999) Multiclass learning, boosting, and error-correcting codes. In: Proc. 12th annual conf. computational learning theory. pp 145–155. doi: <ExternalRef><RefSource>10.1145/307400.307429</RefSource><RefTarget TargetType="DOI" Address="10.1145/307400.307429"/></ExternalRef>.</BibUnstructured>
              </Citation>
            </Bibliography>
          </ArticleBackmatter>
        </Article>
      </Issue>
    </Volume>
  </Journal>
</Publisher>
