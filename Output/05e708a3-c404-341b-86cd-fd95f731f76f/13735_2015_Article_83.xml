<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE Publisher PUBLIC "-//Springer-Verlag//DTD A++ V2.4//EN" "http://devel.springer.de/A++/V2.4/DTD/A++V2.4.dtd">
<Publisher>
  <PublisherInfo>
    <PublisherName>Springer London</PublisherName>
    <PublisherLocation>London</PublisherLocation>
    <PublisherImprintName>Springer</PublisherImprintName>
  </PublisherInfo>
  <Journal OutputMedium="All">
    <JournalInfo JournalProductType="ArchiveJournal" NumberingStyle="ContentOnly">
      <JournalID>13735</JournalID>
      <JournalDOI>10.1007/13735.2192-662X</JournalDOI>
      <JournalPrintISSN>2192-6611</JournalPrintISSN>
      <JournalElectronicISSN>2192-662X</JournalElectronicISSN>
      <JournalTitle>International Journal of Multimedia Information Retrieval</JournalTitle>
      <JournalAbbreviatedTitle>Int J Multimed Info Retr</JournalAbbreviatedTitle>
      <JournalSubjectGroup>
        <JournalSubject Code="SCI" Type="Primary">Computer Science</JournalSubject>
        <JournalSubject Code="SCI18059" Priority="1" Type="Secondary">Multimedia Information Systems</JournalSubject>
        <JournalSubject Code="SCI18032" Priority="2" Type="Secondary">Information Storage and Retrieval</JournalSubject>
        <JournalSubject Code="SCI18040" Priority="3" Type="Secondary">Information Systems Applications (incl. Internet)</JournalSubject>
        <JournalSubject Code="SCI18030" Priority="4" Type="Secondary">Data Mining and Knowledge Discovery</JournalSubject>
        <JournalSubject Code="SCI22021" Priority="5" Type="Secondary">Image Processing and Computer Vision</JournalSubject>
        <JournalSubject Code="SCI00001" Priority="6" Type="Secondary">Computer Science, general</JournalSubject>
        <SubjectCollection Code="SC6">Computer Science</SubjectCollection>
      </JournalSubjectGroup>
    </JournalInfo>
    <Volume OutputMedium="All">
      <VolumeInfo TocLevels="0" VolumeType="Regular">
        <VolumeIDStart>4</VolumeIDStart>
        <VolumeIDEnd>4</VolumeIDEnd>
        <VolumeIssueCount>4</VolumeIssueCount>
      </VolumeInfo>
      <Issue IssueType="Regular" OutputMedium="All">
        <IssueInfo IssueType="Regular" TocLevels="0">
          <IssueIDStart>2</IssueIDStart>
          <IssueIDEnd>2</IssueIDEnd>
          <IssueTitle Language="En">Special Issue: Concept Detection with Big Data</IssueTitle>
          <IssueArticleCount>7</IssueArticleCount>
          <IssueHistory>
            <OnlineDate>
              <Year>2015</Year>
              <Month>5</Month>
              <Day>20</Day>
            </OnlineDate>
            <PrintDate>
              <Year>2015</Year>
              <Month>5</Month>
              <Day>19</Day>
            </PrintDate>
            <CoverDate>
              <Year>2015</Year>
              <Month>6</Month>
            </CoverDate>
            <PricelistYear>2015</PricelistYear>
          </IssueHistory>
          <IssueCopyright>
            <CopyrightHolderName>Springer-Verlag London</CopyrightHolderName>
            <CopyrightYear>2015</CopyrightYear>
          </IssueCopyright>
        </IssueInfo>
        <Article ID="s13735-015-0083-2" OutputMedium="All">
          <ArticleInfo ArticleType="EditorialNotes" ContainsESM="No" Language="En" NumberingStyle="ContentOnly" TocLevels="0">
            <ArticleID>83</ArticleID>
            <ArticleDOI>10.1007/s13735-015-0083-2</ArticleDOI>
            <ArticleSequenceNumber>1</ArticleSequenceNumber>
            <ArticleTitle Language="En" OutputMedium="All">Special issue on concept detection with big data</ArticleTitle>
            <ArticleCategory>Editorial</ArticleCategory>
            <ArticleFirstPage>73</ArticleFirstPage>
            <ArticleLastPage>74</ArticleLastPage>
            <ArticleHistory>
              <RegistrationDate>
                <Year>2015</Year>
                <Month>3</Month>
                <Day>7</Day>
              </RegistrationDate>
              <OnlineDate>
                <Year>2015</Year>
                <Month>3</Month>
                <Day>17</Day>
              </OnlineDate>
            </ArticleHistory>
            <ArticleCopyright>
              <CopyrightHolderName>Springer-Verlag London</CopyrightHolderName>
              <CopyrightYear>2015</CopyrightYear>
            </ArticleCopyright>
            <ArticleGrants Type="Regular">
              <MetadataGrant Grant="OpenAccess"/>
              <AbstractGrant Grant="OpenAccess"/>
              <BodyPDFGrant Grant="OpenAccess"/>
              <BodyHTMLGrant Grant="OpenAccess"/>
              <BibliographyGrant Grant="OpenAccess"/>
              <ESMGrant Grant="OpenAccess"/>
            </ArticleGrants>
          </ArticleInfo>
          <ArticleHeader>
            <AuthorGroup>
              <Author AffiliationIDS="Aff1" ID="Au1">
                <AuthorName DisplayOrder="Western">
                  <GivenName>Shih-Fu</GivenName>
                  <FamilyName>Chang</FamilyName>
                </AuthorName>
                <Contact>
                  <Email>sfchang@ee.columbia.edu</Email>
                </Contact>
              </Author>
              <Author AffiliationIDS="Aff2" ID="Au2">
                <AuthorName DisplayOrder="Western">
                  <GivenName>Thomas</GivenName>
                  <GivenName>S.</GivenName>
                  <FamilyName>Huang</FamilyName>
                </AuthorName>
                <Contact>
                  <Email>t-huang1@illinois.edu</Email>
                </Contact>
              </Author>
              <Author AffiliationIDS="Aff3" CorrespondingAffiliationID="Aff3" ID="Au3">
                <AuthorName DisplayOrder="Western">
                  <GivenName>Michael</GivenName>
                  <GivenName>S.</GivenName>
                  <FamilyName>Lew</FamilyName>
                </AuthorName>
                <Contact>
                  <Email>mlew@liacs.nl</Email>
                </Contact>
              </Author>
              <Author AffiliationIDS="Aff4" ID="Au4">
                <AuthorName DisplayOrder="Western">
                  <GivenName>Bart</GivenName>
                  <FamilyName>Thomee</FamilyName>
                </AuthorName>
                <Contact>
                  <Email>bthomee@yahoo-inc.com</Email>
                </Contact>
              </Author>
              <Affiliation ID="Aff1">
                <OrgName>Columbia University</OrgName>
                <OrgAddress>
                  <City>New York</City>
                  <State>NY</State>
                  <Country Code="US">USA</Country>
                </OrgAddress>
              </Affiliation>
              <Affiliation ID="Aff2">
                <OrgName>University of Illinois</OrgName>
                <OrgAddress>
                  <City>Urbana-Champaign</City>
                  <State>IL</State>
                  <Country Code="US">USA</Country>
                </OrgAddress>
              </Affiliation>
              <Affiliation ID="Aff3">
                <OrgName>Leiden University</OrgName>
                <OrgAddress>
                  <City>Leiden</City>
                  <Country Code="NL">The Netherlands</Country>
                </OrgAddress>
              </Affiliation>
              <Affiliation ID="Aff4">
                <OrgName>Yahoo Labs</OrgName>
                <OrgAddress>
                  <City>San Francisco</City>
                  <State>CA</State>
                  <Country Code="US">USA</Country>
                </OrgAddress>
              </Affiliation>
            </AuthorGroup>
          </ArticleHeader>
          <Body>
            <Para ID="Par1">One of the grand challenges of machine intelligence and pattern recognition for the past decade has been bridging the semantic gap, that is, determining how to translate the low-level features from images, video and audio to the high-level concepts of humans. Concept detection is an important approach toward bridging the semantic gap by allowing computers to understand imagery using the conceptual vocabulary of humans. By exploiting big data, the current generation of algorithms has contributed and developed both advances in accuracy and computational efficiency as well as new paradigms and techniques in concept detection.</Para>
            <Para ID="Par2">This special issue provides a focus on the state-of-the-art in concept detection with big data. We received 21 submissions of which 16 were selected for the triple peer-review process. In this special issue, we are pleased to present six research papers on concept detection with big data that present the latest advances in this field:<UnorderedList Mark="Bullet">
                <ItemContent>
                  <Para ID="Par3">Instead of learning concept detectors in advance, which limits users to query only for concepts known to the system, the paper, “On-the-fly Learning for Visual Search of Large-scale Image and Video Datasets” by K. Chatfield, R. Arandjelović, O. Parkhi and A. Zisserman, presents a framework that enables a suitable concept detector to be generated in real-time given a keyword query. The approach considers as positive training examples the top retrieval results obtained by issuing the query to a standard web search engine, and mixes them with a fixed pool of negative examples before learning the classifier. By varying the kind of positive search images downloaded from the search engine, the real-time classifier can be tailored to support different modalities like objects and faces.</Para>
                </ItemContent>
                <ItemContent>
                  <Para ID="Par4">Concept detectors can improve themselves over time by incrementally learning from additional examples. In the paper, “Learning to detect concepts with Approximate Laplacian Eigenmaps in large-scale and online settings” by E. Mantziou, S. Papadopoulos and Y. Kompatsiaris, the authors propose an inductive manifold learning approach that achieves significant speedups on training of concept detectors without noticeably degrading the detection accuracy. Their approach computes an embedding for incoming images while avoiding having to rebuild the underlying latent representation of the manifold.</Para>
                </ItemContent>
                <ItemContent>
                  <Para ID="Par5">The performance of concept detectors is often dependent on the choice and tuning of their underlying kernels. In the paper, “ImageCLEF Annotation with Explicit Context-Aware Kernel Maps” by H. Sahbi, the author designs a new continuous, symmetric and positive semi-definite kernel in which context is integrated, such that pairs of visually and semantically similar images are mapped together. This is achieved by considering an image collection as a graph and the kernel recursively diffuses similarity between neighborhoods of connected images.</Para>
                </ItemContent>
                <ItemContent>
                  <Para ID="Par6">One of the challenges in concept detection is gathering enough, reliable, annotated training examples for building accurate classifiers. In the paper, “Building effective SVM concept detectors from clickthrough data for large-scale image retrieval” by I. Sarafis, C. Diou and A. Delopoulos, the authors analyze the click logs of the Bing image search engine to determine the degree of relevance of an image for a particular concept using IR models, consequently enabling training sets to be automatically generated and used for the construction of noise-resilient SVM classifiers.</Para>
                </ItemContent>
                <ItemContent>
                  <Para ID="Par7">Manual labeling of training examples may yield accurate annotations, but it is a time-consuming effort. In the paper, “Large image modality labeling initiative using semi-supervised and optimized clustering” by S. Vajda, D. You, S. Antani and G. Thoma, the authors propose a multi-view clustering method to reduce the amount of manual labeling needed while still building a reliable classifier. The method projects biomedical images into multiple feature spaces, each of which is separately clustered and where only the cluster centers require manually labeling. The assigned labels are then propagated back to all other images in each cluster provided that a majority of feature spaces agree on the label to assign to an image.</Para>
                </ItemContent>
                <ItemContent>
                  <Para ID="Par8">The multiple modalities underlying cross-media data can not only bring advantages, in terms of being able to exploit additional and complementary signals, but may also bring disadvantages when these signals are different and conflicting. In the paper, “Distributed Cross-Media Multiple Binary Subspace Learning” by X. Zhao, C. Zhang and Z. Zhang, the various modalities of such media are mapped into a common, binary subspace in which a semi-supervised concept detector can be learned efficiently.</Para>
                </ItemContent>
              </UnorderedList>
            </Para>
          </Body>
          <BodyRef FileRef="BodyRef/PDF/13735_2015_Article_83.pdf" PDFType="Typeset" TargetType="OnlinePDF"/>
          <BodyRef FileRef="BodyRef/PDF/13735_2015_83_TEX.zip" TargetType="TEX"/>
        </Article>
      </Issue>
    </Volume>
  </Journal>
</Publisher>
